{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of Linear classifier.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLiR38P6NlU5",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
        "\n",
        "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
        "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
        "\n",
        "В этом задании вы:\n",
        "- потренируетесь считать градиенты различных многомерных функций\n",
        "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
        "- реализуете процесс тренировки линейного классификатора\n",
        "- подберете параметры тренировки на практике\n",
        "\n",
        "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
        "http://cs231n.github.io/python-numpy-tutorial/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geb3fn5nNlU7",
        "colab_type": "code",
        "outputId": "e37cf19b-8d39-415e-e9c2-3d8d466312dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRnONji0PTKF",
        "colab_type": "code",
        "outputId": "9b9febda-6f8c-4a09-ee93-9ced961d01f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 2)) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3oDg9nUNlVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset import load_svhn, random_split_train_val\n",
        "from gradient_check import check_gradient\n",
        "from metrics import multiclass_accuracy \n",
        "import linear_classifer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhu5kVLXNlVN",
        "colab_type": "text"
      },
      "source": [
        "# Как всегда, первым делом загружаем данные\n",
        "\n",
        "Мы будем использовать все тот же SVHN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA0jnA4vNlVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_for_linear_classifier(train_X, test_X):\n",
        "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
        "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
        "    \n",
        "    # Subtract mean\n",
        "    mean_image = np.mean(train_flat, axis = 0)\n",
        "    train_flat -= mean_image\n",
        "    test_flat -= mean_image\n",
        "    \n",
        "    # Add another channel with ones as a bias term\n",
        "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
        "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
        "    return train_flat_with_ones, test_flat_with_ones\n",
        "    \n",
        "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
        "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
        "# Split train into train and val\n",
        "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv3Ei7MaNlVV",
        "colab_type": "text"
      },
      "source": [
        "# Играемся с градиентами!\n",
        "\n",
        "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
        "\n",
        "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
        "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
        "```\n",
        "def f(x):\n",
        "    \"\"\"\n",
        "    Computes function and analytic gradient at x\n",
        "    \n",
        "    x: np array of float, input to the function\n",
        "    \n",
        "    Returns:\n",
        "    value: float, value of the function \n",
        "    grad: np array of float, same shape as x\n",
        "    \"\"\"\n",
        "    ...\n",
        "    \n",
        "    return value, grad\n",
        "```\n",
        "\n",
        "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
        "\n",
        "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
        "\n",
        "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
        "\n",
        "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
        "\n",
        "Все функции приведенные в следующей клетке должны проходить gradient check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9cv-DdJ6NlVW",
        "colab_type": "code",
        "outputId": "0594c104-9d20-4a4c-fe05-8c74e930d6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# TODO: Implement check_gradient function in gradient_check.py\n",
        "# All the functions below should pass the gradient check\n",
        "\n",
        "def square(x):\n",
        "    return float(x*x), 2*x\n",
        "\n",
        "check_gradient(square, np.array([3.0]))\n",
        "\n",
        "def array_sum(x):\n",
        "    assert x.shape == (2,), x.shape\n",
        "    return np.sum(x), np.ones_like(x)\n",
        "\n",
        "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
        "\n",
        "def array_2d_sum(x):\n",
        "    assert x.shape == (2,2)\n",
        "    return np.sum(x), np.ones_like(x)\n",
        "\n",
        "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n",
            "Gradient check passed!\n",
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKVIoSCnNlVc",
        "colab_type": "text"
      },
      "source": [
        "## Начинаем писать свои функции, считающие аналитический градиент\n",
        "\n",
        "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
        "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
        "\n",
        "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
        "\n",
        "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
        "```\n",
        "predictions -= np.max(predictions)\n",
        "```\n",
        "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZOvWSPGNlVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Implement softmax and cross-entropy for single sample\n",
        "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
        "\n",
        "# Make sure it works for big numbers too!\n",
        "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
        "assert np.isclose(probs[0], 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0THkbxNlVl",
        "colab_type": "text"
      },
      "source": [
        "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
        "В общем виде cross-entropy определена следующим образом:\n",
        "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
        "\n",
        "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
        "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
        "\n",
        "Это позволяет реализовать функцию проще!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4PNhbdSNlVm",
        "colab_type": "code",
        "outputId": "0d834e28-5523-47ee-9dfb-09c38836dc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
        "linear_classifer.cross_entropy_loss(probs, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.006760443547122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B74DhwJrNlVr",
        "colab_type": "text"
      },
      "source": [
        "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
        "\n",
        "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
        "\n",
        "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umbJ0GA8NlVs",
        "colab_type": "code",
        "outputId": "0fba6c22-e753-4221-c082-ab1f8794c5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
        "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
        "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5puu0ESNlVx",
        "colab_type": "text"
      },
      "source": [
        "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
        "\n",
        "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
        "\n",
        "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
        "\n",
        "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "S3Sys7ZANlVx",
        "colab_type": "code",
        "outputId": "f7ad2f83-b639-4cf8-93d4-2445bcf25866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
        "np.random.seed(42)\n",
        "# Test batch_size = 1\n",
        "num_classes = 4\n",
        "batch_size = 1\n",
        "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
        "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
        "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
        "\n",
        "# Test batch_size = 3\n",
        "num_classes = 4\n",
        "batch_size = 3\n",
        "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
        "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
        "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
        "\n",
        "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
        "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
        "assert np.all(np.isclose(probs[:, 0], 1.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n",
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfa805gONlV7",
        "colab_type": "text"
      },
      "source": [
        "### Наконец, реализуем сам линейный классификатор!\n",
        "\n",
        "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
        "\n",
        "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
        "\n",
        "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
        "\n",
        "`predictions = X * W`, где `*` - матричное умножение.\n",
        "\n",
        "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjPH5Eg-NlV8",
        "colab_type": "code",
        "outputId": "e9099269-922d-4359-cad6-b3b93ccd94d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
        "batch_size = 2\n",
        "num_classes = 2\n",
        "num_features = 3\n",
        "np.random.seed(42)\n",
        "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
        "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
        "target_index = np.ones(batch_size, dtype=np.int)\n",
        "\n",
        "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
        "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGiQK-w2NlWA",
        "colab_type": "text"
      },
      "source": [
        "### И теперь регуляризация\n",
        "\n",
        "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
        "\n",
        "Напомним, L2 regularization определяется как\n",
        "\n",
        "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
        "\n",
        "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu9dKy7oNlWC",
        "colab_type": "code",
        "outputId": "03a14b03-c85b-4c73-edc9-c17b2c7b09bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
        "linear_classifer.l2_regularization(W, 0.01)\n",
        "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w4v29ZlNlWG",
        "colab_type": "text"
      },
      "source": [
        "# Тренировка!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI14HpmqNlWH",
        "colab_type": "text"
      },
      "source": [
        "Градиенты в порядке, реализуем процесс тренировки!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UJAUHrd9NlWI",
        "colab_type": "code",
        "outputId": "bf0352e5-1e24-4054-c8e2-cefcb42aa35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
        "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
        "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 2.395767\n",
            "Epoch 1, loss: 2.330950\n",
            "Epoch 2, loss: 2.309530\n",
            "Epoch 3, loss: 2.304154\n",
            "Epoch 4, loss: 2.303255\n",
            "Epoch 5, loss: 2.301688\n",
            "Epoch 6, loss: 2.301990\n",
            "Epoch 7, loss: 2.302472\n",
            "Epoch 8, loss: 2.301130\n",
            "Epoch 9, loss: 2.301503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nrqDZe9NlWO",
        "colab_type": "code",
        "outputId": "5e9a8aec-f080-4414-e524-8b24244a8a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# let's look at the loss history!\n",
        "plt.plot(loss_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5fcbcf0e48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVkb-9otNlWR",
        "colab_type": "code",
        "outputId": "b9f64aeb-d3fe-4139-ffae-0512f42d1410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's check how it performs on validation set\n",
        "pred = classifier.predict(val_X)\n",
        "accuracy = multiclass_accuracy(pred, val_y)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "# Now, let's train more and see if it performs better\n",
        "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
        "pred = classifier.predict(val_X)\n",
        "accuracy = multiclass_accuracy(pred, val_y)\n",
        "print(\"Accuracy after training for 100 epochs: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.124\n",
            "Epoch 0, loss: 2.301501\n",
            "Epoch 1, loss: 2.302313\n",
            "Epoch 2, loss: 2.301883\n",
            "Epoch 3, loss: 2.301845\n",
            "Epoch 4, loss: 2.302276\n",
            "Epoch 5, loss: 2.302485\n",
            "Epoch 6, loss: 2.302364\n",
            "Epoch 7, loss: 2.301298\n",
            "Epoch 8, loss: 2.302338\n",
            "Epoch 9, loss: 2.301881\n",
            "Epoch 10, loss: 2.302596\n",
            "Epoch 11, loss: 2.301575\n",
            "Epoch 12, loss: 2.302080\n",
            "Epoch 13, loss: 2.302565\n",
            "Epoch 14, loss: 2.301696\n",
            "Epoch 15, loss: 2.302177\n",
            "Epoch 16, loss: 2.301785\n",
            "Epoch 17, loss: 2.301750\n",
            "Epoch 18, loss: 2.301764\n",
            "Epoch 19, loss: 2.302287\n",
            "Epoch 20, loss: 2.301292\n",
            "Epoch 21, loss: 2.302687\n",
            "Epoch 22, loss: 2.301826\n",
            "Epoch 23, loss: 2.302097\n",
            "Epoch 24, loss: 2.301259\n",
            "Epoch 25, loss: 2.301961\n",
            "Epoch 26, loss: 2.301761\n",
            "Epoch 27, loss: 2.301834\n",
            "Epoch 28, loss: 2.303270\n",
            "Epoch 29, loss: 2.301080\n",
            "Epoch 30, loss: 2.302123\n",
            "Epoch 31, loss: 2.302584\n",
            "Epoch 32, loss: 2.301889\n",
            "Epoch 33, loss: 2.302011\n",
            "Epoch 34, loss: 2.301695\n",
            "Epoch 35, loss: 2.301557\n",
            "Epoch 36, loss: 2.301359\n",
            "Epoch 37, loss: 2.302435\n",
            "Epoch 38, loss: 2.302201\n",
            "Epoch 39, loss: 2.302176\n",
            "Epoch 40, loss: 2.302025\n",
            "Epoch 41, loss: 2.303180\n",
            "Epoch 42, loss: 2.302761\n",
            "Epoch 43, loss: 2.301389\n",
            "Epoch 44, loss: 2.302629\n",
            "Epoch 45, loss: 2.302294\n",
            "Epoch 46, loss: 2.301531\n",
            "Epoch 47, loss: 2.301978\n",
            "Epoch 48, loss: 2.303381\n",
            "Epoch 49, loss: 2.301689\n",
            "Epoch 50, loss: 2.301640\n",
            "Epoch 51, loss: 2.301791\n",
            "Epoch 52, loss: 2.301897\n",
            "Epoch 53, loss: 2.301547\n",
            "Epoch 54, loss: 2.303404\n",
            "Epoch 55, loss: 2.301407\n",
            "Epoch 56, loss: 2.301697\n",
            "Epoch 57, loss: 2.302235\n",
            "Epoch 58, loss: 2.302234\n",
            "Epoch 59, loss: 2.301999\n",
            "Epoch 60, loss: 2.302766\n",
            "Epoch 61, loss: 2.302097\n",
            "Epoch 62, loss: 2.302867\n",
            "Epoch 63, loss: 2.302045\n",
            "Epoch 64, loss: 2.302751\n",
            "Epoch 65, loss: 2.301914\n",
            "Epoch 66, loss: 2.302335\n",
            "Epoch 67, loss: 2.302790\n",
            "Epoch 68, loss: 2.302288\n",
            "Epoch 69, loss: 2.301488\n",
            "Epoch 70, loss: 2.301481\n",
            "Epoch 71, loss: 2.301756\n",
            "Epoch 72, loss: 2.301878\n",
            "Epoch 73, loss: 2.301798\n",
            "Epoch 74, loss: 2.301870\n",
            "Epoch 75, loss: 2.301915\n",
            "Epoch 76, loss: 2.301387\n",
            "Epoch 77, loss: 2.302014\n",
            "Epoch 78, loss: 2.302790\n",
            "Epoch 79, loss: 2.302084\n",
            "Epoch 80, loss: 2.301726\n",
            "Epoch 81, loss: 2.302008\n",
            "Epoch 82, loss: 2.301707\n",
            "Epoch 83, loss: 2.301944\n",
            "Epoch 84, loss: 2.301665\n",
            "Epoch 85, loss: 2.301386\n",
            "Epoch 86, loss: 2.302350\n",
            "Epoch 87, loss: 2.302348\n",
            "Epoch 88, loss: 2.302591\n",
            "Epoch 89, loss: 2.301497\n",
            "Epoch 90, loss: 2.301395\n",
            "Epoch 91, loss: 2.302336\n",
            "Epoch 92, loss: 2.301550\n",
            "Epoch 93, loss: 2.301032\n",
            "Epoch 94, loss: 2.301975\n",
            "Epoch 95, loss: 2.301899\n",
            "Epoch 96, loss: 2.301907\n",
            "Epoch 97, loss: 2.302204\n",
            "Epoch 98, loss: 2.301865\n",
            "Epoch 99, loss: 2.302292\n",
            "Accuracy after training for 100 epochs:  0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0dveEXJNlWW",
        "colab_type": "text"
      },
      "source": [
        "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
        "\n",
        "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
        "\n",
        "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
        "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbShqsjlNlWX",
        "colab_type": "code",
        "outputId": "df283423-80f8-42f6-a838-aa423db8aa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 200\n",
        "batch_size = 300\n",
        "\n",
        "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
        "reg_strengths = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
        "\n",
        "best_classifier = None\n",
        "best_val_accuracy = None\n",
        "best_learning_rate = None\n",
        "best_reg_strength = None\n",
        "\n",
        "# TODO use validation set to find the best hyperparameters\n",
        "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
        "# than provided initially\n",
        "best_val_accuracy = 0\n",
        "for learning_rate in learning_rates:\n",
        "    for reg_strength in reg_strengths:\n",
        "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
        "        loss_history = classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=learning_rate, \n",
        "                                      batch_size=batch_size, reg=reg_strength)\n",
        "        pred = classifier.predict(val_X)\n",
        "        accuracy = multiclass_accuracy(pred, val_y)\n",
        "        if accuracy >= best_val_accuracy:\n",
        "            best_val_accuracy = accuracy\n",
        "            best_classifier = classifier\n",
        "            best_learning_rate = learning_rate\n",
        "            best_reg_strength = reg_strength\n",
        "\n",
        "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
        "print('best learning_rate = %f' % best_learning_rate)\n",
        "print('best reg_strength = %f' % best_reg_strength)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 4, loss: 2.259552\n",
            "Epoch 5, loss: 2.257325\n",
            "Epoch 6, loss: 2.260300\n",
            "Epoch 7, loss: 2.245833\n",
            "Epoch 8, loss: 2.239943\n",
            "Epoch 9, loss: 2.256069\n",
            "Epoch 10, loss: 2.231689\n",
            "Epoch 11, loss: 2.235096\n",
            "Epoch 12, loss: 2.226761\n",
            "Epoch 13, loss: 2.241988\n",
            "Epoch 14, loss: 2.207938\n",
            "Epoch 15, loss: 2.224887\n",
            "Epoch 16, loss: 2.219602\n",
            "Epoch 17, loss: 2.192776\n",
            "Epoch 18, loss: 2.214616\n",
            "Epoch 19, loss: 2.203598\n",
            "Epoch 20, loss: 2.241191\n",
            "Epoch 21, loss: 2.210083\n",
            "Epoch 22, loss: 2.202556\n",
            "Epoch 23, loss: 2.195071\n",
            "Epoch 24, loss: 2.166453\n",
            "Epoch 25, loss: 2.172004\n",
            "Epoch 26, loss: 2.139890\n",
            "Epoch 27, loss: 2.143694\n",
            "Epoch 28, loss: 2.168679\n",
            "Epoch 29, loss: 2.182848\n",
            "Epoch 30, loss: 2.156698\n",
            "Epoch 31, loss: 2.191785\n",
            "Epoch 32, loss: 2.173422\n",
            "Epoch 33, loss: 2.188646\n",
            "Epoch 34, loss: 2.192877\n",
            "Epoch 35, loss: 2.155518\n",
            "Epoch 36, loss: 2.163789\n",
            "Epoch 37, loss: 2.153506\n",
            "Epoch 38, loss: 2.166200\n",
            "Epoch 39, loss: 2.178356\n",
            "Epoch 40, loss: 2.176805\n",
            "Epoch 41, loss: 2.214292\n",
            "Epoch 42, loss: 2.191208\n",
            "Epoch 43, loss: 2.162893\n",
            "Epoch 44, loss: 2.180193\n",
            "Epoch 45, loss: 2.151111\n",
            "Epoch 46, loss: 2.107447\n",
            "Epoch 47, loss: 2.106017\n",
            "Epoch 48, loss: 2.149201\n",
            "Epoch 49, loss: 2.177136\n",
            "Epoch 50, loss: 2.177028\n",
            "Epoch 51, loss: 2.105256\n",
            "Epoch 52, loss: 2.154033\n",
            "Epoch 53, loss: 2.132481\n",
            "Epoch 54, loss: 2.155060\n",
            "Epoch 55, loss: 2.159208\n",
            "Epoch 56, loss: 2.176289\n",
            "Epoch 57, loss: 2.147492\n",
            "Epoch 58, loss: 2.193808\n",
            "Epoch 59, loss: 2.153782\n",
            "Epoch 60, loss: 2.092857\n",
            "Epoch 61, loss: 2.120830\n",
            "Epoch 62, loss: 2.183163\n",
            "Epoch 63, loss: 2.121794\n",
            "Epoch 64, loss: 2.136390\n",
            "Epoch 65, loss: 2.157689\n",
            "Epoch 66, loss: 2.172392\n",
            "Epoch 67, loss: 2.197455\n",
            "Epoch 68, loss: 2.164127\n",
            "Epoch 69, loss: 2.176913\n",
            "Epoch 70, loss: 2.144232\n",
            "Epoch 71, loss: 2.141150\n",
            "Epoch 72, loss: 2.173873\n",
            "Epoch 73, loss: 2.134269\n",
            "Epoch 74, loss: 2.099557\n",
            "Epoch 75, loss: 2.142234\n",
            "Epoch 76, loss: 2.164401\n",
            "Epoch 77, loss: 2.147522\n",
            "Epoch 78, loss: 2.215097\n",
            "Epoch 79, loss: 2.182617\n",
            "Epoch 80, loss: 2.091248\n",
            "Epoch 81, loss: 2.149604\n",
            "Epoch 82, loss: 2.092855\n",
            "Epoch 83, loss: 2.114506\n",
            "Epoch 84, loss: 2.121331\n",
            "Epoch 85, loss: 2.134931\n",
            "Epoch 86, loss: 2.116582\n",
            "Epoch 87, loss: 2.148386\n",
            "Epoch 88, loss: 2.146492\n",
            "Epoch 89, loss: 2.178283\n",
            "Epoch 90, loss: 2.140733\n",
            "Epoch 91, loss: 2.140772\n",
            "Epoch 92, loss: 2.107776\n",
            "Epoch 93, loss: 2.119873\n",
            "Epoch 94, loss: 2.130168\n",
            "Epoch 95, loss: 2.135405\n",
            "Epoch 96, loss: 2.126540\n",
            "Epoch 97, loss: 2.108215\n",
            "Epoch 98, loss: 2.127753\n",
            "Epoch 99, loss: 2.150404\n",
            "Epoch 100, loss: 2.097053\n",
            "Epoch 101, loss: 2.079660\n",
            "Epoch 102, loss: 2.175501\n",
            "Epoch 103, loss: 2.126460\n",
            "Epoch 104, loss: 2.137126\n",
            "Epoch 105, loss: 2.146491\n",
            "Epoch 106, loss: 2.134100\n",
            "Epoch 107, loss: 2.106748\n",
            "Epoch 108, loss: 2.170207\n",
            "Epoch 109, loss: 2.098800\n",
            "Epoch 110, loss: 2.050154\n",
            "Epoch 111, loss: 2.116705\n",
            "Epoch 112, loss: 2.146319\n",
            "Epoch 113, loss: 2.161574\n",
            "Epoch 114, loss: 2.098592\n",
            "Epoch 115, loss: 2.109184\n",
            "Epoch 116, loss: 2.154357\n",
            "Epoch 117, loss: 2.105172\n",
            "Epoch 118, loss: 2.115272\n",
            "Epoch 119, loss: 2.109208\n",
            "Epoch 120, loss: 2.157617\n",
            "Epoch 121, loss: 2.131073\n",
            "Epoch 122, loss: 2.199607\n",
            "Epoch 123, loss: 2.166066\n",
            "Epoch 124, loss: 2.166381\n",
            "Epoch 125, loss: 2.107625\n",
            "Epoch 126, loss: 2.167255\n",
            "Epoch 127, loss: 2.079470\n",
            "Epoch 128, loss: 2.138756\n",
            "Epoch 129, loss: 2.116852\n",
            "Epoch 130, loss: 2.134173\n",
            "Epoch 131, loss: 2.123844\n",
            "Epoch 132, loss: 2.096449\n",
            "Epoch 133, loss: 2.081768\n",
            "Epoch 134, loss: 2.069020\n",
            "Epoch 135, loss: 2.111360\n",
            "Epoch 136, loss: 2.143584\n",
            "Epoch 137, loss: 2.093054\n",
            "Epoch 138, loss: 2.134167\n",
            "Epoch 139, loss: 2.048292\n",
            "Epoch 140, loss: 2.099671\n",
            "Epoch 141, loss: 2.078754\n",
            "Epoch 142, loss: 2.164966\n",
            "Epoch 143, loss: 2.118382\n",
            "Epoch 144, loss: 2.128887\n",
            "Epoch 145, loss: 2.131463\n",
            "Epoch 146, loss: 2.145186\n",
            "Epoch 147, loss: 2.068837\n",
            "Epoch 148, loss: 2.090031\n",
            "Epoch 149, loss: 2.199793\n",
            "Epoch 150, loss: 2.122097\n",
            "Epoch 151, loss: 2.129428\n",
            "Epoch 152, loss: 2.124848\n",
            "Epoch 153, loss: 2.120091\n",
            "Epoch 154, loss: 2.116014\n",
            "Epoch 155, loss: 2.097789\n",
            "Epoch 156, loss: 2.127062\n",
            "Epoch 157, loss: 2.078016\n",
            "Epoch 158, loss: 2.078445\n",
            "Epoch 159, loss: 2.112978\n",
            "Epoch 160, loss: 2.086705\n",
            "Epoch 161, loss: 2.161321\n",
            "Epoch 162, loss: 2.083235\n",
            "Epoch 163, loss: 2.136399\n",
            "Epoch 164, loss: 2.079031\n",
            "Epoch 165, loss: 2.124503\n",
            "Epoch 166, loss: 2.096680\n",
            "Epoch 167, loss: 2.107799\n",
            "Epoch 168, loss: 2.122268\n",
            "Epoch 169, loss: 2.111868\n",
            "Epoch 170, loss: 2.101766\n",
            "Epoch 171, loss: 2.090664\n",
            "Epoch 172, loss: 2.139473\n",
            "Epoch 173, loss: 2.085073\n",
            "Epoch 174, loss: 2.088292\n",
            "Epoch 175, loss: 2.078729\n",
            "Epoch 176, loss: 2.109024\n",
            "Epoch 177, loss: 2.141306\n",
            "Epoch 178, loss: 2.143636\n",
            "Epoch 179, loss: 2.112365\n",
            "Epoch 180, loss: 2.080167\n",
            "Epoch 181, loss: 2.200286\n",
            "Epoch 182, loss: 2.126538\n",
            "Epoch 183, loss: 2.138820\n",
            "Epoch 184, loss: 2.094015\n",
            "Epoch 185, loss: 2.115183\n",
            "Epoch 186, loss: 2.116923\n",
            "Epoch 187, loss: 2.136532\n",
            "Epoch 188, loss: 2.083738\n",
            "Epoch 189, loss: 2.105925\n",
            "Epoch 190, loss: 2.133885\n",
            "Epoch 191, loss: 2.103802\n",
            "Epoch 192, loss: 2.165414\n",
            "Epoch 193, loss: 2.093512\n",
            "Epoch 194, loss: 2.121595\n",
            "Epoch 195, loss: 2.149493\n",
            "Epoch 196, loss: 2.108347\n",
            "Epoch 197, loss: 2.130878\n",
            "Epoch 198, loss: 2.103442\n",
            "Epoch 199, loss: 2.112952\n",
            "Epoch 0, loss: 2.293552\n",
            "Epoch 1, loss: 2.284613\n",
            "Epoch 2, loss: 2.280742\n",
            "Epoch 3, loss: 2.271766\n",
            "Epoch 4, loss: 2.249248\n",
            "Epoch 5, loss: 2.256981\n",
            "Epoch 6, loss: 2.258702\n",
            "Epoch 7, loss: 2.254724\n",
            "Epoch 8, loss: 2.244026\n",
            "Epoch 9, loss: 2.241129\n",
            "Epoch 10, loss: 2.232023\n",
            "Epoch 11, loss: 2.221236\n",
            "Epoch 12, loss: 2.237520\n",
            "Epoch 13, loss: 2.207679\n",
            "Epoch 14, loss: 2.226569\n",
            "Epoch 15, loss: 2.234839\n",
            "Epoch 16, loss: 2.207063\n",
            "Epoch 17, loss: 2.188000\n",
            "Epoch 18, loss: 2.194311\n",
            "Epoch 19, loss: 2.207879\n",
            "Epoch 20, loss: 2.167342\n",
            "Epoch 21, loss: 2.198021\n",
            "Epoch 22, loss: 2.183641\n",
            "Epoch 23, loss: 2.195068\n",
            "Epoch 24, loss: 2.187475\n",
            "Epoch 25, loss: 2.163220\n",
            "Epoch 26, loss: 2.163166\n",
            "Epoch 27, loss: 2.203459\n",
            "Epoch 28, loss: 2.183918\n",
            "Epoch 29, loss: 2.184625\n",
            "Epoch 30, loss: 2.165394\n",
            "Epoch 31, loss: 2.192361\n",
            "Epoch 32, loss: 2.181325\n",
            "Epoch 33, loss: 2.147980\n",
            "Epoch 34, loss: 2.159250\n",
            "Epoch 35, loss: 2.177111\n",
            "Epoch 36, loss: 2.167857\n",
            "Epoch 37, loss: 2.177879\n",
            "Epoch 38, loss: 2.158896\n",
            "Epoch 39, loss: 2.117977\n",
            "Epoch 40, loss: 2.133214\n",
            "Epoch 41, loss: 2.172639\n",
            "Epoch 42, loss: 2.176368\n",
            "Epoch 43, loss: 2.181049\n",
            "Epoch 44, loss: 2.218489\n",
            "Epoch 45, loss: 2.167431\n",
            "Epoch 46, loss: 2.149089\n",
            "Epoch 47, loss: 2.149849\n",
            "Epoch 48, loss: 2.171343\n",
            "Epoch 49, loss: 2.176065\n",
            "Epoch 50, loss: 2.135491\n",
            "Epoch 51, loss: 2.173324\n",
            "Epoch 52, loss: 2.113106\n",
            "Epoch 53, loss: 2.212470\n",
            "Epoch 54, loss: 2.165357\n",
            "Epoch 55, loss: 2.117597\n",
            "Epoch 56, loss: 2.146070\n",
            "Epoch 57, loss: 2.128525\n",
            "Epoch 58, loss: 2.162554\n",
            "Epoch 59, loss: 2.101197\n",
            "Epoch 60, loss: 2.127923\n",
            "Epoch 61, loss: 2.089548\n",
            "Epoch 62, loss: 2.098582\n",
            "Epoch 63, loss: 2.169458\n",
            "Epoch 64, loss: 2.129376\n",
            "Epoch 65, loss: 2.147695\n",
            "Epoch 66, loss: 2.141763\n",
            "Epoch 67, loss: 2.141472\n",
            "Epoch 68, loss: 2.137251\n",
            "Epoch 69, loss: 2.117955\n",
            "Epoch 70, loss: 2.127393\n",
            "Epoch 71, loss: 2.152045\n",
            "Epoch 72, loss: 2.190370\n",
            "Epoch 73, loss: 2.106070\n",
            "Epoch 74, loss: 2.137841\n",
            "Epoch 75, loss: 2.115370\n",
            "Epoch 76, loss: 2.158247\n",
            "Epoch 77, loss: 2.174940\n",
            "Epoch 78, loss: 2.180738\n",
            "Epoch 79, loss: 2.144599\n",
            "Epoch 80, loss: 2.119905\n",
            "Epoch 81, loss: 2.137449\n",
            "Epoch 82, loss: 2.133137\n",
            "Epoch 83, loss: 2.176735\n",
            "Epoch 84, loss: 2.137041\n",
            "Epoch 85, loss: 2.097435\n",
            "Epoch 86, loss: 2.107840\n",
            "Epoch 87, loss: 2.133154\n",
            "Epoch 88, loss: 2.080346\n",
            "Epoch 89, loss: 2.100805\n",
            "Epoch 90, loss: 2.104995\n",
            "Epoch 91, loss: 2.169921\n",
            "Epoch 92, loss: 2.127859\n",
            "Epoch 93, loss: 2.145374\n",
            "Epoch 94, loss: 2.123853\n",
            "Epoch 95, loss: 2.119886\n",
            "Epoch 96, loss: 2.173225\n",
            "Epoch 97, loss: 2.119678\n",
            "Epoch 98, loss: 2.106077\n",
            "Epoch 99, loss: 2.139413\n",
            "Epoch 100, loss: 2.167415\n",
            "Epoch 101, loss: 2.097774\n",
            "Epoch 102, loss: 2.097410\n",
            "Epoch 103, loss: 2.144883\n",
            "Epoch 104, loss: 2.088211\n",
            "Epoch 105, loss: 2.111707\n",
            "Epoch 106, loss: 2.143531\n",
            "Epoch 107, loss: 2.160080\n",
            "Epoch 108, loss: 2.171210\n",
            "Epoch 109, loss: 2.123744\n",
            "Epoch 110, loss: 2.094155\n",
            "Epoch 111, loss: 2.180604\n",
            "Epoch 112, loss: 2.126042\n",
            "Epoch 113, loss: 2.156821\n",
            "Epoch 114, loss: 2.129651\n",
            "Epoch 115, loss: 2.155788\n",
            "Epoch 116, loss: 2.162689\n",
            "Epoch 117, loss: 2.150906\n",
            "Epoch 118, loss: 2.164367\n",
            "Epoch 119, loss: 2.086419\n",
            "Epoch 120, loss: 2.090329\n",
            "Epoch 121, loss: 2.084255\n",
            "Epoch 122, loss: 2.114117\n",
            "Epoch 123, loss: 2.180005\n",
            "Epoch 124, loss: 2.092458\n",
            "Epoch 125, loss: 2.106207\n",
            "Epoch 126, loss: 2.141160\n",
            "Epoch 127, loss: 2.134478\n",
            "Epoch 128, loss: 2.099935\n",
            "Epoch 129, loss: 2.140018\n",
            "Epoch 130, loss: 2.127483\n",
            "Epoch 131, loss: 2.165458\n",
            "Epoch 132, loss: 2.114041\n",
            "Epoch 133, loss: 2.139737\n",
            "Epoch 134, loss: 2.063809\n",
            "Epoch 135, loss: 2.147814\n",
            "Epoch 136, loss: 2.125128\n",
            "Epoch 137, loss: 2.137273\n",
            "Epoch 138, loss: 2.127335\n",
            "Epoch 139, loss: 2.096818\n",
            "Epoch 140, loss: 2.057646\n",
            "Epoch 141, loss: 2.120255\n",
            "Epoch 142, loss: 2.118720\n",
            "Epoch 143, loss: 2.173089\n",
            "Epoch 144, loss: 2.122182\n",
            "Epoch 145, loss: 2.106305\n",
            "Epoch 146, loss: 2.116243\n",
            "Epoch 147, loss: 2.107647\n",
            "Epoch 148, loss: 2.090810\n",
            "Epoch 149, loss: 2.196829\n",
            "Epoch 150, loss: 2.104068\n",
            "Epoch 151, loss: 2.104773\n",
            "Epoch 152, loss: 2.046791\n",
            "Epoch 153, loss: 2.083329\n",
            "Epoch 154, loss: 2.059320\n",
            "Epoch 155, loss: 2.136288\n",
            "Epoch 156, loss: 2.079996\n",
            "Epoch 157, loss: 2.158586\n",
            "Epoch 158, loss: 2.123330\n",
            "Epoch 159, loss: 2.073185\n",
            "Epoch 160, loss: 2.103358\n",
            "Epoch 161, loss: 2.114129\n",
            "Epoch 162, loss: 2.163674\n",
            "Epoch 163, loss: 2.115275\n",
            "Epoch 164, loss: 2.116101\n",
            "Epoch 165, loss: 2.086306\n",
            "Epoch 166, loss: 2.071799\n",
            "Epoch 167, loss: 2.159608\n",
            "Epoch 168, loss: 2.108489\n",
            "Epoch 169, loss: 2.161293\n",
            "Epoch 170, loss: 2.081795\n",
            "Epoch 171, loss: 2.166297\n",
            "Epoch 172, loss: 2.107520\n",
            "Epoch 173, loss: 2.102632\n",
            "Epoch 174, loss: 2.107954\n",
            "Epoch 175, loss: 2.127759\n",
            "Epoch 176, loss: 2.106994\n",
            "Epoch 177, loss: 2.092725\n",
            "Epoch 178, loss: 2.123613\n",
            "Epoch 179, loss: 2.098377\n",
            "Epoch 180, loss: 2.131900\n",
            "Epoch 181, loss: 2.119529\n",
            "Epoch 182, loss: 2.084154\n",
            "Epoch 183, loss: 2.158736\n",
            "Epoch 184, loss: 2.099124\n",
            "Epoch 185, loss: 2.070711\n",
            "Epoch 186, loss: 2.099188\n",
            "Epoch 187, loss: 2.083350\n",
            "Epoch 188, loss: 2.102835\n",
            "Epoch 189, loss: 2.187735\n",
            "Epoch 190, loss: 2.109804\n",
            "Epoch 191, loss: 2.079479\n",
            "Epoch 192, loss: 2.125772\n",
            "Epoch 193, loss: 2.095641\n",
            "Epoch 194, loss: 2.082516\n",
            "Epoch 195, loss: 2.058414\n",
            "Epoch 196, loss: 2.134852\n",
            "Epoch 197, loss: 2.079386\n",
            "Epoch 198, loss: 2.116531\n",
            "Epoch 199, loss: 2.116317\n",
            "Epoch 0, loss: 2.295162\n",
            "Epoch 1, loss: 2.288131\n",
            "Epoch 2, loss: 2.276783\n",
            "Epoch 3, loss: 2.276352\n",
            "Epoch 4, loss: 2.261873\n",
            "Epoch 5, loss: 2.268888\n",
            "Epoch 6, loss: 2.250294\n",
            "Epoch 7, loss: 2.259803\n",
            "Epoch 8, loss: 2.244480\n",
            "Epoch 9, loss: 2.257043\n",
            "Epoch 10, loss: 2.237057\n",
            "Epoch 11, loss: 2.232988\n",
            "Epoch 12, loss: 2.218044\n",
            "Epoch 13, loss: 2.228404\n",
            "Epoch 14, loss: 2.210462\n",
            "Epoch 15, loss: 2.221769\n",
            "Epoch 16, loss: 2.189055\n",
            "Epoch 17, loss: 2.223759\n",
            "Epoch 18, loss: 2.224288\n",
            "Epoch 19, loss: 2.192189\n",
            "Epoch 20, loss: 2.215082\n",
            "Epoch 21, loss: 2.207020\n",
            "Epoch 22, loss: 2.174012\n",
            "Epoch 23, loss: 2.198805\n",
            "Epoch 24, loss: 2.184188\n",
            "Epoch 25, loss: 2.205680\n",
            "Epoch 26, loss: 2.180853\n",
            "Epoch 27, loss: 2.194163\n",
            "Epoch 28, loss: 2.185368\n",
            "Epoch 29, loss: 2.188920\n",
            "Epoch 30, loss: 2.200329\n",
            "Epoch 31, loss: 2.187973\n",
            "Epoch 32, loss: 2.180029\n",
            "Epoch 33, loss: 2.139371\n",
            "Epoch 34, loss: 2.217298\n",
            "Epoch 35, loss: 2.174399\n",
            "Epoch 36, loss: 2.164115\n",
            "Epoch 37, loss: 2.171578\n",
            "Epoch 38, loss: 2.196850\n",
            "Epoch 39, loss: 2.152639\n",
            "Epoch 40, loss: 2.184909\n",
            "Epoch 41, loss: 2.172119\n",
            "Epoch 42, loss: 2.162672\n",
            "Epoch 43, loss: 2.173129\n",
            "Epoch 44, loss: 2.129645\n",
            "Epoch 45, loss: 2.185903\n",
            "Epoch 46, loss: 2.199127\n",
            "Epoch 47, loss: 2.127098\n",
            "Epoch 48, loss: 2.179060\n",
            "Epoch 49, loss: 2.160719\n",
            "Epoch 50, loss: 2.196747\n",
            "Epoch 51, loss: 2.171248\n",
            "Epoch 52, loss: 2.124787\n",
            "Epoch 53, loss: 2.181024\n",
            "Epoch 54, loss: 2.178027\n",
            "Epoch 55, loss: 2.141905\n",
            "Epoch 56, loss: 2.135850\n",
            "Epoch 57, loss: 2.154355\n",
            "Epoch 58, loss: 2.182505\n",
            "Epoch 59, loss: 2.110547\n",
            "Epoch 60, loss: 2.110828\n",
            "Epoch 61, loss: 2.144285\n",
            "Epoch 62, loss: 2.154810\n",
            "Epoch 63, loss: 2.135516\n",
            "Epoch 64, loss: 2.164710\n",
            "Epoch 65, loss: 2.096857\n",
            "Epoch 66, loss: 2.140583\n",
            "Epoch 67, loss: 2.161913\n",
            "Epoch 68, loss: 2.187331\n",
            "Epoch 69, loss: 2.156772\n",
            "Epoch 70, loss: 2.195603\n",
            "Epoch 71, loss: 2.169247\n",
            "Epoch 72, loss: 2.169276\n",
            "Epoch 73, loss: 2.113909\n",
            "Epoch 74, loss: 2.187554\n",
            "Epoch 75, loss: 2.172508\n",
            "Epoch 76, loss: 2.125452\n",
            "Epoch 77, loss: 2.164579\n",
            "Epoch 78, loss: 2.134260\n",
            "Epoch 79, loss: 2.131383\n",
            "Epoch 80, loss: 2.132768\n",
            "Epoch 81, loss: 2.137053\n",
            "Epoch 82, loss: 2.158486\n",
            "Epoch 83, loss: 2.115025\n",
            "Epoch 84, loss: 2.093247\n",
            "Epoch 85, loss: 2.161732\n",
            "Epoch 86, loss: 2.112830\n",
            "Epoch 87, loss: 2.137611\n",
            "Epoch 88, loss: 2.150153\n",
            "Epoch 89, loss: 2.090456\n",
            "Epoch 90, loss: 2.133494\n",
            "Epoch 91, loss: 2.106815\n",
            "Epoch 92, loss: 2.151875\n",
            "Epoch 93, loss: 2.119733\n",
            "Epoch 94, loss: 2.098631\n",
            "Epoch 95, loss: 2.139091\n",
            "Epoch 96, loss: 2.148017\n",
            "Epoch 97, loss: 2.152305\n",
            "Epoch 98, loss: 2.096500\n",
            "Epoch 99, loss: 2.140345\n",
            "Epoch 100, loss: 2.084382\n",
            "Epoch 101, loss: 2.106731\n",
            "Epoch 102, loss: 2.111469\n",
            "Epoch 103, loss: 2.178401\n",
            "Epoch 104, loss: 2.141327\n",
            "Epoch 105, loss: 2.157937\n",
            "Epoch 106, loss: 2.089359\n",
            "Epoch 107, loss: 2.139158\n",
            "Epoch 108, loss: 2.163786\n",
            "Epoch 109, loss: 2.079898\n",
            "Epoch 110, loss: 2.075342\n",
            "Epoch 111, loss: 2.129666\n",
            "Epoch 112, loss: 2.139184\n",
            "Epoch 113, loss: 2.108281\n",
            "Epoch 114, loss: 2.086478\n",
            "Epoch 115, loss: 2.099649\n",
            "Epoch 116, loss: 2.050566\n",
            "Epoch 117, loss: 2.079411\n",
            "Epoch 118, loss: 2.130663\n",
            "Epoch 119, loss: 2.101546\n",
            "Epoch 120, loss: 2.172794\n",
            "Epoch 121, loss: 2.116923\n",
            "Epoch 122, loss: 2.137973\n",
            "Epoch 123, loss: 2.087269\n",
            "Epoch 124, loss: 2.074694\n",
            "Epoch 125, loss: 2.093580\n",
            "Epoch 126, loss: 2.147383\n",
            "Epoch 127, loss: 2.146819\n",
            "Epoch 128, loss: 2.075134\n",
            "Epoch 129, loss: 2.085486\n",
            "Epoch 130, loss: 2.122889\n",
            "Epoch 131, loss: 2.099702\n",
            "Epoch 132, loss: 2.111890\n",
            "Epoch 133, loss: 2.132576\n",
            "Epoch 134, loss: 2.166523\n",
            "Epoch 135, loss: 2.111446\n",
            "Epoch 136, loss: 2.112034\n",
            "Epoch 137, loss: 2.098046\n",
            "Epoch 138, loss: 2.070585\n",
            "Epoch 139, loss: 2.097275\n",
            "Epoch 140, loss: 2.114253\n",
            "Epoch 141, loss: 2.069927\n",
            "Epoch 142, loss: 2.103519\n",
            "Epoch 143, loss: 2.088297\n",
            "Epoch 144, loss: 2.084957\n",
            "Epoch 145, loss: 2.147421\n",
            "Epoch 146, loss: 2.085479\n",
            "Epoch 147, loss: 2.089889\n",
            "Epoch 148, loss: 2.138209\n",
            "Epoch 149, loss: 2.100107\n",
            "Epoch 150, loss: 2.108264\n",
            "Epoch 151, loss: 2.166159\n",
            "Epoch 152, loss: 2.126373\n",
            "Epoch 153, loss: 2.148160\n",
            "Epoch 154, loss: 2.102892\n",
            "Epoch 155, loss: 2.148943\n",
            "Epoch 156, loss: 2.115309\n",
            "Epoch 157, loss: 2.105790\n",
            "Epoch 158, loss: 2.127105\n",
            "Epoch 159, loss: 2.104038\n",
            "Epoch 160, loss: 2.125127\n",
            "Epoch 161, loss: 2.125210\n",
            "Epoch 162, loss: 2.118871\n",
            "Epoch 163, loss: 2.149906\n",
            "Epoch 164, loss: 2.097403\n",
            "Epoch 165, loss: 2.188776\n",
            "Epoch 166, loss: 2.117419\n",
            "Epoch 167, loss: 2.061724\n",
            "Epoch 168, loss: 2.082053\n",
            "Epoch 169, loss: 2.088094\n",
            "Epoch 170, loss: 2.095430\n",
            "Epoch 171, loss: 2.063201\n",
            "Epoch 172, loss: 2.026660\n",
            "Epoch 173, loss: 2.091152\n",
            "Epoch 174, loss: 2.109569\n",
            "Epoch 175, loss: 2.105889\n",
            "Epoch 176, loss: 2.094932\n",
            "Epoch 177, loss: 2.086706\n",
            "Epoch 178, loss: 2.078958\n",
            "Epoch 179, loss: 2.135566\n",
            "Epoch 180, loss: 2.080407\n",
            "Epoch 181, loss: 2.104233\n",
            "Epoch 182, loss: 2.089458\n",
            "Epoch 183, loss: 2.108239\n",
            "Epoch 184, loss: 2.139802\n",
            "Epoch 185, loss: 2.059451\n",
            "Epoch 186, loss: 2.137587\n",
            "Epoch 187, loss: 2.096309\n",
            "Epoch 188, loss: 2.135933\n",
            "Epoch 189, loss: 2.052988\n",
            "Epoch 190, loss: 2.129646\n",
            "Epoch 191, loss: 2.046185\n",
            "Epoch 192, loss: 2.085791\n",
            "Epoch 193, loss: 2.035766\n",
            "Epoch 194, loss: 2.111729\n",
            "Epoch 195, loss: 2.110307\n",
            "Epoch 196, loss: 2.132223\n",
            "Epoch 197, loss: 2.065854\n",
            "Epoch 198, loss: 2.076137\n",
            "Epoch 199, loss: 2.088880\n",
            "Epoch 0, loss: 2.293171\n",
            "Epoch 1, loss: 2.283920\n",
            "Epoch 2, loss: 2.272494\n",
            "Epoch 3, loss: 2.275993\n",
            "Epoch 4, loss: 2.267246\n",
            "Epoch 5, loss: 2.259464\n",
            "Epoch 6, loss: 2.253912\n",
            "Epoch 7, loss: 2.242591\n",
            "Epoch 8, loss: 2.255518\n",
            "Epoch 9, loss: 2.240556\n",
            "Epoch 10, loss: 2.225907\n",
            "Epoch 11, loss: 2.239609\n",
            "Epoch 12, loss: 2.227914\n",
            "Epoch 13, loss: 2.225627\n",
            "Epoch 14, loss: 2.230338\n",
            "Epoch 15, loss: 2.213717\n",
            "Epoch 16, loss: 2.199500\n",
            "Epoch 17, loss: 2.211817\n",
            "Epoch 18, loss: 2.207138\n",
            "Epoch 19, loss: 2.213248\n",
            "Epoch 20, loss: 2.210648\n",
            "Epoch 21, loss: 2.181029\n",
            "Epoch 22, loss: 2.201295\n",
            "Epoch 23, loss: 2.201287\n",
            "Epoch 24, loss: 2.199155\n",
            "Epoch 25, loss: 2.205780\n",
            "Epoch 26, loss: 2.147475\n",
            "Epoch 27, loss: 2.188131\n",
            "Epoch 28, loss: 2.191277\n",
            "Epoch 29, loss: 2.207309\n",
            "Epoch 30, loss: 2.182032\n",
            "Epoch 31, loss: 2.196757\n",
            "Epoch 32, loss: 2.159016\n",
            "Epoch 33, loss: 2.205189\n",
            "Epoch 34, loss: 2.218404\n",
            "Epoch 35, loss: 2.173683\n",
            "Epoch 36, loss: 2.192670\n",
            "Epoch 37, loss: 2.205563\n",
            "Epoch 38, loss: 2.197652\n",
            "Epoch 39, loss: 2.226358\n",
            "Epoch 40, loss: 2.174581\n",
            "Epoch 41, loss: 2.182118\n",
            "Epoch 42, loss: 2.194780\n",
            "Epoch 43, loss: 2.177673\n",
            "Epoch 44, loss: 2.190080\n",
            "Epoch 45, loss: 2.172874\n",
            "Epoch 46, loss: 2.124575\n",
            "Epoch 47, loss: 2.207152\n",
            "Epoch 48, loss: 2.141234\n",
            "Epoch 49, loss: 2.168772\n",
            "Epoch 50, loss: 2.145680\n",
            "Epoch 51, loss: 2.131919\n",
            "Epoch 52, loss: 2.149701\n",
            "Epoch 53, loss: 2.129725\n",
            "Epoch 54, loss: 2.146747\n",
            "Epoch 55, loss: 2.147473\n",
            "Epoch 56, loss: 2.147923\n",
            "Epoch 57, loss: 2.174641\n",
            "Epoch 58, loss: 2.105957\n",
            "Epoch 59, loss: 2.184089\n",
            "Epoch 60, loss: 2.145530\n",
            "Epoch 61, loss: 2.123067\n",
            "Epoch 62, loss: 2.108629\n",
            "Epoch 63, loss: 2.164171\n",
            "Epoch 64, loss: 2.142128\n",
            "Epoch 65, loss: 2.145571\n",
            "Epoch 66, loss: 2.157039\n",
            "Epoch 67, loss: 2.143495\n",
            "Epoch 68, loss: 2.171091\n",
            "Epoch 69, loss: 2.138184\n",
            "Epoch 70, loss: 2.156118\n",
            "Epoch 71, loss: 2.134171\n",
            "Epoch 72, loss: 2.196094\n",
            "Epoch 73, loss: 2.131293\n",
            "Epoch 74, loss: 2.138830\n",
            "Epoch 75, loss: 2.124270\n",
            "Epoch 76, loss: 2.152271\n",
            "Epoch 77, loss: 2.154400\n",
            "Epoch 78, loss: 2.129708\n",
            "Epoch 79, loss: 2.165867\n",
            "Epoch 80, loss: 2.147157\n",
            "Epoch 81, loss: 2.100408\n",
            "Epoch 82, loss: 2.162234\n",
            "Epoch 83, loss: 2.174782\n",
            "Epoch 84, loss: 2.125342\n",
            "Epoch 85, loss: 2.134500\n",
            "Epoch 86, loss: 2.145632\n",
            "Epoch 87, loss: 2.118828\n",
            "Epoch 88, loss: 2.167838\n",
            "Epoch 89, loss: 2.176840\n",
            "Epoch 90, loss: 2.126646\n",
            "Epoch 91, loss: 2.124063\n",
            "Epoch 92, loss: 2.169306\n",
            "Epoch 93, loss: 2.153796\n",
            "Epoch 94, loss: 2.128135\n",
            "Epoch 95, loss: 2.115233\n",
            "Epoch 96, loss: 2.121002\n",
            "Epoch 97, loss: 2.133313\n",
            "Epoch 98, loss: 2.173244\n",
            "Epoch 99, loss: 2.141019\n",
            "Epoch 100, loss: 2.109439\n",
            "Epoch 101, loss: 2.117693\n",
            "Epoch 102, loss: 2.120569\n",
            "Epoch 103, loss: 2.153218\n",
            "Epoch 104, loss: 2.111037\n",
            "Epoch 105, loss: 2.133989\n",
            "Epoch 106, loss: 2.115370\n",
            "Epoch 107, loss: 2.122148\n",
            "Epoch 108, loss: 2.120801\n",
            "Epoch 109, loss: 2.146243\n",
            "Epoch 110, loss: 2.124688\n",
            "Epoch 111, loss: 2.157253\n",
            "Epoch 112, loss: 2.096641\n",
            "Epoch 113, loss: 2.153185\n",
            "Epoch 114, loss: 2.103625\n",
            "Epoch 115, loss: 2.166176\n",
            "Epoch 116, loss: 2.102759\n",
            "Epoch 117, loss: 2.184621\n",
            "Epoch 118, loss: 2.114238\n",
            "Epoch 119, loss: 2.124775\n",
            "Epoch 120, loss: 2.122838\n",
            "Epoch 121, loss: 2.113965\n",
            "Epoch 122, loss: 2.133173\n",
            "Epoch 123, loss: 2.156822\n",
            "Epoch 124, loss: 2.145211\n",
            "Epoch 125, loss: 2.139545\n",
            "Epoch 126, loss: 2.126790\n",
            "Epoch 127, loss: 2.135452\n",
            "Epoch 128, loss: 2.106474\n",
            "Epoch 129, loss: 2.177206\n",
            "Epoch 130, loss: 2.092600\n",
            "Epoch 131, loss: 2.091405\n",
            "Epoch 132, loss: 2.059303\n",
            "Epoch 133, loss: 2.104203\n",
            "Epoch 134, loss: 2.124755\n",
            "Epoch 135, loss: 2.118586\n",
            "Epoch 136, loss: 2.113545\n",
            "Epoch 137, loss: 2.087115\n",
            "Epoch 138, loss: 2.060378\n",
            "Epoch 139, loss: 2.122765\n",
            "Epoch 140, loss: 2.091683\n",
            "Epoch 141, loss: 2.229612\n",
            "Epoch 142, loss: 2.131964\n",
            "Epoch 143, loss: 2.125151\n",
            "Epoch 144, loss: 2.167314\n",
            "Epoch 145, loss: 2.150854\n",
            "Epoch 146, loss: 2.103729\n",
            "Epoch 147, loss: 2.121431\n",
            "Epoch 148, loss: 2.107879\n",
            "Epoch 149, loss: 2.149220\n",
            "Epoch 150, loss: 2.124711\n",
            "Epoch 151, loss: 2.164366\n",
            "Epoch 152, loss: 2.120581\n",
            "Epoch 153, loss: 2.073247\n",
            "Epoch 154, loss: 2.120958\n",
            "Epoch 155, loss: 2.155959\n",
            "Epoch 156, loss: 2.135963\n",
            "Epoch 157, loss: 2.150566\n",
            "Epoch 158, loss: 2.140880\n",
            "Epoch 159, loss: 2.061271\n",
            "Epoch 160, loss: 2.093410\n",
            "Epoch 161, loss: 2.110605\n",
            "Epoch 162, loss: 2.120917\n",
            "Epoch 163, loss: 2.128790\n",
            "Epoch 164, loss: 2.048527\n",
            "Epoch 165, loss: 2.108108\n",
            "Epoch 166, loss: 2.105736\n",
            "Epoch 167, loss: 2.137258\n",
            "Epoch 168, loss: 2.139326\n",
            "Epoch 169, loss: 2.088435\n",
            "Epoch 170, loss: 2.071941\n",
            "Epoch 171, loss: 2.076904\n",
            "Epoch 172, loss: 2.154905\n",
            "Epoch 173, loss: 2.049065\n",
            "Epoch 174, loss: 2.118804\n",
            "Epoch 175, loss: 2.096812\n",
            "Epoch 176, loss: 2.082118\n",
            "Epoch 177, loss: 2.157088\n",
            "Epoch 178, loss: 2.105565\n",
            "Epoch 179, loss: 2.154329\n",
            "Epoch 180, loss: 2.178286\n",
            "Epoch 181, loss: 2.123906\n",
            "Epoch 182, loss: 2.077720\n",
            "Epoch 183, loss: 2.079475\n",
            "Epoch 184, loss: 2.118197\n",
            "Epoch 185, loss: 2.146136\n",
            "Epoch 186, loss: 2.128503\n",
            "Epoch 187, loss: 2.063520\n",
            "Epoch 188, loss: 2.080489\n",
            "Epoch 189, loss: 2.088451\n",
            "Epoch 190, loss: 2.092941\n",
            "Epoch 191, loss: 2.036933\n",
            "Epoch 192, loss: 2.106051\n",
            "Epoch 193, loss: 2.116605\n",
            "Epoch 194, loss: 2.098637\n",
            "Epoch 195, loss: 2.151310\n",
            "Epoch 196, loss: 2.062896\n",
            "Epoch 197, loss: 2.080213\n",
            "Epoch 198, loss: 2.087710\n",
            "Epoch 199, loss: 2.096755\n",
            "Epoch 0, loss: 2.298321\n",
            "Epoch 1, loss: 2.287394\n",
            "Epoch 2, loss: 2.287983\n",
            "Epoch 3, loss: 2.276560\n",
            "Epoch 4, loss: 2.269373\n",
            "Epoch 5, loss: 2.257593\n",
            "Epoch 6, loss: 2.248942\n",
            "Epoch 7, loss: 2.249846\n",
            "Epoch 8, loss: 2.262509\n",
            "Epoch 9, loss: 2.229682\n",
            "Epoch 10, loss: 2.215937\n",
            "Epoch 11, loss: 2.241685\n",
            "Epoch 12, loss: 2.229307\n",
            "Epoch 13, loss: 2.220060\n",
            "Epoch 14, loss: 2.214200\n",
            "Epoch 15, loss: 2.219327\n",
            "Epoch 16, loss: 2.211587\n",
            "Epoch 17, loss: 2.177368\n",
            "Epoch 18, loss: 2.205520\n",
            "Epoch 19, loss: 2.221186\n",
            "Epoch 20, loss: 2.211075\n",
            "Epoch 21, loss: 2.181483\n",
            "Epoch 22, loss: 2.164135\n",
            "Epoch 23, loss: 2.160452\n",
            "Epoch 24, loss: 2.173819\n",
            "Epoch 25, loss: 2.197240\n",
            "Epoch 26, loss: 2.223485\n",
            "Epoch 27, loss: 2.228738\n",
            "Epoch 28, loss: 2.176093\n",
            "Epoch 29, loss: 2.203196\n",
            "Epoch 30, loss: 2.147471\n",
            "Epoch 31, loss: 2.171966\n",
            "Epoch 32, loss: 2.186913\n",
            "Epoch 33, loss: 2.211653\n",
            "Epoch 34, loss: 2.195583\n",
            "Epoch 35, loss: 2.179596\n",
            "Epoch 36, loss: 2.181565\n",
            "Epoch 37, loss: 2.186450\n",
            "Epoch 38, loss: 2.166201\n",
            "Epoch 39, loss: 2.152580\n",
            "Epoch 40, loss: 2.175564\n",
            "Epoch 41, loss: 2.143937\n",
            "Epoch 42, loss: 2.149065\n",
            "Epoch 43, loss: 2.169761\n",
            "Epoch 44, loss: 2.118464\n",
            "Epoch 45, loss: 2.180318\n",
            "Epoch 46, loss: 2.147059\n",
            "Epoch 47, loss: 2.184029\n",
            "Epoch 48, loss: 2.175458\n",
            "Epoch 49, loss: 2.116687\n",
            "Epoch 50, loss: 2.186146\n",
            "Epoch 51, loss: 2.152319\n",
            "Epoch 52, loss: 2.139215\n",
            "Epoch 53, loss: 2.138552\n",
            "Epoch 54, loss: 2.167644\n",
            "Epoch 55, loss: 2.178935\n",
            "Epoch 56, loss: 2.138058\n",
            "Epoch 57, loss: 2.146076\n",
            "Epoch 58, loss: 2.071735\n",
            "Epoch 59, loss: 2.190944\n",
            "Epoch 60, loss: 2.150718\n",
            "Epoch 61, loss: 2.135030\n",
            "Epoch 62, loss: 2.104608\n",
            "Epoch 63, loss: 2.170019\n",
            "Epoch 64, loss: 2.111635\n",
            "Epoch 65, loss: 2.146853\n",
            "Epoch 66, loss: 2.175340\n",
            "Epoch 67, loss: 2.106845\n",
            "Epoch 68, loss: 2.154536\n",
            "Epoch 69, loss: 2.204015\n",
            "Epoch 70, loss: 2.142088\n",
            "Epoch 71, loss: 2.158175\n",
            "Epoch 72, loss: 2.155940\n",
            "Epoch 73, loss: 2.165191\n",
            "Epoch 74, loss: 2.177060\n",
            "Epoch 75, loss: 2.170453\n",
            "Epoch 76, loss: 2.155429\n",
            "Epoch 77, loss: 2.187517\n",
            "Epoch 78, loss: 2.167043\n",
            "Epoch 79, loss: 2.134786\n",
            "Epoch 80, loss: 2.089542\n",
            "Epoch 81, loss: 2.104882\n",
            "Epoch 82, loss: 2.125874\n",
            "Epoch 83, loss: 2.095252\n",
            "Epoch 84, loss: 2.177148\n",
            "Epoch 85, loss: 2.195373\n",
            "Epoch 86, loss: 2.093021\n",
            "Epoch 87, loss: 2.134546\n",
            "Epoch 88, loss: 2.125696\n",
            "Epoch 89, loss: 2.171007\n",
            "Epoch 90, loss: 2.132726\n",
            "Epoch 91, loss: 2.092242\n",
            "Epoch 92, loss: 2.094877\n",
            "Epoch 93, loss: 2.089227\n",
            "Epoch 94, loss: 2.118617\n",
            "Epoch 95, loss: 2.127768\n",
            "Epoch 96, loss: 2.171159\n",
            "Epoch 97, loss: 2.119406\n",
            "Epoch 98, loss: 2.107769\n",
            "Epoch 99, loss: 2.097166\n",
            "Epoch 100, loss: 2.137047\n",
            "Epoch 101, loss: 2.131940\n",
            "Epoch 102, loss: 2.138392\n",
            "Epoch 103, loss: 2.121513\n",
            "Epoch 104, loss: 2.094761\n",
            "Epoch 105, loss: 2.144882\n",
            "Epoch 106, loss: 2.123904\n",
            "Epoch 107, loss: 2.183835\n",
            "Epoch 108, loss: 2.191518\n",
            "Epoch 109, loss: 2.134597\n",
            "Epoch 110, loss: 2.096079\n",
            "Epoch 111, loss: 2.109452\n",
            "Epoch 112, loss: 2.089043\n",
            "Epoch 113, loss: 2.091133\n",
            "Epoch 114, loss: 2.155497\n",
            "Epoch 115, loss: 2.065155\n",
            "Epoch 116, loss: 2.152213\n",
            "Epoch 117, loss: 2.139739\n",
            "Epoch 118, loss: 2.172128\n",
            "Epoch 119, loss: 2.137423\n",
            "Epoch 120, loss: 2.134076\n",
            "Epoch 121, loss: 2.140920\n",
            "Epoch 122, loss: 2.098357\n",
            "Epoch 123, loss: 2.092538\n",
            "Epoch 124, loss: 2.066239\n",
            "Epoch 125, loss: 2.147973\n",
            "Epoch 126, loss: 2.112119\n",
            "Epoch 127, loss: 2.124039\n",
            "Epoch 128, loss: 2.100731\n",
            "Epoch 129, loss: 2.111720\n",
            "Epoch 130, loss: 2.099250\n",
            "Epoch 131, loss: 2.095163\n",
            "Epoch 132, loss: 2.148266\n",
            "Epoch 133, loss: 2.098597\n",
            "Epoch 134, loss: 2.084969\n",
            "Epoch 135, loss: 2.193401\n",
            "Epoch 136, loss: 2.115707\n",
            "Epoch 137, loss: 2.156442\n",
            "Epoch 138, loss: 2.137136\n",
            "Epoch 139, loss: 2.144846\n",
            "Epoch 140, loss: 2.149139\n",
            "Epoch 141, loss: 2.076273\n",
            "Epoch 142, loss: 2.111387\n",
            "Epoch 143, loss: 2.162187\n",
            "Epoch 144, loss: 2.125978\n",
            "Epoch 145, loss: 2.085754\n",
            "Epoch 146, loss: 2.099779\n",
            "Epoch 147, loss: 2.065700\n",
            "Epoch 148, loss: 2.214440\n",
            "Epoch 149, loss: 2.078837\n",
            "Epoch 150, loss: 2.094100\n",
            "Epoch 151, loss: 2.095307\n",
            "Epoch 152, loss: 2.125483\n",
            "Epoch 153, loss: 2.117061\n",
            "Epoch 154, loss: 2.092476\n",
            "Epoch 155, loss: 2.171839\n",
            "Epoch 156, loss: 2.104920\n",
            "Epoch 157, loss: 2.143247\n",
            "Epoch 158, loss: 2.148784\n",
            "Epoch 159, loss: 2.114492\n",
            "Epoch 160, loss: 2.169193\n",
            "Epoch 161, loss: 2.084320\n",
            "Epoch 162, loss: 2.142922\n",
            "Epoch 163, loss: 2.087450\n",
            "Epoch 164, loss: 2.095453\n",
            "Epoch 165, loss: 2.149317\n",
            "Epoch 166, loss: 2.102288\n",
            "Epoch 167, loss: 2.051926\n",
            "Epoch 168, loss: 2.156560\n",
            "Epoch 169, loss: 2.177710\n",
            "Epoch 170, loss: 2.035093\n",
            "Epoch 171, loss: 2.134622\n",
            "Epoch 172, loss: 2.078784\n",
            "Epoch 173, loss: 2.120443\n",
            "Epoch 174, loss: 2.076870\n",
            "Epoch 175, loss: 2.123876\n",
            "Epoch 176, loss: 2.153949\n",
            "Epoch 177, loss: 2.115718\n",
            "Epoch 178, loss: 2.142573\n",
            "Epoch 179, loss: 2.134465\n",
            "Epoch 180, loss: 2.105166\n",
            "Epoch 181, loss: 2.086208\n",
            "Epoch 182, loss: 2.081947\n",
            "Epoch 183, loss: 2.075426\n",
            "Epoch 184, loss: 2.136837\n",
            "Epoch 185, loss: 2.100560\n",
            "Epoch 186, loss: 2.048962\n",
            "Epoch 187, loss: 2.039913\n",
            "Epoch 188, loss: 2.108585\n",
            "Epoch 189, loss: 2.143509\n",
            "Epoch 190, loss: 2.088197\n",
            "Epoch 191, loss: 2.060375\n",
            "Epoch 192, loss: 2.078710\n",
            "Epoch 193, loss: 2.073443\n",
            "Epoch 194, loss: 2.130768\n",
            "Epoch 195, loss: 2.104617\n",
            "Epoch 196, loss: 2.105287\n",
            "Epoch 197, loss: 2.141090\n",
            "Epoch 198, loss: 2.088365\n",
            "Epoch 199, loss: 2.111624\n",
            "Epoch 0, loss: 2.302168\n",
            "Epoch 1, loss: 2.302035\n",
            "Epoch 2, loss: 2.297530\n",
            "Epoch 3, loss: 2.298743\n",
            "Epoch 4, loss: 2.299085\n",
            "Epoch 5, loss: 2.295200\n",
            "Epoch 6, loss: 2.297926\n",
            "Epoch 7, loss: 2.296786\n",
            "Epoch 8, loss: 2.292315\n",
            "Epoch 9, loss: 2.289779\n",
            "Epoch 10, loss: 2.293043\n",
            "Epoch 11, loss: 2.290500\n",
            "Epoch 12, loss: 2.292346\n",
            "Epoch 13, loss: 2.288475\n",
            "Epoch 14, loss: 2.285135\n",
            "Epoch 15, loss: 2.287510\n",
            "Epoch 16, loss: 2.290693\n",
            "Epoch 17, loss: 2.292552\n",
            "Epoch 18, loss: 2.284381\n",
            "Epoch 19, loss: 2.291240\n",
            "Epoch 20, loss: 2.282663\n",
            "Epoch 21, loss: 2.284818\n",
            "Epoch 22, loss: 2.282845\n",
            "Epoch 23, loss: 2.281458\n",
            "Epoch 24, loss: 2.280996\n",
            "Epoch 25, loss: 2.282931\n",
            "Epoch 26, loss: 2.274164\n",
            "Epoch 27, loss: 2.274696\n",
            "Epoch 28, loss: 2.278759\n",
            "Epoch 29, loss: 2.275172\n",
            "Epoch 30, loss: 2.280055\n",
            "Epoch 31, loss: 2.269356\n",
            "Epoch 32, loss: 2.271275\n",
            "Epoch 33, loss: 2.274691\n",
            "Epoch 34, loss: 2.276244\n",
            "Epoch 35, loss: 2.269561\n",
            "Epoch 36, loss: 2.274829\n",
            "Epoch 37, loss: 2.264683\n",
            "Epoch 38, loss: 2.279230\n",
            "Epoch 39, loss: 2.269418\n",
            "Epoch 40, loss: 2.279840\n",
            "Epoch 41, loss: 2.261980\n",
            "Epoch 42, loss: 2.268272\n",
            "Epoch 43, loss: 2.273762\n",
            "Epoch 44, loss: 2.270131\n",
            "Epoch 45, loss: 2.275663\n",
            "Epoch 46, loss: 2.267024\n",
            "Epoch 47, loss: 2.270957\n",
            "Epoch 48, loss: 2.262422\n",
            "Epoch 49, loss: 2.269108\n",
            "Epoch 50, loss: 2.256872\n",
            "Epoch 51, loss: 2.265063\n",
            "Epoch 52, loss: 2.265769\n",
            "Epoch 53, loss: 2.256715\n",
            "Epoch 54, loss: 2.266812\n",
            "Epoch 55, loss: 2.255994\n",
            "Epoch 56, loss: 2.266415\n",
            "Epoch 57, loss: 2.265597\n",
            "Epoch 58, loss: 2.263587\n",
            "Epoch 59, loss: 2.264157\n",
            "Epoch 60, loss: 2.259447\n",
            "Epoch 61, loss: 2.258276\n",
            "Epoch 62, loss: 2.256234\n",
            "Epoch 63, loss: 2.256161\n",
            "Epoch 64, loss: 2.264557\n",
            "Epoch 65, loss: 2.262138\n",
            "Epoch 66, loss: 2.261850\n",
            "Epoch 67, loss: 2.257953\n",
            "Epoch 68, loss: 2.255726\n",
            "Epoch 69, loss: 2.247676\n",
            "Epoch 70, loss: 2.260172\n",
            "Epoch 71, loss: 2.248795\n",
            "Epoch 72, loss: 2.230619\n",
            "Epoch 73, loss: 2.243244\n",
            "Epoch 74, loss: 2.258821\n",
            "Epoch 75, loss: 2.247833\n",
            "Epoch 76, loss: 2.243959\n",
            "Epoch 77, loss: 2.246399\n",
            "Epoch 78, loss: 2.253533\n",
            "Epoch 79, loss: 2.247430\n",
            "Epoch 80, loss: 2.240069\n",
            "Epoch 81, loss: 2.245454\n",
            "Epoch 82, loss: 2.245882\n",
            "Epoch 83, loss: 2.238242\n",
            "Epoch 84, loss: 2.260726\n",
            "Epoch 85, loss: 2.244354\n",
            "Epoch 86, loss: 2.245812\n",
            "Epoch 87, loss: 2.249628\n",
            "Epoch 88, loss: 2.240330\n",
            "Epoch 89, loss: 2.253225\n",
            "Epoch 90, loss: 2.249738\n",
            "Epoch 91, loss: 2.245664\n",
            "Epoch 92, loss: 2.235286\n",
            "Epoch 93, loss: 2.235437\n",
            "Epoch 94, loss: 2.221098\n",
            "Epoch 95, loss: 2.251570\n",
            "Epoch 96, loss: 2.237537\n",
            "Epoch 97, loss: 2.251368\n",
            "Epoch 98, loss: 2.223135\n",
            "Epoch 99, loss: 2.237157\n",
            "Epoch 100, loss: 2.250965\n",
            "Epoch 101, loss: 2.221126\n",
            "Epoch 102, loss: 2.236605\n",
            "Epoch 103, loss: 2.226350\n",
            "Epoch 104, loss: 2.233899\n",
            "Epoch 105, loss: 2.213200\n",
            "Epoch 106, loss: 2.247700\n",
            "Epoch 107, loss: 2.214316\n",
            "Epoch 108, loss: 2.230825\n",
            "Epoch 109, loss: 2.239231\n",
            "Epoch 110, loss: 2.234866\n",
            "Epoch 111, loss: 2.201053\n",
            "Epoch 112, loss: 2.209028\n",
            "Epoch 113, loss: 2.224065\n",
            "Epoch 114, loss: 2.251416\n",
            "Epoch 115, loss: 2.243129\n",
            "Epoch 116, loss: 2.223937\n",
            "Epoch 117, loss: 2.249376\n",
            "Epoch 118, loss: 2.241668\n",
            "Epoch 119, loss: 2.240300\n",
            "Epoch 120, loss: 2.215786\n",
            "Epoch 121, loss: 2.238452\n",
            "Epoch 122, loss: 2.239752\n",
            "Epoch 123, loss: 2.234893\n",
            "Epoch 124, loss: 2.220177\n",
            "Epoch 125, loss: 2.209640\n",
            "Epoch 126, loss: 2.245689\n",
            "Epoch 127, loss: 2.216979\n",
            "Epoch 128, loss: 2.200125\n",
            "Epoch 129, loss: 2.213259\n",
            "Epoch 130, loss: 2.206903\n",
            "Epoch 131, loss: 2.218439\n",
            "Epoch 132, loss: 2.236324\n",
            "Epoch 133, loss: 2.222189\n",
            "Epoch 134, loss: 2.237964\n",
            "Epoch 135, loss: 2.231821\n",
            "Epoch 136, loss: 2.227961\n",
            "Epoch 137, loss: 2.241645\n",
            "Epoch 138, loss: 2.203645\n",
            "Epoch 139, loss: 2.233737\n",
            "Epoch 140, loss: 2.221010\n",
            "Epoch 141, loss: 2.234278\n",
            "Epoch 142, loss: 2.216986\n",
            "Epoch 143, loss: 2.211245\n",
            "Epoch 144, loss: 2.211296\n",
            "Epoch 145, loss: 2.209540\n",
            "Epoch 146, loss: 2.235318\n",
            "Epoch 147, loss: 2.235957\n",
            "Epoch 148, loss: 2.199483\n",
            "Epoch 149, loss: 2.212995\n",
            "Epoch 150, loss: 2.197752\n",
            "Epoch 151, loss: 2.195185\n",
            "Epoch 152, loss: 2.203938\n",
            "Epoch 153, loss: 2.234501\n",
            "Epoch 154, loss: 2.214127\n",
            "Epoch 155, loss: 2.199229\n",
            "Epoch 156, loss: 2.193928\n",
            "Epoch 157, loss: 2.232965\n",
            "Epoch 158, loss: 2.206514\n",
            "Epoch 159, loss: 2.213856\n",
            "Epoch 160, loss: 2.225758\n",
            "Epoch 161, loss: 2.215581\n",
            "Epoch 162, loss: 2.225896\n",
            "Epoch 163, loss: 2.238078\n",
            "Epoch 164, loss: 2.214506\n",
            "Epoch 165, loss: 2.213555\n",
            "Epoch 166, loss: 2.212125\n",
            "Epoch 167, loss: 2.220547\n",
            "Epoch 168, loss: 2.189816\n",
            "Epoch 169, loss: 2.213570\n",
            "Epoch 170, loss: 2.240761\n",
            "Epoch 171, loss: 2.221691\n",
            "Epoch 172, loss: 2.199519\n",
            "Epoch 173, loss: 2.194181\n",
            "Epoch 174, loss: 2.188505\n",
            "Epoch 175, loss: 2.215618\n",
            "Epoch 176, loss: 2.201906\n",
            "Epoch 177, loss: 2.205806\n",
            "Epoch 178, loss: 2.226165\n",
            "Epoch 179, loss: 2.211664\n",
            "Epoch 180, loss: 2.193172\n",
            "Epoch 181, loss: 2.223213\n",
            "Epoch 182, loss: 2.185939\n",
            "Epoch 183, loss: 2.238110\n",
            "Epoch 184, loss: 2.227109\n",
            "Epoch 185, loss: 2.175679\n",
            "Epoch 186, loss: 2.214481\n",
            "Epoch 187, loss: 2.208415\n",
            "Epoch 188, loss: 2.212458\n",
            "Epoch 189, loss: 2.183538\n",
            "Epoch 190, loss: 2.211287\n",
            "Epoch 191, loss: 2.223238\n",
            "Epoch 192, loss: 2.193218\n",
            "Epoch 193, loss: 2.191117\n",
            "Epoch 194, loss: 2.194474\n",
            "Epoch 195, loss: 2.210582\n",
            "Epoch 196, loss: 2.207828\n",
            "Epoch 197, loss: 2.235345\n",
            "Epoch 198, loss: 2.200373\n",
            "Epoch 199, loss: 2.209282\n",
            "Epoch 0, loss: 2.301272\n",
            "Epoch 1, loss: 2.301652\n",
            "Epoch 2, loss: 2.299477\n",
            "Epoch 3, loss: 2.299882\n",
            "Epoch 4, loss: 2.298865\n",
            "Epoch 5, loss: 2.295109\n",
            "Epoch 6, loss: 2.295595\n",
            "Epoch 7, loss: 2.295551\n",
            "Epoch 8, loss: 2.298515\n",
            "Epoch 9, loss: 2.294449\n",
            "Epoch 10, loss: 2.291436\n",
            "Epoch 11, loss: 2.291839\n",
            "Epoch 12, loss: 2.291203\n",
            "Epoch 13, loss: 2.294081\n",
            "Epoch 14, loss: 2.290734\n",
            "Epoch 15, loss: 2.291852\n",
            "Epoch 16, loss: 2.282916\n",
            "Epoch 17, loss: 2.287672\n",
            "Epoch 18, loss: 2.281714\n",
            "Epoch 19, loss: 2.287661\n",
            "Epoch 20, loss: 2.278959\n",
            "Epoch 21, loss: 2.282464\n",
            "Epoch 22, loss: 2.284730\n",
            "Epoch 23, loss: 2.276411\n",
            "Epoch 24, loss: 2.278483\n",
            "Epoch 25, loss: 2.279966\n",
            "Epoch 26, loss: 2.274943\n",
            "Epoch 27, loss: 2.278264\n",
            "Epoch 28, loss: 2.289814\n",
            "Epoch 29, loss: 2.266797\n",
            "Epoch 30, loss: 2.275383\n",
            "Epoch 31, loss: 2.271774\n",
            "Epoch 32, loss: 2.270555\n",
            "Epoch 33, loss: 2.270951\n",
            "Epoch 34, loss: 2.270335\n",
            "Epoch 35, loss: 2.270676\n",
            "Epoch 36, loss: 2.276138\n",
            "Epoch 37, loss: 2.278912\n",
            "Epoch 38, loss: 2.270140\n",
            "Epoch 39, loss: 2.275700\n",
            "Epoch 40, loss: 2.268581\n",
            "Epoch 41, loss: 2.275035\n",
            "Epoch 42, loss: 2.278346\n",
            "Epoch 43, loss: 2.259996\n",
            "Epoch 44, loss: 2.272360\n",
            "Epoch 45, loss: 2.262898\n",
            "Epoch 46, loss: 2.255827\n",
            "Epoch 47, loss: 2.275868\n",
            "Epoch 48, loss: 2.261571\n",
            "Epoch 49, loss: 2.262837\n",
            "Epoch 50, loss: 2.265729\n",
            "Epoch 51, loss: 2.259749\n",
            "Epoch 52, loss: 2.249964\n",
            "Epoch 53, loss: 2.255689\n",
            "Epoch 54, loss: 2.272380\n",
            "Epoch 55, loss: 2.250560\n",
            "Epoch 56, loss: 2.271674\n",
            "Epoch 57, loss: 2.256367\n",
            "Epoch 58, loss: 2.257026\n",
            "Epoch 59, loss: 2.262947\n",
            "Epoch 60, loss: 2.252631\n",
            "Epoch 61, loss: 2.256128\n",
            "Epoch 62, loss: 2.263532\n",
            "Epoch 63, loss: 2.252382\n",
            "Epoch 64, loss: 2.262355\n",
            "Epoch 65, loss: 2.256299\n",
            "Epoch 66, loss: 2.257260\n",
            "Epoch 67, loss: 2.255392\n",
            "Epoch 68, loss: 2.250571\n",
            "Epoch 69, loss: 2.271198\n",
            "Epoch 70, loss: 2.256381\n",
            "Epoch 71, loss: 2.250019\n",
            "Epoch 72, loss: 2.231736\n",
            "Epoch 73, loss: 2.249185\n",
            "Epoch 74, loss: 2.243787\n",
            "Epoch 75, loss: 2.247420\n",
            "Epoch 76, loss: 2.253310\n",
            "Epoch 77, loss: 2.252136\n",
            "Epoch 78, loss: 2.231996\n",
            "Epoch 79, loss: 2.250291\n",
            "Epoch 80, loss: 2.251697\n",
            "Epoch 81, loss: 2.251760\n",
            "Epoch 82, loss: 2.243815\n",
            "Epoch 83, loss: 2.233091\n",
            "Epoch 84, loss: 2.223074\n",
            "Epoch 85, loss: 2.234299\n",
            "Epoch 86, loss: 2.235576\n",
            "Epoch 87, loss: 2.237876\n",
            "Epoch 88, loss: 2.243019\n",
            "Epoch 89, loss: 2.216727\n",
            "Epoch 90, loss: 2.245354\n",
            "Epoch 91, loss: 2.227700\n",
            "Epoch 92, loss: 2.254696\n",
            "Epoch 93, loss: 2.265489\n",
            "Epoch 94, loss: 2.250913\n",
            "Epoch 95, loss: 2.239969\n",
            "Epoch 96, loss: 2.237302\n",
            "Epoch 97, loss: 2.226486\n",
            "Epoch 98, loss: 2.234749\n",
            "Epoch 99, loss: 2.255620\n",
            "Epoch 100, loss: 2.248693\n",
            "Epoch 101, loss: 2.226159\n",
            "Epoch 102, loss: 2.239815\n",
            "Epoch 103, loss: 2.222639\n",
            "Epoch 104, loss: 2.235742\n",
            "Epoch 105, loss: 2.255416\n",
            "Epoch 106, loss: 2.237289\n",
            "Epoch 107, loss: 2.238395\n",
            "Epoch 108, loss: 2.234602\n",
            "Epoch 109, loss: 2.228472\n",
            "Epoch 110, loss: 2.248014\n",
            "Epoch 111, loss: 2.230337\n",
            "Epoch 112, loss: 2.207999\n",
            "Epoch 113, loss: 2.222301\n",
            "Epoch 114, loss: 2.235498\n",
            "Epoch 115, loss: 2.249670\n",
            "Epoch 116, loss: 2.218112\n",
            "Epoch 117, loss: 2.219478\n",
            "Epoch 118, loss: 2.242437\n",
            "Epoch 119, loss: 2.232682\n",
            "Epoch 120, loss: 2.201003\n",
            "Epoch 121, loss: 2.232533\n",
            "Epoch 122, loss: 2.235546\n",
            "Epoch 123, loss: 2.203887\n",
            "Epoch 124, loss: 2.216454\n",
            "Epoch 125, loss: 2.225184\n",
            "Epoch 126, loss: 2.219364\n",
            "Epoch 127, loss: 2.237630\n",
            "Epoch 128, loss: 2.228502\n",
            "Epoch 129, loss: 2.220615\n",
            "Epoch 130, loss: 2.203077\n",
            "Epoch 131, loss: 2.214167\n",
            "Epoch 132, loss: 2.225299\n",
            "Epoch 133, loss: 2.218476\n",
            "Epoch 134, loss: 2.230429\n",
            "Epoch 135, loss: 2.239212\n",
            "Epoch 136, loss: 2.233320\n",
            "Epoch 137, loss: 2.204748\n",
            "Epoch 138, loss: 2.223727\n",
            "Epoch 139, loss: 2.220474\n",
            "Epoch 140, loss: 2.230879\n",
            "Epoch 141, loss: 2.220284\n",
            "Epoch 142, loss: 2.230035\n",
            "Epoch 143, loss: 2.212588\n",
            "Epoch 144, loss: 2.223719\n",
            "Epoch 145, loss: 2.212572\n",
            "Epoch 146, loss: 2.219790\n",
            "Epoch 147, loss: 2.227217\n",
            "Epoch 148, loss: 2.212397\n",
            "Epoch 149, loss: 2.214844\n",
            "Epoch 150, loss: 2.223752\n",
            "Epoch 151, loss: 2.199835\n",
            "Epoch 152, loss: 2.205113\n",
            "Epoch 153, loss: 2.213309\n",
            "Epoch 154, loss: 2.224951\n",
            "Epoch 155, loss: 2.213000\n",
            "Epoch 156, loss: 2.230705\n",
            "Epoch 157, loss: 2.209556\n",
            "Epoch 158, loss: 2.217212\n",
            "Epoch 159, loss: 2.196167\n",
            "Epoch 160, loss: 2.196154\n",
            "Epoch 161, loss: 2.218506\n",
            "Epoch 162, loss: 2.221870\n",
            "Epoch 163, loss: 2.191328\n",
            "Epoch 164, loss: 2.212059\n",
            "Epoch 165, loss: 2.195592\n",
            "Epoch 166, loss: 2.204104\n",
            "Epoch 167, loss: 2.210195\n",
            "Epoch 168, loss: 2.211379\n",
            "Epoch 169, loss: 2.222471\n",
            "Epoch 170, loss: 2.201070\n",
            "Epoch 171, loss: 2.210771\n",
            "Epoch 172, loss: 2.216464\n",
            "Epoch 173, loss: 2.201841\n",
            "Epoch 174, loss: 2.213982\n",
            "Epoch 175, loss: 2.182804\n",
            "Epoch 176, loss: 2.206187\n",
            "Epoch 177, loss: 2.180571\n",
            "Epoch 178, loss: 2.188930\n",
            "Epoch 179, loss: 2.214488\n",
            "Epoch 180, loss: 2.182285\n",
            "Epoch 181, loss: 2.203857\n",
            "Epoch 182, loss: 2.199142\n",
            "Epoch 183, loss: 2.207960\n",
            "Epoch 184, loss: 2.223745\n",
            "Epoch 185, loss: 2.201318\n",
            "Epoch 186, loss: 2.192437\n",
            "Epoch 187, loss: 2.227159\n",
            "Epoch 188, loss: 2.190023\n",
            "Epoch 189, loss: 2.208224\n",
            "Epoch 190, loss: 2.210314\n",
            "Epoch 191, loss: 2.215599\n",
            "Epoch 192, loss: 2.200403\n",
            "Epoch 193, loss: 2.195548\n",
            "Epoch 194, loss: 2.191003\n",
            "Epoch 195, loss: 2.218723\n",
            "Epoch 196, loss: 2.207896\n",
            "Epoch 197, loss: 2.194382\n",
            "Epoch 198, loss: 2.195170\n",
            "Epoch 199, loss: 2.203403\n",
            "Epoch 0, loss: 2.301957\n",
            "Epoch 1, loss: 2.300094\n",
            "Epoch 2, loss: 2.301039\n",
            "Epoch 3, loss: 2.298874\n",
            "Epoch 4, loss: 2.296233\n",
            "Epoch 5, loss: 2.296621\n",
            "Epoch 6, loss: 2.295329\n",
            "Epoch 7, loss: 2.296019\n",
            "Epoch 8, loss: 2.290384\n",
            "Epoch 9, loss: 2.290522\n",
            "Epoch 10, loss: 2.294061\n",
            "Epoch 11, loss: 2.294221\n",
            "Epoch 12, loss: 2.291140\n",
            "Epoch 13, loss: 2.290872\n",
            "Epoch 14, loss: 2.290884\n",
            "Epoch 15, loss: 2.290804\n",
            "Epoch 16, loss: 2.287375\n",
            "Epoch 17, loss: 2.286363\n",
            "Epoch 18, loss: 2.287767\n",
            "Epoch 19, loss: 2.284057\n",
            "Epoch 20, loss: 2.281820\n",
            "Epoch 21, loss: 2.284643\n",
            "Epoch 22, loss: 2.283953\n",
            "Epoch 23, loss: 2.281746\n",
            "Epoch 24, loss: 2.276096\n",
            "Epoch 25, loss: 2.281710\n",
            "Epoch 26, loss: 2.281303\n",
            "Epoch 27, loss: 2.277252\n",
            "Epoch 28, loss: 2.274209\n",
            "Epoch 29, loss: 2.272554\n",
            "Epoch 30, loss: 2.280340\n",
            "Epoch 31, loss: 2.266350\n",
            "Epoch 32, loss: 2.272322\n",
            "Epoch 33, loss: 2.273889\n",
            "Epoch 34, loss: 2.272914\n",
            "Epoch 35, loss: 2.268971\n",
            "Epoch 36, loss: 2.282266\n",
            "Epoch 37, loss: 2.267125\n",
            "Epoch 38, loss: 2.269526\n",
            "Epoch 39, loss: 2.278064\n",
            "Epoch 40, loss: 2.271368\n",
            "Epoch 41, loss: 2.278985\n",
            "Epoch 42, loss: 2.267726\n",
            "Epoch 43, loss: 2.268199\n",
            "Epoch 44, loss: 2.261335\n",
            "Epoch 45, loss: 2.267771\n",
            "Epoch 46, loss: 2.266131\n",
            "Epoch 47, loss: 2.267100\n",
            "Epoch 48, loss: 2.261558\n",
            "Epoch 49, loss: 2.267938\n",
            "Epoch 50, loss: 2.258599\n",
            "Epoch 51, loss: 2.259279\n",
            "Epoch 52, loss: 2.260451\n",
            "Epoch 53, loss: 2.244605\n",
            "Epoch 54, loss: 2.250112\n",
            "Epoch 55, loss: 2.259378\n",
            "Epoch 56, loss: 2.262771\n",
            "Epoch 57, loss: 2.260631\n",
            "Epoch 58, loss: 2.249094\n",
            "Epoch 59, loss: 2.277883\n",
            "Epoch 60, loss: 2.255516\n",
            "Epoch 61, loss: 2.236845\n",
            "Epoch 62, loss: 2.256676\n",
            "Epoch 63, loss: 2.266680\n",
            "Epoch 64, loss: 2.251490\n",
            "Epoch 65, loss: 2.270584\n",
            "Epoch 66, loss: 2.261560\n",
            "Epoch 67, loss: 2.257122\n",
            "Epoch 68, loss: 2.250366\n",
            "Epoch 69, loss: 2.263314\n",
            "Epoch 70, loss: 2.264256\n",
            "Epoch 71, loss: 2.246755\n",
            "Epoch 72, loss: 2.259595\n",
            "Epoch 73, loss: 2.261632\n",
            "Epoch 74, loss: 2.254474\n",
            "Epoch 75, loss: 2.251544\n",
            "Epoch 76, loss: 2.246087\n",
            "Epoch 77, loss: 2.264107\n",
            "Epoch 78, loss: 2.253306\n",
            "Epoch 79, loss: 2.239092\n",
            "Epoch 80, loss: 2.247039\n",
            "Epoch 81, loss: 2.250836\n",
            "Epoch 82, loss: 2.240162\n",
            "Epoch 83, loss: 2.256520\n",
            "Epoch 84, loss: 2.263833\n",
            "Epoch 85, loss: 2.246637\n",
            "Epoch 86, loss: 2.255182\n",
            "Epoch 87, loss: 2.250890\n",
            "Epoch 88, loss: 2.238754\n",
            "Epoch 89, loss: 2.233946\n",
            "Epoch 90, loss: 2.235773\n",
            "Epoch 91, loss: 2.235883\n",
            "Epoch 92, loss: 2.253822\n",
            "Epoch 93, loss: 2.221594\n",
            "Epoch 94, loss: 2.240457\n",
            "Epoch 95, loss: 2.234328\n",
            "Epoch 96, loss: 2.251871\n",
            "Epoch 97, loss: 2.241247\n",
            "Epoch 98, loss: 2.246297\n",
            "Epoch 99, loss: 2.229359\n",
            "Epoch 100, loss: 2.254016\n",
            "Epoch 101, loss: 2.258618\n",
            "Epoch 102, loss: 2.233807\n",
            "Epoch 103, loss: 2.230803\n",
            "Epoch 104, loss: 2.240010\n",
            "Epoch 105, loss: 2.222542\n",
            "Epoch 106, loss: 2.235490\n",
            "Epoch 107, loss: 2.237107\n",
            "Epoch 108, loss: 2.237226\n",
            "Epoch 109, loss: 2.232039\n",
            "Epoch 110, loss: 2.238107\n",
            "Epoch 111, loss: 2.232159\n",
            "Epoch 112, loss: 2.241529\n",
            "Epoch 113, loss: 2.227542\n",
            "Epoch 114, loss: 2.218303\n",
            "Epoch 115, loss: 2.221761\n",
            "Epoch 116, loss: 2.229555\n",
            "Epoch 117, loss: 2.228159\n",
            "Epoch 118, loss: 2.219451\n",
            "Epoch 119, loss: 2.240328\n",
            "Epoch 120, loss: 2.215592\n",
            "Epoch 121, loss: 2.240388\n",
            "Epoch 122, loss: 2.199800\n",
            "Epoch 123, loss: 2.229022\n",
            "Epoch 124, loss: 2.233296\n",
            "Epoch 125, loss: 2.234708\n",
            "Epoch 126, loss: 2.231293\n",
            "Epoch 127, loss: 2.227593\n",
            "Epoch 128, loss: 2.221737\n",
            "Epoch 129, loss: 2.240833\n",
            "Epoch 130, loss: 2.237063\n",
            "Epoch 131, loss: 2.218572\n",
            "Epoch 132, loss: 2.206434\n",
            "Epoch 133, loss: 2.216967\n",
            "Epoch 134, loss: 2.243600\n",
            "Epoch 135, loss: 2.232305\n",
            "Epoch 136, loss: 2.221255\n",
            "Epoch 137, loss: 2.224992\n",
            "Epoch 138, loss: 2.240206\n",
            "Epoch 139, loss: 2.219506\n",
            "Epoch 140, loss: 2.212689\n",
            "Epoch 141, loss: 2.220448\n",
            "Epoch 142, loss: 2.214040\n",
            "Epoch 143, loss: 2.210506\n",
            "Epoch 144, loss: 2.199093\n",
            "Epoch 145, loss: 2.219094\n",
            "Epoch 146, loss: 2.212448\n",
            "Epoch 147, loss: 2.238550\n",
            "Epoch 148, loss: 2.214412\n",
            "Epoch 149, loss: 2.198153\n",
            "Epoch 150, loss: 2.214925\n",
            "Epoch 151, loss: 2.225248\n",
            "Epoch 152, loss: 2.219950\n",
            "Epoch 153, loss: 2.198169\n",
            "Epoch 154, loss: 2.200942\n",
            "Epoch 155, loss: 2.197675\n",
            "Epoch 156, loss: 2.222697\n",
            "Epoch 157, loss: 2.208802\n",
            "Epoch 158, loss: 2.237171\n",
            "Epoch 159, loss: 2.212576\n",
            "Epoch 160, loss: 2.204865\n",
            "Epoch 161, loss: 2.228880\n",
            "Epoch 162, loss: 2.180994\n",
            "Epoch 163, loss: 2.186308\n",
            "Epoch 164, loss: 2.205722\n",
            "Epoch 165, loss: 2.188183\n",
            "Epoch 166, loss: 2.206312\n",
            "Epoch 167, loss: 2.219512\n",
            "Epoch 168, loss: 2.236215\n",
            "Epoch 169, loss: 2.230219\n",
            "Epoch 170, loss: 2.187669\n",
            "Epoch 171, loss: 2.225443\n",
            "Epoch 172, loss: 2.195905\n",
            "Epoch 173, loss: 2.214092\n",
            "Epoch 174, loss: 2.246645\n",
            "Epoch 175, loss: 2.232073\n",
            "Epoch 176, loss: 2.216746\n",
            "Epoch 177, loss: 2.219761\n",
            "Epoch 178, loss: 2.197203\n",
            "Epoch 179, loss: 2.212618\n",
            "Epoch 180, loss: 2.196625\n",
            "Epoch 181, loss: 2.198569\n",
            "Epoch 182, loss: 2.216708\n",
            "Epoch 183, loss: 2.207023\n",
            "Epoch 184, loss: 2.213826\n",
            "Epoch 185, loss: 2.204809\n",
            "Epoch 186, loss: 2.220652\n",
            "Epoch 187, loss: 2.210505\n",
            "Epoch 188, loss: 2.207807\n",
            "Epoch 189, loss: 2.200350\n",
            "Epoch 190, loss: 2.198363\n",
            "Epoch 191, loss: 2.209643\n",
            "Epoch 192, loss: 2.195356\n",
            "Epoch 193, loss: 2.202754\n",
            "Epoch 194, loss: 2.210416\n",
            "Epoch 195, loss: 2.194216\n",
            "Epoch 196, loss: 2.206831\n",
            "Epoch 197, loss: 2.195016\n",
            "Epoch 198, loss: 2.225599\n",
            "Epoch 199, loss: 2.202651\n",
            "Epoch 0, loss: 2.301667\n",
            "Epoch 1, loss: 2.301773\n",
            "Epoch 2, loss: 2.299531\n",
            "Epoch 3, loss: 2.299158\n",
            "Epoch 4, loss: 2.296655\n",
            "Epoch 5, loss: 2.300646\n",
            "Epoch 6, loss: 2.297764\n",
            "Epoch 7, loss: 2.297863\n",
            "Epoch 8, loss: 2.297092\n",
            "Epoch 9, loss: 2.288581\n",
            "Epoch 10, loss: 2.292021\n",
            "Epoch 11, loss: 2.293688\n",
            "Epoch 12, loss: 2.292925\n",
            "Epoch 13, loss: 2.291087\n",
            "Epoch 14, loss: 2.291192\n",
            "Epoch 15, loss: 2.288912\n",
            "Epoch 16, loss: 2.286211\n",
            "Epoch 17, loss: 2.291359\n",
            "Epoch 18, loss: 2.287123\n",
            "Epoch 19, loss: 2.281857\n",
            "Epoch 20, loss: 2.287879\n",
            "Epoch 21, loss: 2.286510\n",
            "Epoch 22, loss: 2.284405\n",
            "Epoch 23, loss: 2.284217\n",
            "Epoch 24, loss: 2.274850\n",
            "Epoch 25, loss: 2.279948\n",
            "Epoch 26, loss: 2.279715\n",
            "Epoch 27, loss: 2.281762\n",
            "Epoch 28, loss: 2.272111\n",
            "Epoch 29, loss: 2.278671\n",
            "Epoch 30, loss: 2.280776\n",
            "Epoch 31, loss: 2.279787\n",
            "Epoch 32, loss: 2.271500\n",
            "Epoch 33, loss: 2.277076\n",
            "Epoch 34, loss: 2.270864\n",
            "Epoch 35, loss: 2.275682\n",
            "Epoch 36, loss: 2.277402\n",
            "Epoch 37, loss: 2.270107\n",
            "Epoch 38, loss: 2.271749\n",
            "Epoch 39, loss: 2.272609\n",
            "Epoch 40, loss: 2.271170\n",
            "Epoch 41, loss: 2.268364\n",
            "Epoch 42, loss: 2.275999\n",
            "Epoch 43, loss: 2.272346\n",
            "Epoch 44, loss: 2.265758\n",
            "Epoch 45, loss: 2.254024\n",
            "Epoch 46, loss: 2.264176\n",
            "Epoch 47, loss: 2.265688\n",
            "Epoch 48, loss: 2.276401\n",
            "Epoch 49, loss: 2.261469\n",
            "Epoch 50, loss: 2.268356\n",
            "Epoch 51, loss: 2.261851\n",
            "Epoch 52, loss: 2.271392\n",
            "Epoch 53, loss: 2.258613\n",
            "Epoch 54, loss: 2.255260\n",
            "Epoch 55, loss: 2.266591\n",
            "Epoch 56, loss: 2.270410\n",
            "Epoch 57, loss: 2.243866\n",
            "Epoch 58, loss: 2.257748\n",
            "Epoch 59, loss: 2.249788\n",
            "Epoch 60, loss: 2.262903\n",
            "Epoch 61, loss: 2.251846\n",
            "Epoch 62, loss: 2.250978\n",
            "Epoch 63, loss: 2.250841\n",
            "Epoch 64, loss: 2.259743\n",
            "Epoch 65, loss: 2.251979\n",
            "Epoch 66, loss: 2.256671\n",
            "Epoch 67, loss: 2.255961\n",
            "Epoch 68, loss: 2.255365\n",
            "Epoch 69, loss: 2.245817\n",
            "Epoch 70, loss: 2.259628\n",
            "Epoch 71, loss: 2.251667\n",
            "Epoch 72, loss: 2.254572\n",
            "Epoch 73, loss: 2.234614\n",
            "Epoch 74, loss: 2.246251\n",
            "Epoch 75, loss: 2.255570\n",
            "Epoch 76, loss: 2.244033\n",
            "Epoch 77, loss: 2.262223\n",
            "Epoch 78, loss: 2.250763\n",
            "Epoch 79, loss: 2.249659\n",
            "Epoch 80, loss: 2.241034\n",
            "Epoch 81, loss: 2.258620\n",
            "Epoch 82, loss: 2.231705\n",
            "Epoch 83, loss: 2.265935\n",
            "Epoch 84, loss: 2.248551\n",
            "Epoch 85, loss: 2.250571\n",
            "Epoch 86, loss: 2.249362\n",
            "Epoch 87, loss: 2.262631\n",
            "Epoch 88, loss: 2.251455\n",
            "Epoch 89, loss: 2.239574\n",
            "Epoch 90, loss: 2.232792\n",
            "Epoch 91, loss: 2.238902\n",
            "Epoch 92, loss: 2.247224\n",
            "Epoch 93, loss: 2.246247\n",
            "Epoch 94, loss: 2.259819\n",
            "Epoch 95, loss: 2.261483\n",
            "Epoch 96, loss: 2.227439\n",
            "Epoch 97, loss: 2.236944\n",
            "Epoch 98, loss: 2.234730\n",
            "Epoch 99, loss: 2.247531\n",
            "Epoch 100, loss: 2.227743\n",
            "Epoch 101, loss: 2.247250\n",
            "Epoch 102, loss: 2.235322\n",
            "Epoch 103, loss: 2.232991\n",
            "Epoch 104, loss: 2.227787\n",
            "Epoch 105, loss: 2.239318\n",
            "Epoch 106, loss: 2.239023\n",
            "Epoch 107, loss: 2.237339\n",
            "Epoch 108, loss: 2.246318\n",
            "Epoch 109, loss: 2.244996\n",
            "Epoch 110, loss: 2.238962\n",
            "Epoch 111, loss: 2.236362\n",
            "Epoch 112, loss: 2.234168\n",
            "Epoch 113, loss: 2.234782\n",
            "Epoch 114, loss: 2.226131\n",
            "Epoch 115, loss: 2.240828\n",
            "Epoch 116, loss: 2.212410\n",
            "Epoch 117, loss: 2.237057\n",
            "Epoch 118, loss: 2.223793\n",
            "Epoch 119, loss: 2.225553\n",
            "Epoch 120, loss: 2.238820\n",
            "Epoch 121, loss: 2.228346\n",
            "Epoch 122, loss: 2.237193\n",
            "Epoch 123, loss: 2.230612\n",
            "Epoch 124, loss: 2.227065\n",
            "Epoch 125, loss: 2.228152\n",
            "Epoch 126, loss: 2.209394\n",
            "Epoch 127, loss: 2.243292\n",
            "Epoch 128, loss: 2.223297\n",
            "Epoch 129, loss: 2.226503\n",
            "Epoch 130, loss: 2.209213\n",
            "Epoch 131, loss: 2.213115\n",
            "Epoch 132, loss: 2.226545\n",
            "Epoch 133, loss: 2.220110\n",
            "Epoch 134, loss: 2.230380\n",
            "Epoch 135, loss: 2.221632\n",
            "Epoch 136, loss: 2.209054\n",
            "Epoch 137, loss: 2.227731\n",
            "Epoch 138, loss: 2.219210\n",
            "Epoch 139, loss: 2.251325\n",
            "Epoch 140, loss: 2.226606\n",
            "Epoch 141, loss: 2.207929\n",
            "Epoch 142, loss: 2.215472\n",
            "Epoch 143, loss: 2.206403\n",
            "Epoch 144, loss: 2.199594\n",
            "Epoch 145, loss: 2.209359\n",
            "Epoch 146, loss: 2.229270\n",
            "Epoch 147, loss: 2.229942\n",
            "Epoch 148, loss: 2.215998\n",
            "Epoch 149, loss: 2.227494\n",
            "Epoch 150, loss: 2.220011\n",
            "Epoch 151, loss: 2.230096\n",
            "Epoch 152, loss: 2.218591\n",
            "Epoch 153, loss: 2.230857\n",
            "Epoch 154, loss: 2.209140\n",
            "Epoch 155, loss: 2.237746\n",
            "Epoch 156, loss: 2.226157\n",
            "Epoch 157, loss: 2.225689\n",
            "Epoch 158, loss: 2.220364\n",
            "Epoch 159, loss: 2.197320\n",
            "Epoch 160, loss: 2.210382\n",
            "Epoch 161, loss: 2.202996\n",
            "Epoch 162, loss: 2.219473\n",
            "Epoch 163, loss: 2.227573\n",
            "Epoch 164, loss: 2.206564\n",
            "Epoch 165, loss: 2.206819\n",
            "Epoch 166, loss: 2.187376\n",
            "Epoch 167, loss: 2.218517\n",
            "Epoch 168, loss: 2.197648\n",
            "Epoch 169, loss: 2.200258\n",
            "Epoch 170, loss: 2.221516\n",
            "Epoch 171, loss: 2.222403\n",
            "Epoch 172, loss: 2.213716\n",
            "Epoch 173, loss: 2.223604\n",
            "Epoch 174, loss: 2.210496\n",
            "Epoch 175, loss: 2.221045\n",
            "Epoch 176, loss: 2.237410\n",
            "Epoch 177, loss: 2.212348\n",
            "Epoch 178, loss: 2.192086\n",
            "Epoch 179, loss: 2.212259\n",
            "Epoch 180, loss: 2.184175\n",
            "Epoch 181, loss: 2.218985\n",
            "Epoch 182, loss: 2.212293\n",
            "Epoch 183, loss: 2.215732\n",
            "Epoch 184, loss: 2.205852\n",
            "Epoch 185, loss: 2.167379\n",
            "Epoch 186, loss: 2.225855\n",
            "Epoch 187, loss: 2.216338\n",
            "Epoch 188, loss: 2.209629\n",
            "Epoch 189, loss: 2.206371\n",
            "Epoch 190, loss: 2.220439\n",
            "Epoch 191, loss: 2.190466\n",
            "Epoch 192, loss: 2.233298\n",
            "Epoch 193, loss: 2.197911\n",
            "Epoch 194, loss: 2.206397\n",
            "Epoch 195, loss: 2.193477\n",
            "Epoch 196, loss: 2.203648\n",
            "Epoch 197, loss: 2.230138\n",
            "Epoch 198, loss: 2.207714\n",
            "Epoch 199, loss: 2.233705\n",
            "Epoch 0, loss: 2.302624\n",
            "Epoch 1, loss: 2.300455\n",
            "Epoch 2, loss: 2.299316\n",
            "Epoch 3, loss: 2.300692\n",
            "Epoch 4, loss: 2.298358\n",
            "Epoch 5, loss: 2.295163\n",
            "Epoch 6, loss: 2.293027\n",
            "Epoch 7, loss: 2.296084\n",
            "Epoch 8, loss: 2.297929\n",
            "Epoch 9, loss: 2.294019\n",
            "Epoch 10, loss: 2.292738\n",
            "Epoch 11, loss: 2.289482\n",
            "Epoch 12, loss: 2.293757\n",
            "Epoch 13, loss: 2.286449\n",
            "Epoch 14, loss: 2.294095\n",
            "Epoch 15, loss: 2.287291\n",
            "Epoch 16, loss: 2.287156\n",
            "Epoch 17, loss: 2.285429\n",
            "Epoch 18, loss: 2.287903\n",
            "Epoch 19, loss: 2.285128\n",
            "Epoch 20, loss: 2.286485\n",
            "Epoch 21, loss: 2.283373\n",
            "Epoch 22, loss: 2.283545\n",
            "Epoch 23, loss: 2.278270\n",
            "Epoch 24, loss: 2.285137\n",
            "Epoch 25, loss: 2.280031\n",
            "Epoch 26, loss: 2.279672\n",
            "Epoch 27, loss: 2.280758\n",
            "Epoch 28, loss: 2.277669\n",
            "Epoch 29, loss: 2.268533\n",
            "Epoch 30, loss: 2.272517\n",
            "Epoch 31, loss: 2.270833\n",
            "Epoch 32, loss: 2.277922\n",
            "Epoch 33, loss: 2.279354\n",
            "Epoch 34, loss: 2.266121\n",
            "Epoch 35, loss: 2.266461\n",
            "Epoch 36, loss: 2.274799\n",
            "Epoch 37, loss: 2.265067\n",
            "Epoch 38, loss: 2.259584\n",
            "Epoch 39, loss: 2.273872\n",
            "Epoch 40, loss: 2.273784\n",
            "Epoch 41, loss: 2.265297\n",
            "Epoch 42, loss: 2.255104\n",
            "Epoch 43, loss: 2.262063\n",
            "Epoch 44, loss: 2.267528\n",
            "Epoch 45, loss: 2.264566\n",
            "Epoch 46, loss: 2.262647\n",
            "Epoch 47, loss: 2.266697\n",
            "Epoch 48, loss: 2.262390\n",
            "Epoch 49, loss: 2.255935\n",
            "Epoch 50, loss: 2.261145\n",
            "Epoch 51, loss: 2.256672\n",
            "Epoch 52, loss: 2.266735\n",
            "Epoch 53, loss: 2.261130\n",
            "Epoch 54, loss: 2.265369\n",
            "Epoch 55, loss: 2.259674\n",
            "Epoch 56, loss: 2.264100\n",
            "Epoch 57, loss: 2.260608\n",
            "Epoch 58, loss: 2.250900\n",
            "Epoch 59, loss: 2.254354\n",
            "Epoch 60, loss: 2.253565\n",
            "Epoch 61, loss: 2.263367\n",
            "Epoch 62, loss: 2.254016\n",
            "Epoch 63, loss: 2.260221\n",
            "Epoch 64, loss: 2.250335\n",
            "Epoch 65, loss: 2.250542\n",
            "Epoch 66, loss: 2.249976\n",
            "Epoch 67, loss: 2.267059\n",
            "Epoch 68, loss: 2.258890\n",
            "Epoch 69, loss: 2.256112\n",
            "Epoch 70, loss: 2.240470\n",
            "Epoch 71, loss: 2.235984\n",
            "Epoch 72, loss: 2.254667\n",
            "Epoch 73, loss: 2.259066\n",
            "Epoch 74, loss: 2.249526\n",
            "Epoch 75, loss: 2.243358\n",
            "Epoch 76, loss: 2.241994\n",
            "Epoch 77, loss: 2.260050\n",
            "Epoch 78, loss: 2.254132\n",
            "Epoch 79, loss: 2.255912\n",
            "Epoch 80, loss: 2.261358\n",
            "Epoch 81, loss: 2.261412\n",
            "Epoch 82, loss: 2.242340\n",
            "Epoch 83, loss: 2.242568\n",
            "Epoch 84, loss: 2.246957\n",
            "Epoch 85, loss: 2.252897\n",
            "Epoch 86, loss: 2.246203\n",
            "Epoch 87, loss: 2.251217\n",
            "Epoch 88, loss: 2.223502\n",
            "Epoch 89, loss: 2.227439\n",
            "Epoch 90, loss: 2.231026\n",
            "Epoch 91, loss: 2.243541\n",
            "Epoch 92, loss: 2.253979\n",
            "Epoch 93, loss: 2.243181\n",
            "Epoch 94, loss: 2.231614\n",
            "Epoch 95, loss: 2.249816\n",
            "Epoch 96, loss: 2.250254\n",
            "Epoch 97, loss: 2.245816\n",
            "Epoch 98, loss: 2.242896\n",
            "Epoch 99, loss: 2.234193\n",
            "Epoch 100, loss: 2.250809\n",
            "Epoch 101, loss: 2.225776\n",
            "Epoch 102, loss: 2.252471\n",
            "Epoch 103, loss: 2.235308\n",
            "Epoch 104, loss: 2.232471\n",
            "Epoch 105, loss: 2.245749\n",
            "Epoch 106, loss: 2.245180\n",
            "Epoch 107, loss: 2.240332\n",
            "Epoch 108, loss: 2.208278\n",
            "Epoch 109, loss: 2.232104\n",
            "Epoch 110, loss: 2.207847\n",
            "Epoch 111, loss: 2.226667\n",
            "Epoch 112, loss: 2.220261\n",
            "Epoch 113, loss: 2.245193\n",
            "Epoch 114, loss: 2.223335\n",
            "Epoch 115, loss: 2.232141\n",
            "Epoch 116, loss: 2.225572\n",
            "Epoch 117, loss: 2.243482\n",
            "Epoch 118, loss: 2.231555\n",
            "Epoch 119, loss: 2.233652\n",
            "Epoch 120, loss: 2.216674\n",
            "Epoch 121, loss: 2.225201\n",
            "Epoch 122, loss: 2.242363\n",
            "Epoch 123, loss: 2.210590\n",
            "Epoch 124, loss: 2.242432\n",
            "Epoch 125, loss: 2.231627\n",
            "Epoch 126, loss: 2.238013\n",
            "Epoch 127, loss: 2.212365\n",
            "Epoch 128, loss: 2.212686\n",
            "Epoch 129, loss: 2.212563\n",
            "Epoch 130, loss: 2.219839\n",
            "Epoch 131, loss: 2.208966\n",
            "Epoch 132, loss: 2.209120\n",
            "Epoch 133, loss: 2.209806\n",
            "Epoch 134, loss: 2.226958\n",
            "Epoch 135, loss: 2.222589\n",
            "Epoch 136, loss: 2.238864\n",
            "Epoch 137, loss: 2.222317\n",
            "Epoch 138, loss: 2.201892\n",
            "Epoch 139, loss: 2.213125\n",
            "Epoch 140, loss: 2.242947\n",
            "Epoch 141, loss: 2.231236\n",
            "Epoch 142, loss: 2.231150\n",
            "Epoch 143, loss: 2.218792\n",
            "Epoch 144, loss: 2.230574\n",
            "Epoch 145, loss: 2.193147\n",
            "Epoch 146, loss: 2.237040\n",
            "Epoch 147, loss: 2.232887\n",
            "Epoch 148, loss: 2.184533\n",
            "Epoch 149, loss: 2.194701\n",
            "Epoch 150, loss: 2.239547\n",
            "Epoch 151, loss: 2.219725\n",
            "Epoch 152, loss: 2.237461\n",
            "Epoch 153, loss: 2.245498\n",
            "Epoch 154, loss: 2.228161\n",
            "Epoch 155, loss: 2.217111\n",
            "Epoch 156, loss: 2.207854\n",
            "Epoch 157, loss: 2.209339\n",
            "Epoch 158, loss: 2.211061\n",
            "Epoch 159, loss: 2.247150\n",
            "Epoch 160, loss: 2.229783\n",
            "Epoch 161, loss: 2.215143\n",
            "Epoch 162, loss: 2.208436\n",
            "Epoch 163, loss: 2.207371\n",
            "Epoch 164, loss: 2.182626\n",
            "Epoch 165, loss: 2.193789\n",
            "Epoch 166, loss: 2.253278\n",
            "Epoch 167, loss: 2.186229\n",
            "Epoch 168, loss: 2.220762\n",
            "Epoch 169, loss: 2.220763\n",
            "Epoch 170, loss: 2.202827\n",
            "Epoch 171, loss: 2.213433\n",
            "Epoch 172, loss: 2.189429\n",
            "Epoch 173, loss: 2.184507\n",
            "Epoch 174, loss: 2.203828\n",
            "Epoch 175, loss: 2.224893\n",
            "Epoch 176, loss: 2.203577\n",
            "Epoch 177, loss: 2.219709\n",
            "Epoch 178, loss: 2.205885\n",
            "Epoch 179, loss: 2.201314\n",
            "Epoch 180, loss: 2.200659\n",
            "Epoch 181, loss: 2.194662\n",
            "Epoch 182, loss: 2.213774\n",
            "Epoch 183, loss: 2.185085\n",
            "Epoch 184, loss: 2.177567\n",
            "Epoch 185, loss: 2.223848\n",
            "Epoch 186, loss: 2.215120\n",
            "Epoch 187, loss: 2.207304\n",
            "Epoch 188, loss: 2.188307\n",
            "Epoch 189, loss: 2.195783\n",
            "Epoch 190, loss: 2.211923\n",
            "Epoch 191, loss: 2.205089\n",
            "Epoch 192, loss: 2.211157\n",
            "Epoch 193, loss: 2.231777\n",
            "Epoch 194, loss: 2.221829\n",
            "Epoch 195, loss: 2.181962\n",
            "Epoch 196, loss: 2.191916\n",
            "Epoch 197, loss: 2.195487\n",
            "Epoch 198, loss: 2.213254\n",
            "Epoch 199, loss: 2.183992\n",
            "Epoch 0, loss: 2.301824\n",
            "Epoch 1, loss: 2.301917\n",
            "Epoch 2, loss: 2.301350\n",
            "Epoch 3, loss: 2.301584\n",
            "Epoch 4, loss: 2.300974\n",
            "Epoch 5, loss: 2.302473\n",
            "Epoch 6, loss: 2.302629\n",
            "Epoch 7, loss: 2.301300\n",
            "Epoch 8, loss: 2.302102\n",
            "Epoch 9, loss: 2.301481\n",
            "Epoch 10, loss: 2.301516\n",
            "Epoch 11, loss: 2.301133\n",
            "Epoch 12, loss: 2.300433\n",
            "Epoch 13, loss: 2.301483\n",
            "Epoch 14, loss: 2.301237\n",
            "Epoch 15, loss: 2.302148\n",
            "Epoch 16, loss: 2.301020\n",
            "Epoch 17, loss: 2.300424\n",
            "Epoch 18, loss: 2.301021\n",
            "Epoch 19, loss: 2.300845\n",
            "Epoch 20, loss: 2.299208\n",
            "Epoch 21, loss: 2.300102\n",
            "Epoch 22, loss: 2.301235\n",
            "Epoch 23, loss: 2.299594\n",
            "Epoch 24, loss: 2.300652\n",
            "Epoch 25, loss: 2.301406\n",
            "Epoch 26, loss: 2.299152\n",
            "Epoch 27, loss: 2.301266\n",
            "Epoch 28, loss: 2.300962\n",
            "Epoch 29, loss: 2.299660\n",
            "Epoch 30, loss: 2.299902\n",
            "Epoch 31, loss: 2.299153\n",
            "Epoch 32, loss: 2.299595\n",
            "Epoch 33, loss: 2.299070\n",
            "Epoch 34, loss: 2.298060\n",
            "Epoch 35, loss: 2.299560\n",
            "Epoch 36, loss: 2.298558\n",
            "Epoch 37, loss: 2.299872\n",
            "Epoch 38, loss: 2.298994\n",
            "Epoch 39, loss: 2.299435\n",
            "Epoch 40, loss: 2.296203\n",
            "Epoch 41, loss: 2.299465\n",
            "Epoch 42, loss: 2.296224\n",
            "Epoch 43, loss: 2.298357\n",
            "Epoch 44, loss: 2.295068\n",
            "Epoch 45, loss: 2.299237\n",
            "Epoch 46, loss: 2.296075\n",
            "Epoch 47, loss: 2.299832\n",
            "Epoch 48, loss: 2.296624\n",
            "Epoch 49, loss: 2.297868\n",
            "Epoch 50, loss: 2.300643\n",
            "Epoch 51, loss: 2.296554\n",
            "Epoch 52, loss: 2.298392\n",
            "Epoch 53, loss: 2.298565\n",
            "Epoch 54, loss: 2.296635\n",
            "Epoch 55, loss: 2.299438\n",
            "Epoch 56, loss: 2.296025\n",
            "Epoch 57, loss: 2.297567\n",
            "Epoch 58, loss: 2.296250\n",
            "Epoch 59, loss: 2.294664\n",
            "Epoch 60, loss: 2.295077\n",
            "Epoch 61, loss: 2.297433\n",
            "Epoch 62, loss: 2.299179\n",
            "Epoch 63, loss: 2.297690\n",
            "Epoch 64, loss: 2.298014\n",
            "Epoch 65, loss: 2.296239\n",
            "Epoch 66, loss: 2.294613\n",
            "Epoch 67, loss: 2.295437\n",
            "Epoch 68, loss: 2.295547\n",
            "Epoch 69, loss: 2.296589\n",
            "Epoch 70, loss: 2.296829\n",
            "Epoch 71, loss: 2.295325\n",
            "Epoch 72, loss: 2.297090\n",
            "Epoch 73, loss: 2.295461\n",
            "Epoch 74, loss: 2.293730\n",
            "Epoch 75, loss: 2.293320\n",
            "Epoch 76, loss: 2.294966\n",
            "Epoch 77, loss: 2.294812\n",
            "Epoch 78, loss: 2.294053\n",
            "Epoch 79, loss: 2.293329\n",
            "Epoch 80, loss: 2.294897\n",
            "Epoch 81, loss: 2.295291\n",
            "Epoch 82, loss: 2.293449\n",
            "Epoch 83, loss: 2.296181\n",
            "Epoch 84, loss: 2.291193\n",
            "Epoch 85, loss: 2.295154\n",
            "Epoch 86, loss: 2.297356\n",
            "Epoch 87, loss: 2.292843\n",
            "Epoch 88, loss: 2.294658\n",
            "Epoch 89, loss: 2.294224\n",
            "Epoch 90, loss: 2.292695\n",
            "Epoch 91, loss: 2.291578\n",
            "Epoch 92, loss: 2.293431\n",
            "Epoch 93, loss: 2.293315\n",
            "Epoch 94, loss: 2.294624\n",
            "Epoch 95, loss: 2.292846\n",
            "Epoch 96, loss: 2.292836\n",
            "Epoch 97, loss: 2.296120\n",
            "Epoch 98, loss: 2.295084\n",
            "Epoch 99, loss: 2.293424\n",
            "Epoch 100, loss: 2.293155\n",
            "Epoch 101, loss: 2.294359\n",
            "Epoch 102, loss: 2.292881\n",
            "Epoch 103, loss: 2.290406\n",
            "Epoch 104, loss: 2.293362\n",
            "Epoch 105, loss: 2.294338\n",
            "Epoch 106, loss: 2.290706\n",
            "Epoch 107, loss: 2.296539\n",
            "Epoch 108, loss: 2.296528\n",
            "Epoch 109, loss: 2.291230\n",
            "Epoch 110, loss: 2.291169\n",
            "Epoch 111, loss: 2.291399\n",
            "Epoch 112, loss: 2.292628\n",
            "Epoch 113, loss: 2.294865\n",
            "Epoch 114, loss: 2.291222\n",
            "Epoch 115, loss: 2.292982\n",
            "Epoch 116, loss: 2.294577\n",
            "Epoch 117, loss: 2.290783\n",
            "Epoch 118, loss: 2.290051\n",
            "Epoch 119, loss: 2.290489\n",
            "Epoch 120, loss: 2.289265\n",
            "Epoch 121, loss: 2.291207\n",
            "Epoch 122, loss: 2.292272\n",
            "Epoch 123, loss: 2.289709\n",
            "Epoch 124, loss: 2.286434\n",
            "Epoch 125, loss: 2.289424\n",
            "Epoch 126, loss: 2.293141\n",
            "Epoch 127, loss: 2.291260\n",
            "Epoch 128, loss: 2.289531\n",
            "Epoch 129, loss: 2.291427\n",
            "Epoch 130, loss: 2.287365\n",
            "Epoch 131, loss: 2.294645\n",
            "Epoch 132, loss: 2.295428\n",
            "Epoch 133, loss: 2.294564\n",
            "Epoch 134, loss: 2.291565\n",
            "Epoch 135, loss: 2.289250\n",
            "Epoch 136, loss: 2.290551\n",
            "Epoch 137, loss: 2.291678\n",
            "Epoch 138, loss: 2.291312\n",
            "Epoch 139, loss: 2.289694\n",
            "Epoch 140, loss: 2.292318\n",
            "Epoch 141, loss: 2.289339\n",
            "Epoch 142, loss: 2.288066\n",
            "Epoch 143, loss: 2.294327\n",
            "Epoch 144, loss: 2.286856\n",
            "Epoch 145, loss: 2.286641\n",
            "Epoch 146, loss: 2.287433\n",
            "Epoch 147, loss: 2.289745\n",
            "Epoch 148, loss: 2.288607\n",
            "Epoch 149, loss: 2.289217\n",
            "Epoch 150, loss: 2.288211\n",
            "Epoch 151, loss: 2.291083\n",
            "Epoch 152, loss: 2.289550\n",
            "Epoch 153, loss: 2.291570\n",
            "Epoch 154, loss: 2.290350\n",
            "Epoch 155, loss: 2.284979\n",
            "Epoch 156, loss: 2.288421\n",
            "Epoch 157, loss: 2.289251\n",
            "Epoch 158, loss: 2.286072\n",
            "Epoch 159, loss: 2.288481\n",
            "Epoch 160, loss: 2.292039\n",
            "Epoch 161, loss: 2.290926\n",
            "Epoch 162, loss: 2.286973\n",
            "Epoch 163, loss: 2.285706\n",
            "Epoch 164, loss: 2.287061\n",
            "Epoch 165, loss: 2.286748\n",
            "Epoch 166, loss: 2.284714\n",
            "Epoch 167, loss: 2.284511\n",
            "Epoch 168, loss: 2.285938\n",
            "Epoch 169, loss: 2.288354\n",
            "Epoch 170, loss: 2.290820\n",
            "Epoch 171, loss: 2.286732\n",
            "Epoch 172, loss: 2.287905\n",
            "Epoch 173, loss: 2.284322\n",
            "Epoch 174, loss: 2.283436\n",
            "Epoch 175, loss: 2.286681\n",
            "Epoch 176, loss: 2.294001\n",
            "Epoch 177, loss: 2.286798\n",
            "Epoch 178, loss: 2.283253\n",
            "Epoch 179, loss: 2.289661\n",
            "Epoch 180, loss: 2.285937\n",
            "Epoch 181, loss: 2.291778\n",
            "Epoch 182, loss: 2.287464\n",
            "Epoch 183, loss: 2.286270\n",
            "Epoch 184, loss: 2.285132\n",
            "Epoch 185, loss: 2.281507\n",
            "Epoch 186, loss: 2.287350\n",
            "Epoch 187, loss: 2.286311\n",
            "Epoch 188, loss: 2.288306\n",
            "Epoch 189, loss: 2.284250\n",
            "Epoch 190, loss: 2.286799\n",
            "Epoch 191, loss: 2.283893\n",
            "Epoch 192, loss: 2.286213\n",
            "Epoch 193, loss: 2.286209\n",
            "Epoch 194, loss: 2.287174\n",
            "Epoch 195, loss: 2.289366\n",
            "Epoch 196, loss: 2.283556\n",
            "Epoch 197, loss: 2.287161\n",
            "Epoch 198, loss: 2.286907\n",
            "Epoch 199, loss: 2.287967\n",
            "Epoch 0, loss: 2.302710\n",
            "Epoch 1, loss: 2.301350\n",
            "Epoch 2, loss: 2.303532\n",
            "Epoch 3, loss: 2.301893\n",
            "Epoch 4, loss: 2.301223\n",
            "Epoch 5, loss: 2.301198\n",
            "Epoch 6, loss: 2.302425\n",
            "Epoch 7, loss: 2.302126\n",
            "Epoch 8, loss: 2.301703\n",
            "Epoch 9, loss: 2.301511\n",
            "Epoch 10, loss: 2.302400\n",
            "Epoch 11, loss: 2.300879\n",
            "Epoch 12, loss: 2.300505\n",
            "Epoch 13, loss: 2.301941\n",
            "Epoch 14, loss: 2.301104\n",
            "Epoch 15, loss: 2.300672\n",
            "Epoch 16, loss: 2.300178\n",
            "Epoch 17, loss: 2.302234\n",
            "Epoch 18, loss: 2.299979\n",
            "Epoch 19, loss: 2.300114\n",
            "Epoch 20, loss: 2.301760\n",
            "Epoch 21, loss: 2.300805\n",
            "Epoch 22, loss: 2.300912\n",
            "Epoch 23, loss: 2.299852\n",
            "Epoch 24, loss: 2.297593\n",
            "Epoch 25, loss: 2.300193\n",
            "Epoch 26, loss: 2.300628\n",
            "Epoch 27, loss: 2.299497\n",
            "Epoch 28, loss: 2.298808\n",
            "Epoch 29, loss: 2.299659\n",
            "Epoch 30, loss: 2.298679\n",
            "Epoch 31, loss: 2.297708\n",
            "Epoch 32, loss: 2.298437\n",
            "Epoch 33, loss: 2.299871\n",
            "Epoch 34, loss: 2.299269\n",
            "Epoch 35, loss: 2.298876\n",
            "Epoch 36, loss: 2.298106\n",
            "Epoch 37, loss: 2.295611\n",
            "Epoch 38, loss: 2.298202\n",
            "Epoch 39, loss: 2.299123\n",
            "Epoch 40, loss: 2.298978\n",
            "Epoch 41, loss: 2.297345\n",
            "Epoch 42, loss: 2.296650\n",
            "Epoch 43, loss: 2.295666\n",
            "Epoch 44, loss: 2.297813\n",
            "Epoch 45, loss: 2.298941\n",
            "Epoch 46, loss: 2.296887\n",
            "Epoch 47, loss: 2.297529\n",
            "Epoch 48, loss: 2.298203\n",
            "Epoch 49, loss: 2.295897\n",
            "Epoch 50, loss: 2.299865\n",
            "Epoch 51, loss: 2.298527\n",
            "Epoch 52, loss: 2.296935\n",
            "Epoch 53, loss: 2.297963\n",
            "Epoch 54, loss: 2.295414\n",
            "Epoch 55, loss: 2.297024\n",
            "Epoch 56, loss: 2.298729\n",
            "Epoch 57, loss: 2.297778\n",
            "Epoch 58, loss: 2.295699\n",
            "Epoch 59, loss: 2.296008\n",
            "Epoch 60, loss: 2.295461\n",
            "Epoch 61, loss: 2.297389\n",
            "Epoch 62, loss: 2.299219\n",
            "Epoch 63, loss: 2.298120\n",
            "Epoch 64, loss: 2.295625\n",
            "Epoch 65, loss: 2.296120\n",
            "Epoch 66, loss: 2.295164\n",
            "Epoch 67, loss: 2.294129\n",
            "Epoch 68, loss: 2.299137\n",
            "Epoch 69, loss: 2.294940\n",
            "Epoch 70, loss: 2.300228\n",
            "Epoch 71, loss: 2.296131\n",
            "Epoch 72, loss: 2.295539\n",
            "Epoch 73, loss: 2.294675\n",
            "Epoch 74, loss: 2.294030\n",
            "Epoch 75, loss: 2.295299\n",
            "Epoch 76, loss: 2.297875\n",
            "Epoch 77, loss: 2.294849\n",
            "Epoch 78, loss: 2.297386\n",
            "Epoch 79, loss: 2.294231\n",
            "Epoch 80, loss: 2.294296\n",
            "Epoch 81, loss: 2.294825\n",
            "Epoch 82, loss: 2.295975\n",
            "Epoch 83, loss: 2.293706\n",
            "Epoch 84, loss: 2.295591\n",
            "Epoch 85, loss: 2.293521\n",
            "Epoch 86, loss: 2.291732\n",
            "Epoch 87, loss: 2.295625\n",
            "Epoch 88, loss: 2.290068\n",
            "Epoch 89, loss: 2.291864\n",
            "Epoch 90, loss: 2.295161\n",
            "Epoch 91, loss: 2.297295\n",
            "Epoch 92, loss: 2.297050\n",
            "Epoch 93, loss: 2.294518\n",
            "Epoch 94, loss: 2.292922\n",
            "Epoch 95, loss: 2.294241\n",
            "Epoch 96, loss: 2.293750\n",
            "Epoch 97, loss: 2.293431\n",
            "Epoch 98, loss: 2.293790\n",
            "Epoch 99, loss: 2.294591\n",
            "Epoch 100, loss: 2.292724\n",
            "Epoch 101, loss: 2.290406\n",
            "Epoch 102, loss: 2.293981\n",
            "Epoch 103, loss: 2.289554\n",
            "Epoch 104, loss: 2.295844\n",
            "Epoch 105, loss: 2.294653\n",
            "Epoch 106, loss: 2.287908\n",
            "Epoch 107, loss: 2.294254\n",
            "Epoch 108, loss: 2.296327\n",
            "Epoch 109, loss: 2.291067\n",
            "Epoch 110, loss: 2.294945\n",
            "Epoch 111, loss: 2.290671\n",
            "Epoch 112, loss: 2.290748\n",
            "Epoch 113, loss: 2.289221\n",
            "Epoch 114, loss: 2.293909\n",
            "Epoch 115, loss: 2.292544\n",
            "Epoch 116, loss: 2.290936\n",
            "Epoch 117, loss: 2.294110\n",
            "Epoch 118, loss: 2.291665\n",
            "Epoch 119, loss: 2.291705\n",
            "Epoch 120, loss: 2.289056\n",
            "Epoch 121, loss: 2.288621\n",
            "Epoch 122, loss: 2.289203\n",
            "Epoch 123, loss: 2.292638\n",
            "Epoch 124, loss: 2.290138\n",
            "Epoch 125, loss: 2.292321\n",
            "Epoch 126, loss: 2.288454\n",
            "Epoch 127, loss: 2.292078\n",
            "Epoch 128, loss: 2.290016\n",
            "Epoch 129, loss: 2.295343\n",
            "Epoch 130, loss: 2.287818\n",
            "Epoch 131, loss: 2.287928\n",
            "Epoch 132, loss: 2.290655\n",
            "Epoch 133, loss: 2.287713\n",
            "Epoch 134, loss: 2.291699\n",
            "Epoch 135, loss: 2.293214\n",
            "Epoch 136, loss: 2.290018\n",
            "Epoch 137, loss: 2.290619\n",
            "Epoch 138, loss: 2.285072\n",
            "Epoch 139, loss: 2.290201\n",
            "Epoch 140, loss: 2.290196\n",
            "Epoch 141, loss: 2.288307\n",
            "Epoch 142, loss: 2.292806\n",
            "Epoch 143, loss: 2.288972\n",
            "Epoch 144, loss: 2.288965\n",
            "Epoch 145, loss: 2.287739\n",
            "Epoch 146, loss: 2.292451\n",
            "Epoch 147, loss: 2.289609\n",
            "Epoch 148, loss: 2.288602\n",
            "Epoch 149, loss: 2.290806\n",
            "Epoch 150, loss: 2.290613\n",
            "Epoch 151, loss: 2.287399\n",
            "Epoch 152, loss: 2.287357\n",
            "Epoch 153, loss: 2.290295\n",
            "Epoch 154, loss: 2.289782\n",
            "Epoch 155, loss: 2.289509\n",
            "Epoch 156, loss: 2.285267\n",
            "Epoch 157, loss: 2.287559\n",
            "Epoch 158, loss: 2.283730\n",
            "Epoch 159, loss: 2.287587\n",
            "Epoch 160, loss: 2.285366\n",
            "Epoch 161, loss: 2.289097\n",
            "Epoch 162, loss: 2.286984\n",
            "Epoch 163, loss: 2.289534\n",
            "Epoch 164, loss: 2.287515\n",
            "Epoch 165, loss: 2.289426\n",
            "Epoch 166, loss: 2.287025\n",
            "Epoch 167, loss: 2.282435\n",
            "Epoch 168, loss: 2.283760\n",
            "Epoch 169, loss: 2.284701\n",
            "Epoch 170, loss: 2.290646\n",
            "Epoch 171, loss: 2.288236\n",
            "Epoch 172, loss: 2.287110\n",
            "Epoch 173, loss: 2.290053\n",
            "Epoch 174, loss: 2.286288\n",
            "Epoch 175, loss: 2.282666\n",
            "Epoch 176, loss: 2.288996\n",
            "Epoch 177, loss: 2.290012\n",
            "Epoch 178, loss: 2.286455\n",
            "Epoch 179, loss: 2.284465\n",
            "Epoch 180, loss: 2.286905\n",
            "Epoch 181, loss: 2.284711\n",
            "Epoch 182, loss: 2.287240\n",
            "Epoch 183, loss: 2.284643\n",
            "Epoch 184, loss: 2.288293\n",
            "Epoch 185, loss: 2.286621\n",
            "Epoch 186, loss: 2.286453\n",
            "Epoch 187, loss: 2.283956\n",
            "Epoch 188, loss: 2.286387\n",
            "Epoch 189, loss: 2.288282\n",
            "Epoch 190, loss: 2.287231\n",
            "Epoch 191, loss: 2.289453\n",
            "Epoch 192, loss: 2.279451\n",
            "Epoch 193, loss: 2.283989\n",
            "Epoch 194, loss: 2.283449\n",
            "Epoch 195, loss: 2.289823\n",
            "Epoch 196, loss: 2.283817\n",
            "Epoch 197, loss: 2.279624\n",
            "Epoch 198, loss: 2.285303\n",
            "Epoch 199, loss: 2.292634\n",
            "Epoch 0, loss: 2.302738\n",
            "Epoch 1, loss: 2.301969\n",
            "Epoch 2, loss: 2.301454\n",
            "Epoch 3, loss: 2.301700\n",
            "Epoch 4, loss: 2.302001\n",
            "Epoch 5, loss: 2.301094\n",
            "Epoch 6, loss: 2.301798\n",
            "Epoch 7, loss: 2.301101\n",
            "Epoch 8, loss: 2.301535\n",
            "Epoch 9, loss: 2.301681\n",
            "Epoch 10, loss: 2.302440\n",
            "Epoch 11, loss: 2.300790\n",
            "Epoch 12, loss: 2.301893\n",
            "Epoch 13, loss: 2.300217\n",
            "Epoch 14, loss: 2.300376\n",
            "Epoch 15, loss: 2.300574\n",
            "Epoch 16, loss: 2.301025\n",
            "Epoch 17, loss: 2.300989\n",
            "Epoch 18, loss: 2.298174\n",
            "Epoch 19, loss: 2.301778\n",
            "Epoch 20, loss: 2.300470\n",
            "Epoch 21, loss: 2.300771\n",
            "Epoch 22, loss: 2.301332\n",
            "Epoch 23, loss: 2.299383\n",
            "Epoch 24, loss: 2.299436\n",
            "Epoch 25, loss: 2.300539\n",
            "Epoch 26, loss: 2.300068\n",
            "Epoch 27, loss: 2.299623\n",
            "Epoch 28, loss: 2.298035\n",
            "Epoch 29, loss: 2.299007\n",
            "Epoch 30, loss: 2.299247\n",
            "Epoch 31, loss: 2.299358\n",
            "Epoch 32, loss: 2.297766\n",
            "Epoch 33, loss: 2.301141\n",
            "Epoch 34, loss: 2.298309\n",
            "Epoch 35, loss: 2.299493\n",
            "Epoch 36, loss: 2.297781\n",
            "Epoch 37, loss: 2.294923\n",
            "Epoch 38, loss: 2.298833\n",
            "Epoch 39, loss: 2.298611\n",
            "Epoch 40, loss: 2.298124\n",
            "Epoch 41, loss: 2.297936\n",
            "Epoch 42, loss: 2.298648\n",
            "Epoch 43, loss: 2.299381\n",
            "Epoch 44, loss: 2.301445\n",
            "Epoch 45, loss: 2.299742\n",
            "Epoch 46, loss: 2.297439\n",
            "Epoch 47, loss: 2.298355\n",
            "Epoch 48, loss: 2.296578\n",
            "Epoch 49, loss: 2.296433\n",
            "Epoch 50, loss: 2.298079\n",
            "Epoch 51, loss: 2.295163\n",
            "Epoch 52, loss: 2.297887\n",
            "Epoch 53, loss: 2.296713\n",
            "Epoch 54, loss: 2.298154\n",
            "Epoch 55, loss: 2.297734\n",
            "Epoch 56, loss: 2.294079\n",
            "Epoch 57, loss: 2.295029\n",
            "Epoch 58, loss: 2.295647\n",
            "Epoch 59, loss: 2.298254\n",
            "Epoch 60, loss: 2.295685\n",
            "Epoch 61, loss: 2.297160\n",
            "Epoch 62, loss: 2.296132\n",
            "Epoch 63, loss: 2.293862\n",
            "Epoch 64, loss: 2.299125\n",
            "Epoch 65, loss: 2.293454\n",
            "Epoch 66, loss: 2.299062\n",
            "Epoch 67, loss: 2.297228\n",
            "Epoch 68, loss: 2.294541\n",
            "Epoch 69, loss: 2.295483\n",
            "Epoch 70, loss: 2.298839\n",
            "Epoch 71, loss: 2.295151\n",
            "Epoch 72, loss: 2.295258\n",
            "Epoch 73, loss: 2.293743\n",
            "Epoch 74, loss: 2.296527\n",
            "Epoch 75, loss: 2.294366\n",
            "Epoch 76, loss: 2.297796\n",
            "Epoch 77, loss: 2.294913\n",
            "Epoch 78, loss: 2.298160\n",
            "Epoch 79, loss: 2.292032\n",
            "Epoch 80, loss: 2.296739\n",
            "Epoch 81, loss: 2.296037\n",
            "Epoch 82, loss: 2.294124\n",
            "Epoch 83, loss: 2.294889\n",
            "Epoch 84, loss: 2.298610\n",
            "Epoch 85, loss: 2.292893\n",
            "Epoch 86, loss: 2.291899\n",
            "Epoch 87, loss: 2.294642\n",
            "Epoch 88, loss: 2.292957\n",
            "Epoch 89, loss: 2.291551\n",
            "Epoch 90, loss: 2.296367\n",
            "Epoch 91, loss: 2.292767\n",
            "Epoch 92, loss: 2.293578\n",
            "Epoch 93, loss: 2.293833\n",
            "Epoch 94, loss: 2.293707\n",
            "Epoch 95, loss: 2.293206\n",
            "Epoch 96, loss: 2.291008\n",
            "Epoch 97, loss: 2.291950\n",
            "Epoch 98, loss: 2.293274\n",
            "Epoch 99, loss: 2.289680\n",
            "Epoch 100, loss: 2.293124\n",
            "Epoch 101, loss: 2.294684\n",
            "Epoch 102, loss: 2.289396\n",
            "Epoch 103, loss: 2.290661\n",
            "Epoch 104, loss: 2.288821\n",
            "Epoch 105, loss: 2.292150\n",
            "Epoch 106, loss: 2.295686\n",
            "Epoch 107, loss: 2.291570\n",
            "Epoch 108, loss: 2.292583\n",
            "Epoch 109, loss: 2.291036\n",
            "Epoch 110, loss: 2.290154\n",
            "Epoch 111, loss: 2.296368\n",
            "Epoch 112, loss: 2.290974\n",
            "Epoch 113, loss: 2.294448\n",
            "Epoch 114, loss: 2.286377\n",
            "Epoch 115, loss: 2.287659\n",
            "Epoch 116, loss: 2.290671\n",
            "Epoch 117, loss: 2.291722\n",
            "Epoch 118, loss: 2.292144\n",
            "Epoch 119, loss: 2.288863\n",
            "Epoch 120, loss: 2.292783\n",
            "Epoch 121, loss: 2.288928\n",
            "Epoch 122, loss: 2.290263\n",
            "Epoch 123, loss: 2.290330\n",
            "Epoch 124, loss: 2.289113\n",
            "Epoch 125, loss: 2.288729\n",
            "Epoch 126, loss: 2.289456\n",
            "Epoch 127, loss: 2.291170\n",
            "Epoch 128, loss: 2.288127\n",
            "Epoch 129, loss: 2.292158\n",
            "Epoch 130, loss: 2.286340\n",
            "Epoch 131, loss: 2.288544\n",
            "Epoch 132, loss: 2.290337\n",
            "Epoch 133, loss: 2.294024\n",
            "Epoch 134, loss: 2.284143\n",
            "Epoch 135, loss: 2.288346\n",
            "Epoch 136, loss: 2.283783\n",
            "Epoch 137, loss: 2.286471\n",
            "Epoch 138, loss: 2.287306\n",
            "Epoch 139, loss: 2.288585\n",
            "Epoch 140, loss: 2.287981\n",
            "Epoch 141, loss: 2.285621\n",
            "Epoch 142, loss: 2.293229\n",
            "Epoch 143, loss: 2.289863\n",
            "Epoch 144, loss: 2.292752\n",
            "Epoch 145, loss: 2.291315\n",
            "Epoch 146, loss: 2.287427\n",
            "Epoch 147, loss: 2.286547\n",
            "Epoch 148, loss: 2.293016\n",
            "Epoch 149, loss: 2.293929\n",
            "Epoch 150, loss: 2.290676\n",
            "Epoch 151, loss: 2.287438\n",
            "Epoch 152, loss: 2.286191\n",
            "Epoch 153, loss: 2.287646\n",
            "Epoch 154, loss: 2.290126\n",
            "Epoch 155, loss: 2.288565\n",
            "Epoch 156, loss: 2.288012\n",
            "Epoch 157, loss: 2.291051\n",
            "Epoch 158, loss: 2.284799\n",
            "Epoch 159, loss: 2.289250\n",
            "Epoch 160, loss: 2.290649\n",
            "Epoch 161, loss: 2.287901\n",
            "Epoch 162, loss: 2.291254\n",
            "Epoch 163, loss: 2.287320\n",
            "Epoch 164, loss: 2.291923\n",
            "Epoch 165, loss: 2.283634\n",
            "Epoch 166, loss: 2.288959\n",
            "Epoch 167, loss: 2.287944\n",
            "Epoch 168, loss: 2.286899\n",
            "Epoch 169, loss: 2.281397\n",
            "Epoch 170, loss: 2.288546\n",
            "Epoch 171, loss: 2.289787\n",
            "Epoch 172, loss: 2.284287\n",
            "Epoch 173, loss: 2.290361\n",
            "Epoch 174, loss: 2.287177\n",
            "Epoch 175, loss: 2.289049\n",
            "Epoch 176, loss: 2.280183\n",
            "Epoch 177, loss: 2.292811\n",
            "Epoch 178, loss: 2.286209\n",
            "Epoch 179, loss: 2.290841\n",
            "Epoch 180, loss: 2.288094\n",
            "Epoch 181, loss: 2.285443\n",
            "Epoch 182, loss: 2.286008\n",
            "Epoch 183, loss: 2.292411\n",
            "Epoch 184, loss: 2.287790\n",
            "Epoch 185, loss: 2.283669\n",
            "Epoch 186, loss: 2.280823\n",
            "Epoch 187, loss: 2.287799\n",
            "Epoch 188, loss: 2.286021\n",
            "Epoch 189, loss: 2.286506\n",
            "Epoch 190, loss: 2.289495\n",
            "Epoch 191, loss: 2.283913\n",
            "Epoch 192, loss: 2.287268\n",
            "Epoch 193, loss: 2.284705\n",
            "Epoch 194, loss: 2.279927\n",
            "Epoch 195, loss: 2.287344\n",
            "Epoch 196, loss: 2.288828\n",
            "Epoch 197, loss: 2.285985\n",
            "Epoch 198, loss: 2.283682\n",
            "Epoch 199, loss: 2.282945\n",
            "Epoch 0, loss: 2.301373\n",
            "Epoch 1, loss: 2.302263\n",
            "Epoch 2, loss: 2.302065\n",
            "Epoch 3, loss: 2.302535\n",
            "Epoch 4, loss: 2.302058\n",
            "Epoch 5, loss: 2.300807\n",
            "Epoch 6, loss: 2.302392\n",
            "Epoch 7, loss: 2.301138\n",
            "Epoch 8, loss: 2.302452\n",
            "Epoch 9, loss: 2.301676\n",
            "Epoch 10, loss: 2.301679\n",
            "Epoch 11, loss: 2.301056\n",
            "Epoch 12, loss: 2.301591\n",
            "Epoch 13, loss: 2.300889\n",
            "Epoch 14, loss: 2.300528\n",
            "Epoch 15, loss: 2.301091\n",
            "Epoch 16, loss: 2.299541\n",
            "Epoch 17, loss: 2.299310\n",
            "Epoch 18, loss: 2.299994\n",
            "Epoch 19, loss: 2.300249\n",
            "Epoch 20, loss: 2.299372\n",
            "Epoch 21, loss: 2.299872\n",
            "Epoch 22, loss: 2.301268\n",
            "Epoch 23, loss: 2.300638\n",
            "Epoch 24, loss: 2.301622\n",
            "Epoch 25, loss: 2.298401\n",
            "Epoch 26, loss: 2.300003\n",
            "Epoch 27, loss: 2.299106\n",
            "Epoch 28, loss: 2.300379\n",
            "Epoch 29, loss: 2.299344\n",
            "Epoch 30, loss: 2.299606\n",
            "Epoch 31, loss: 2.299972\n",
            "Epoch 32, loss: 2.299324\n",
            "Epoch 33, loss: 2.299946\n",
            "Epoch 34, loss: 2.297622\n",
            "Epoch 35, loss: 2.298119\n",
            "Epoch 36, loss: 2.298816\n",
            "Epoch 37, loss: 2.297215\n",
            "Epoch 38, loss: 2.300287\n",
            "Epoch 39, loss: 2.298844\n",
            "Epoch 40, loss: 2.298474\n",
            "Epoch 41, loss: 2.299007\n",
            "Epoch 42, loss: 2.297863\n",
            "Epoch 43, loss: 2.299970\n",
            "Epoch 44, loss: 2.297209\n",
            "Epoch 45, loss: 2.297904\n",
            "Epoch 46, loss: 2.300796\n",
            "Epoch 47, loss: 2.295864\n",
            "Epoch 48, loss: 2.296730\n",
            "Epoch 49, loss: 2.300747\n",
            "Epoch 50, loss: 2.297754\n",
            "Epoch 51, loss: 2.295288\n",
            "Epoch 52, loss: 2.294688\n",
            "Epoch 53, loss: 2.296728\n",
            "Epoch 54, loss: 2.298101\n",
            "Epoch 55, loss: 2.295846\n",
            "Epoch 56, loss: 2.297899\n",
            "Epoch 57, loss: 2.297806\n",
            "Epoch 58, loss: 2.295037\n",
            "Epoch 59, loss: 2.297106\n",
            "Epoch 60, loss: 2.297754\n",
            "Epoch 61, loss: 2.294857\n",
            "Epoch 62, loss: 2.296158\n",
            "Epoch 63, loss: 2.296256\n",
            "Epoch 64, loss: 2.296382\n",
            "Epoch 65, loss: 2.294662\n",
            "Epoch 66, loss: 2.299324\n",
            "Epoch 67, loss: 2.294642\n",
            "Epoch 68, loss: 2.296326\n",
            "Epoch 69, loss: 2.293973\n",
            "Epoch 70, loss: 2.295130\n",
            "Epoch 71, loss: 2.295327\n",
            "Epoch 72, loss: 2.291502\n",
            "Epoch 73, loss: 2.296083\n",
            "Epoch 74, loss: 2.296625\n",
            "Epoch 75, loss: 2.293177\n",
            "Epoch 76, loss: 2.292389\n",
            "Epoch 77, loss: 2.296452\n",
            "Epoch 78, loss: 2.293232\n",
            "Epoch 79, loss: 2.296210\n",
            "Epoch 80, loss: 2.299717\n",
            "Epoch 81, loss: 2.294428\n",
            "Epoch 82, loss: 2.296176\n",
            "Epoch 83, loss: 2.296301\n",
            "Epoch 84, loss: 2.293598\n",
            "Epoch 85, loss: 2.292008\n",
            "Epoch 86, loss: 2.293093\n",
            "Epoch 87, loss: 2.288871\n",
            "Epoch 88, loss: 2.294961\n",
            "Epoch 89, loss: 2.293486\n",
            "Epoch 90, loss: 2.291411\n",
            "Epoch 91, loss: 2.293511\n",
            "Epoch 92, loss: 2.294403\n",
            "Epoch 93, loss: 2.291842\n",
            "Epoch 94, loss: 2.294176\n",
            "Epoch 95, loss: 2.294254\n",
            "Epoch 96, loss: 2.293221\n",
            "Epoch 97, loss: 2.291258\n",
            "Epoch 98, loss: 2.292418\n",
            "Epoch 99, loss: 2.289769\n",
            "Epoch 100, loss: 2.293767\n",
            "Epoch 101, loss: 2.293576\n",
            "Epoch 102, loss: 2.293164\n",
            "Epoch 103, loss: 2.297056\n",
            "Epoch 104, loss: 2.292779\n",
            "Epoch 105, loss: 2.294491\n",
            "Epoch 106, loss: 2.293605\n",
            "Epoch 107, loss: 2.293568\n",
            "Epoch 108, loss: 2.288701\n",
            "Epoch 109, loss: 2.294819\n",
            "Epoch 110, loss: 2.289122\n",
            "Epoch 111, loss: 2.286756\n",
            "Epoch 112, loss: 2.291690\n",
            "Epoch 113, loss: 2.292971\n",
            "Epoch 114, loss: 2.291266\n",
            "Epoch 115, loss: 2.294412\n",
            "Epoch 116, loss: 2.292877\n",
            "Epoch 117, loss: 2.289394\n",
            "Epoch 118, loss: 2.294272\n",
            "Epoch 119, loss: 2.292184\n",
            "Epoch 120, loss: 2.295583\n",
            "Epoch 121, loss: 2.289613\n",
            "Epoch 122, loss: 2.291842\n",
            "Epoch 123, loss: 2.296911\n",
            "Epoch 124, loss: 2.289494\n",
            "Epoch 125, loss: 2.288400\n",
            "Epoch 126, loss: 2.294701\n",
            "Epoch 127, loss: 2.291581\n",
            "Epoch 128, loss: 2.291094\n",
            "Epoch 129, loss: 2.288170\n",
            "Epoch 130, loss: 2.293661\n",
            "Epoch 131, loss: 2.293998\n",
            "Epoch 132, loss: 2.291514\n",
            "Epoch 133, loss: 2.289754\n",
            "Epoch 134, loss: 2.294355\n",
            "Epoch 135, loss: 2.291968\n",
            "Epoch 136, loss: 2.288210\n",
            "Epoch 137, loss: 2.285443\n",
            "Epoch 138, loss: 2.288887\n",
            "Epoch 139, loss: 2.287530\n",
            "Epoch 140, loss: 2.292768\n",
            "Epoch 141, loss: 2.287079\n",
            "Epoch 142, loss: 2.291975\n",
            "Epoch 143, loss: 2.286249\n",
            "Epoch 144, loss: 2.291319\n",
            "Epoch 145, loss: 2.284764\n",
            "Epoch 146, loss: 2.290876\n",
            "Epoch 147, loss: 2.285602\n",
            "Epoch 148, loss: 2.295837\n",
            "Epoch 149, loss: 2.289343\n",
            "Epoch 150, loss: 2.289064\n",
            "Epoch 151, loss: 2.288387\n",
            "Epoch 152, loss: 2.284293\n",
            "Epoch 153, loss: 2.287856\n",
            "Epoch 154, loss: 2.287618\n",
            "Epoch 155, loss: 2.287032\n",
            "Epoch 156, loss: 2.288280\n",
            "Epoch 157, loss: 2.291848\n",
            "Epoch 158, loss: 2.286425\n",
            "Epoch 159, loss: 2.293636\n",
            "Epoch 160, loss: 2.289770\n",
            "Epoch 161, loss: 2.288546\n",
            "Epoch 162, loss: 2.288021\n",
            "Epoch 163, loss: 2.285337\n",
            "Epoch 164, loss: 2.286156\n",
            "Epoch 165, loss: 2.288513\n",
            "Epoch 166, loss: 2.287713\n",
            "Epoch 167, loss: 2.283130\n",
            "Epoch 168, loss: 2.292399\n",
            "Epoch 169, loss: 2.288320\n",
            "Epoch 170, loss: 2.285360\n",
            "Epoch 171, loss: 2.282113\n",
            "Epoch 172, loss: 2.287897\n",
            "Epoch 173, loss: 2.284125\n",
            "Epoch 174, loss: 2.288781\n",
            "Epoch 175, loss: 2.283685\n",
            "Epoch 176, loss: 2.288266\n",
            "Epoch 177, loss: 2.287010\n",
            "Epoch 178, loss: 2.291593\n",
            "Epoch 179, loss: 2.289091\n",
            "Epoch 180, loss: 2.284740\n",
            "Epoch 181, loss: 2.285183\n",
            "Epoch 182, loss: 2.288964\n",
            "Epoch 183, loss: 2.282262\n",
            "Epoch 184, loss: 2.279912\n",
            "Epoch 185, loss: 2.284106\n",
            "Epoch 186, loss: 2.288278\n",
            "Epoch 187, loss: 2.282538\n",
            "Epoch 188, loss: 2.284185\n",
            "Epoch 189, loss: 2.287458\n",
            "Epoch 190, loss: 2.286370\n",
            "Epoch 191, loss: 2.283063\n",
            "Epoch 192, loss: 2.282889\n",
            "Epoch 193, loss: 2.285532\n",
            "Epoch 194, loss: 2.280455\n",
            "Epoch 195, loss: 2.279398\n",
            "Epoch 196, loss: 2.289554\n",
            "Epoch 197, loss: 2.286962\n",
            "Epoch 198, loss: 2.281118\n",
            "Epoch 199, loss: 2.288770\n",
            "Epoch 0, loss: 2.302822\n",
            "Epoch 1, loss: 2.302342\n",
            "Epoch 2, loss: 2.302110\n",
            "Epoch 3, loss: 2.301398\n",
            "Epoch 4, loss: 2.302056\n",
            "Epoch 5, loss: 2.302394\n",
            "Epoch 6, loss: 2.302305\n",
            "Epoch 7, loss: 2.302216\n",
            "Epoch 8, loss: 2.301410\n",
            "Epoch 9, loss: 2.301745\n",
            "Epoch 10, loss: 2.302579\n",
            "Epoch 11, loss: 2.302477\n",
            "Epoch 12, loss: 2.302045\n",
            "Epoch 13, loss: 2.300940\n",
            "Epoch 14, loss: 2.301439\n",
            "Epoch 15, loss: 2.302085\n",
            "Epoch 16, loss: 2.300610\n",
            "Epoch 17, loss: 2.301568\n",
            "Epoch 18, loss: 2.299720\n",
            "Epoch 19, loss: 2.299833\n",
            "Epoch 20, loss: 2.299984\n",
            "Epoch 21, loss: 2.299906\n",
            "Epoch 22, loss: 2.301372\n",
            "Epoch 23, loss: 2.299829\n",
            "Epoch 24, loss: 2.299172\n",
            "Epoch 25, loss: 2.301153\n",
            "Epoch 26, loss: 2.300665\n",
            "Epoch 27, loss: 2.300886\n",
            "Epoch 28, loss: 2.300207\n",
            "Epoch 29, loss: 2.300316\n",
            "Epoch 30, loss: 2.297185\n",
            "Epoch 31, loss: 2.298439\n",
            "Epoch 32, loss: 2.301611\n",
            "Epoch 33, loss: 2.301399\n",
            "Epoch 34, loss: 2.301305\n",
            "Epoch 35, loss: 2.298223\n",
            "Epoch 36, loss: 2.299951\n",
            "Epoch 37, loss: 2.298018\n",
            "Epoch 38, loss: 2.298569\n",
            "Epoch 39, loss: 2.298516\n",
            "Epoch 40, loss: 2.298786\n",
            "Epoch 41, loss: 2.297096\n",
            "Epoch 42, loss: 2.297361\n",
            "Epoch 43, loss: 2.298711\n",
            "Epoch 44, loss: 2.299981\n",
            "Epoch 45, loss: 2.297795\n",
            "Epoch 46, loss: 2.295620\n",
            "Epoch 47, loss: 2.296414\n",
            "Epoch 48, loss: 2.298848\n",
            "Epoch 49, loss: 2.296802\n",
            "Epoch 50, loss: 2.299329\n",
            "Epoch 51, loss: 2.294212\n",
            "Epoch 52, loss: 2.293897\n",
            "Epoch 53, loss: 2.298385\n",
            "Epoch 54, loss: 2.297274\n",
            "Epoch 55, loss: 2.298065\n",
            "Epoch 56, loss: 2.297318\n",
            "Epoch 57, loss: 2.295972\n",
            "Epoch 58, loss: 2.297123\n",
            "Epoch 59, loss: 2.295941\n",
            "Epoch 60, loss: 2.297999\n",
            "Epoch 61, loss: 2.297839\n",
            "Epoch 62, loss: 2.296247\n",
            "Epoch 63, loss: 2.298688\n",
            "Epoch 64, loss: 2.293042\n",
            "Epoch 65, loss: 2.295446\n",
            "Epoch 66, loss: 2.294559\n",
            "Epoch 67, loss: 2.294109\n",
            "Epoch 68, loss: 2.294486\n",
            "Epoch 69, loss: 2.295921\n",
            "Epoch 70, loss: 2.297187\n",
            "Epoch 71, loss: 2.295293\n",
            "Epoch 72, loss: 2.297392\n",
            "Epoch 73, loss: 2.296501\n",
            "Epoch 74, loss: 2.294446\n",
            "Epoch 75, loss: 2.296191\n",
            "Epoch 76, loss: 2.296383\n",
            "Epoch 77, loss: 2.298468\n",
            "Epoch 78, loss: 2.296341\n",
            "Epoch 79, loss: 2.297930\n",
            "Epoch 80, loss: 2.294471\n",
            "Epoch 81, loss: 2.292472\n",
            "Epoch 82, loss: 2.295699\n",
            "Epoch 83, loss: 2.293608\n",
            "Epoch 84, loss: 2.291795\n",
            "Epoch 85, loss: 2.296613\n",
            "Epoch 86, loss: 2.296179\n",
            "Epoch 87, loss: 2.296628\n",
            "Epoch 88, loss: 2.300116\n",
            "Epoch 89, loss: 2.290767\n",
            "Epoch 90, loss: 2.294510\n",
            "Epoch 91, loss: 2.297143\n",
            "Epoch 92, loss: 2.295893\n",
            "Epoch 93, loss: 2.293858\n",
            "Epoch 94, loss: 2.295680\n",
            "Epoch 95, loss: 2.292488\n",
            "Epoch 96, loss: 2.300045\n",
            "Epoch 97, loss: 2.297632\n",
            "Epoch 98, loss: 2.294747\n",
            "Epoch 99, loss: 2.295637\n",
            "Epoch 100, loss: 2.295282\n",
            "Epoch 101, loss: 2.289080\n",
            "Epoch 102, loss: 2.292133\n",
            "Epoch 103, loss: 2.292087\n",
            "Epoch 104, loss: 2.293903\n",
            "Epoch 105, loss: 2.295465\n",
            "Epoch 106, loss: 2.295689\n",
            "Epoch 107, loss: 2.291848\n",
            "Epoch 108, loss: 2.290630\n",
            "Epoch 109, loss: 2.292886\n",
            "Epoch 110, loss: 2.293258\n",
            "Epoch 111, loss: 2.288843\n",
            "Epoch 112, loss: 2.293390\n",
            "Epoch 113, loss: 2.289116\n",
            "Epoch 114, loss: 2.290999\n",
            "Epoch 115, loss: 2.291643\n",
            "Epoch 116, loss: 2.291047\n",
            "Epoch 117, loss: 2.290725\n",
            "Epoch 118, loss: 2.289243\n",
            "Epoch 119, loss: 2.294155\n",
            "Epoch 120, loss: 2.290395\n",
            "Epoch 121, loss: 2.290747\n",
            "Epoch 122, loss: 2.290079\n",
            "Epoch 123, loss: 2.290402\n",
            "Epoch 124, loss: 2.288579\n",
            "Epoch 125, loss: 2.291634\n",
            "Epoch 126, loss: 2.289502\n",
            "Epoch 127, loss: 2.286631\n",
            "Epoch 128, loss: 2.294581\n",
            "Epoch 129, loss: 2.290423\n",
            "Epoch 130, loss: 2.286210\n",
            "Epoch 131, loss: 2.292691\n",
            "Epoch 132, loss: 2.293378\n",
            "Epoch 133, loss: 2.294094\n",
            "Epoch 134, loss: 2.290449\n",
            "Epoch 135, loss: 2.295435\n",
            "Epoch 136, loss: 2.290135\n",
            "Epoch 137, loss: 2.287949\n",
            "Epoch 138, loss: 2.295728\n",
            "Epoch 139, loss: 2.286487\n",
            "Epoch 140, loss: 2.289414\n",
            "Epoch 141, loss: 2.289663\n",
            "Epoch 142, loss: 2.287651\n",
            "Epoch 143, loss: 2.290490\n",
            "Epoch 144, loss: 2.288364\n",
            "Epoch 145, loss: 2.290277\n",
            "Epoch 146, loss: 2.294003\n",
            "Epoch 147, loss: 2.295830\n",
            "Epoch 148, loss: 2.290769\n",
            "Epoch 149, loss: 2.290088\n",
            "Epoch 150, loss: 2.285453\n",
            "Epoch 151, loss: 2.290449\n",
            "Epoch 152, loss: 2.289582\n",
            "Epoch 153, loss: 2.292150\n",
            "Epoch 154, loss: 2.293833\n",
            "Epoch 155, loss: 2.288572\n",
            "Epoch 156, loss: 2.289610\n",
            "Epoch 157, loss: 2.292427\n",
            "Epoch 158, loss: 2.287752\n",
            "Epoch 159, loss: 2.285532\n",
            "Epoch 160, loss: 2.281595\n",
            "Epoch 161, loss: 2.285045\n",
            "Epoch 162, loss: 2.284201\n",
            "Epoch 163, loss: 2.286284\n",
            "Epoch 164, loss: 2.287871\n",
            "Epoch 165, loss: 2.289812\n",
            "Epoch 166, loss: 2.284231\n",
            "Epoch 167, loss: 2.288323\n",
            "Epoch 168, loss: 2.282552\n",
            "Epoch 169, loss: 2.283771\n",
            "Epoch 170, loss: 2.287809\n",
            "Epoch 171, loss: 2.282220\n",
            "Epoch 172, loss: 2.282707\n",
            "Epoch 173, loss: 2.287388\n",
            "Epoch 174, loss: 2.287068\n",
            "Epoch 175, loss: 2.289308\n",
            "Epoch 176, loss: 2.284015\n",
            "Epoch 177, loss: 2.287259\n",
            "Epoch 178, loss: 2.284718\n",
            "Epoch 179, loss: 2.284226\n",
            "Epoch 180, loss: 2.288958\n",
            "Epoch 181, loss: 2.291742\n",
            "Epoch 182, loss: 2.287271\n",
            "Epoch 183, loss: 2.290578\n",
            "Epoch 184, loss: 2.285336\n",
            "Epoch 185, loss: 2.287112\n",
            "Epoch 186, loss: 2.289664\n",
            "Epoch 187, loss: 2.288206\n",
            "Epoch 188, loss: 2.284654\n",
            "Epoch 189, loss: 2.288346\n",
            "Epoch 190, loss: 2.295428\n",
            "Epoch 191, loss: 2.286156\n",
            "Epoch 192, loss: 2.283170\n",
            "Epoch 193, loss: 2.285006\n",
            "Epoch 194, loss: 2.286769\n",
            "Epoch 195, loss: 2.282080\n",
            "Epoch 196, loss: 2.291191\n",
            "Epoch 197, loss: 2.287268\n",
            "Epoch 198, loss: 2.287297\n",
            "Epoch 199, loss: 2.286771\n",
            "Epoch 0, loss: 2.302903\n",
            "Epoch 1, loss: 2.302442\n",
            "Epoch 2, loss: 2.302455\n",
            "Epoch 3, loss: 2.302437\n",
            "Epoch 4, loss: 2.303394\n",
            "Epoch 5, loss: 2.303521\n",
            "Epoch 6, loss: 2.302354\n",
            "Epoch 7, loss: 2.302674\n",
            "Epoch 8, loss: 2.303688\n",
            "Epoch 9, loss: 2.303099\n",
            "Epoch 10, loss: 2.303543\n",
            "Epoch 11, loss: 2.302571\n",
            "Epoch 12, loss: 2.303196\n",
            "Epoch 13, loss: 2.302632\n",
            "Epoch 14, loss: 2.302861\n",
            "Epoch 15, loss: 2.302807\n",
            "Epoch 16, loss: 2.302453\n",
            "Epoch 17, loss: 2.302112\n",
            "Epoch 18, loss: 2.302734\n",
            "Epoch 19, loss: 2.303760\n",
            "Epoch 20, loss: 2.303508\n",
            "Epoch 21, loss: 2.302390\n",
            "Epoch 22, loss: 2.302653\n",
            "Epoch 23, loss: 2.302353\n",
            "Epoch 24, loss: 2.302611\n",
            "Epoch 25, loss: 2.302262\n",
            "Epoch 26, loss: 2.303031\n",
            "Epoch 27, loss: 2.302848\n",
            "Epoch 28, loss: 2.302101\n",
            "Epoch 29, loss: 2.301907\n",
            "Epoch 30, loss: 2.303097\n",
            "Epoch 31, loss: 2.302089\n",
            "Epoch 32, loss: 2.303141\n",
            "Epoch 33, loss: 2.303533\n",
            "Epoch 34, loss: 2.302613\n",
            "Epoch 35, loss: 2.303216\n",
            "Epoch 36, loss: 2.302234\n",
            "Epoch 37, loss: 2.301995\n",
            "Epoch 38, loss: 2.301598\n",
            "Epoch 39, loss: 2.303250\n",
            "Epoch 40, loss: 2.301802\n",
            "Epoch 41, loss: 2.303351\n",
            "Epoch 42, loss: 2.302271\n",
            "Epoch 43, loss: 2.302187\n",
            "Epoch 44, loss: 2.302475\n",
            "Epoch 45, loss: 2.302559\n",
            "Epoch 46, loss: 2.302083\n",
            "Epoch 47, loss: 2.301378\n",
            "Epoch 48, loss: 2.302877\n",
            "Epoch 49, loss: 2.302066\n",
            "Epoch 50, loss: 2.302341\n",
            "Epoch 51, loss: 2.302394\n",
            "Epoch 52, loss: 2.302062\n",
            "Epoch 53, loss: 2.302859\n",
            "Epoch 54, loss: 2.302901\n",
            "Epoch 55, loss: 2.302688\n",
            "Epoch 56, loss: 2.301335\n",
            "Epoch 57, loss: 2.301955\n",
            "Epoch 58, loss: 2.302798\n",
            "Epoch 59, loss: 2.301690\n",
            "Epoch 60, loss: 2.302605\n",
            "Epoch 61, loss: 2.302283\n",
            "Epoch 62, loss: 2.303228\n",
            "Epoch 63, loss: 2.302232\n",
            "Epoch 64, loss: 2.302117\n",
            "Epoch 65, loss: 2.301422\n",
            "Epoch 66, loss: 2.302305\n",
            "Epoch 67, loss: 2.302998\n",
            "Epoch 68, loss: 2.301382\n",
            "Epoch 69, loss: 2.302288\n",
            "Epoch 70, loss: 2.301873\n",
            "Epoch 71, loss: 2.301634\n",
            "Epoch 72, loss: 2.302754\n",
            "Epoch 73, loss: 2.302855\n",
            "Epoch 74, loss: 2.301391\n",
            "Epoch 75, loss: 2.301693\n",
            "Epoch 76, loss: 2.302745\n",
            "Epoch 77, loss: 2.302712\n",
            "Epoch 78, loss: 2.303143\n",
            "Epoch 79, loss: 2.303045\n",
            "Epoch 80, loss: 2.303321\n",
            "Epoch 81, loss: 2.301793\n",
            "Epoch 82, loss: 2.301743\n",
            "Epoch 83, loss: 2.302257\n",
            "Epoch 84, loss: 2.302731\n",
            "Epoch 85, loss: 2.301839\n",
            "Epoch 86, loss: 2.300913\n",
            "Epoch 87, loss: 2.302554\n",
            "Epoch 88, loss: 2.301703\n",
            "Epoch 89, loss: 2.301101\n",
            "Epoch 90, loss: 2.302097\n",
            "Epoch 91, loss: 2.301695\n",
            "Epoch 92, loss: 2.301966\n",
            "Epoch 93, loss: 2.300938\n",
            "Epoch 94, loss: 2.301695\n",
            "Epoch 95, loss: 2.300911\n",
            "Epoch 96, loss: 2.302069\n",
            "Epoch 97, loss: 2.302098\n",
            "Epoch 98, loss: 2.301946\n",
            "Epoch 99, loss: 2.301988\n",
            "Epoch 100, loss: 2.302086\n",
            "Epoch 101, loss: 2.302097\n",
            "Epoch 102, loss: 2.301744\n",
            "Epoch 103, loss: 2.301866\n",
            "Epoch 104, loss: 2.302492\n",
            "Epoch 105, loss: 2.301484\n",
            "Epoch 106, loss: 2.302285\n",
            "Epoch 107, loss: 2.301036\n",
            "Epoch 108, loss: 2.301629\n",
            "Epoch 109, loss: 2.302469\n",
            "Epoch 110, loss: 2.301249\n",
            "Epoch 111, loss: 2.302034\n",
            "Epoch 112, loss: 2.301508\n",
            "Epoch 113, loss: 2.302225\n",
            "Epoch 114, loss: 2.301467\n",
            "Epoch 115, loss: 2.302051\n",
            "Epoch 116, loss: 2.301093\n",
            "Epoch 117, loss: 2.302286\n",
            "Epoch 118, loss: 2.300749\n",
            "Epoch 119, loss: 2.301207\n",
            "Epoch 120, loss: 2.301293\n",
            "Epoch 121, loss: 2.302718\n",
            "Epoch 122, loss: 2.302074\n",
            "Epoch 123, loss: 2.301274\n",
            "Epoch 124, loss: 2.301190\n",
            "Epoch 125, loss: 2.301443\n",
            "Epoch 126, loss: 2.301804\n",
            "Epoch 127, loss: 2.301450\n",
            "Epoch 128, loss: 2.301952\n",
            "Epoch 129, loss: 2.302015\n",
            "Epoch 130, loss: 2.301244\n",
            "Epoch 131, loss: 2.301885\n",
            "Epoch 132, loss: 2.301192\n",
            "Epoch 133, loss: 2.302019\n",
            "Epoch 134, loss: 2.302169\n",
            "Epoch 135, loss: 2.300850\n",
            "Epoch 136, loss: 2.301856\n",
            "Epoch 137, loss: 2.302782\n",
            "Epoch 138, loss: 2.301328\n",
            "Epoch 139, loss: 2.300850\n",
            "Epoch 140, loss: 2.301163\n",
            "Epoch 141, loss: 2.301557\n",
            "Epoch 142, loss: 2.302162\n",
            "Epoch 143, loss: 2.300599\n",
            "Epoch 144, loss: 2.301410\n",
            "Epoch 145, loss: 2.301504\n",
            "Epoch 146, loss: 2.300520\n",
            "Epoch 147, loss: 2.301166\n",
            "Epoch 148, loss: 2.301333\n",
            "Epoch 149, loss: 2.301155\n",
            "Epoch 150, loss: 2.300684\n",
            "Epoch 151, loss: 2.301171\n",
            "Epoch 152, loss: 2.300700\n",
            "Epoch 153, loss: 2.301493\n",
            "Epoch 154, loss: 2.301143\n",
            "Epoch 155, loss: 2.301729\n",
            "Epoch 156, loss: 2.301419\n",
            "Epoch 157, loss: 2.301115\n",
            "Epoch 158, loss: 2.301395\n",
            "Epoch 159, loss: 2.301505\n",
            "Epoch 160, loss: 2.302565\n",
            "Epoch 161, loss: 2.300809\n",
            "Epoch 162, loss: 2.301718\n",
            "Epoch 163, loss: 2.302133\n",
            "Epoch 164, loss: 2.300259\n",
            "Epoch 165, loss: 2.302044\n",
            "Epoch 166, loss: 2.300454\n",
            "Epoch 167, loss: 2.301306\n",
            "Epoch 168, loss: 2.301343\n",
            "Epoch 169, loss: 2.301006\n",
            "Epoch 170, loss: 2.301379\n",
            "Epoch 171, loss: 2.301731\n",
            "Epoch 172, loss: 2.301180\n",
            "Epoch 173, loss: 2.299979\n",
            "Epoch 174, loss: 2.301049\n",
            "Epoch 175, loss: 2.301201\n",
            "Epoch 176, loss: 2.301160\n",
            "Epoch 177, loss: 2.300865\n",
            "Epoch 178, loss: 2.300196\n",
            "Epoch 179, loss: 2.301306\n",
            "Epoch 180, loss: 2.301259\n",
            "Epoch 181, loss: 2.301535\n",
            "Epoch 182, loss: 2.301287\n",
            "Epoch 183, loss: 2.301295\n",
            "Epoch 184, loss: 2.300460\n",
            "Epoch 185, loss: 2.301163\n",
            "Epoch 186, loss: 2.301849\n",
            "Epoch 187, loss: 2.301615\n",
            "Epoch 188, loss: 2.300362\n",
            "Epoch 189, loss: 2.301023\n",
            "Epoch 190, loss: 2.300828\n",
            "Epoch 191, loss: 2.300170\n",
            "Epoch 192, loss: 2.300266\n",
            "Epoch 193, loss: 2.301697\n",
            "Epoch 194, loss: 2.300548\n",
            "Epoch 195, loss: 2.300123\n",
            "Epoch 196, loss: 2.301056\n",
            "Epoch 197, loss: 2.300488\n",
            "Epoch 198, loss: 2.301601\n",
            "Epoch 199, loss: 2.300952\n",
            "Epoch 0, loss: 2.303218\n",
            "Epoch 1, loss: 2.303586\n",
            "Epoch 2, loss: 2.302521\n",
            "Epoch 3, loss: 2.302890\n",
            "Epoch 4, loss: 2.302416\n",
            "Epoch 5, loss: 2.303572\n",
            "Epoch 6, loss: 2.302802\n",
            "Epoch 7, loss: 2.303189\n",
            "Epoch 8, loss: 2.302848\n",
            "Epoch 9, loss: 2.302835\n",
            "Epoch 10, loss: 2.302476\n",
            "Epoch 11, loss: 2.301765\n",
            "Epoch 12, loss: 2.303431\n",
            "Epoch 13, loss: 2.303814\n",
            "Epoch 14, loss: 2.302512\n",
            "Epoch 15, loss: 2.302427\n",
            "Epoch 16, loss: 2.302219\n",
            "Epoch 17, loss: 2.302866\n",
            "Epoch 18, loss: 2.302710\n",
            "Epoch 19, loss: 2.302555\n",
            "Epoch 20, loss: 2.302742\n",
            "Epoch 21, loss: 2.302803\n",
            "Epoch 22, loss: 2.302738\n",
            "Epoch 23, loss: 2.303226\n",
            "Epoch 24, loss: 2.302442\n",
            "Epoch 25, loss: 2.303399\n",
            "Epoch 26, loss: 2.302944\n",
            "Epoch 27, loss: 2.302474\n",
            "Epoch 28, loss: 2.303372\n",
            "Epoch 29, loss: 2.302470\n",
            "Epoch 30, loss: 2.302727\n",
            "Epoch 31, loss: 2.302629\n",
            "Epoch 32, loss: 2.302647\n",
            "Epoch 33, loss: 2.301718\n",
            "Epoch 34, loss: 2.302947\n",
            "Epoch 35, loss: 2.302497\n",
            "Epoch 36, loss: 2.302441\n",
            "Epoch 37, loss: 2.302890\n",
            "Epoch 38, loss: 2.302923\n",
            "Epoch 39, loss: 2.302727\n",
            "Epoch 40, loss: 2.302363\n",
            "Epoch 41, loss: 2.302636\n",
            "Epoch 42, loss: 2.302202\n",
            "Epoch 43, loss: 2.302430\n",
            "Epoch 44, loss: 2.302875\n",
            "Epoch 45, loss: 2.301977\n",
            "Epoch 46, loss: 2.302037\n",
            "Epoch 47, loss: 2.302757\n",
            "Epoch 48, loss: 2.302752\n",
            "Epoch 49, loss: 2.302194\n",
            "Epoch 50, loss: 2.302829\n",
            "Epoch 51, loss: 2.302327\n",
            "Epoch 52, loss: 2.302388\n",
            "Epoch 53, loss: 2.301651\n",
            "Epoch 54, loss: 2.302065\n",
            "Epoch 55, loss: 2.303015\n",
            "Epoch 56, loss: 2.301956\n",
            "Epoch 57, loss: 2.302792\n",
            "Epoch 58, loss: 2.301635\n",
            "Epoch 59, loss: 2.302444\n",
            "Epoch 60, loss: 2.301548\n",
            "Epoch 61, loss: 2.302038\n",
            "Epoch 62, loss: 2.302379\n",
            "Epoch 63, loss: 2.302216\n",
            "Epoch 64, loss: 2.302522\n",
            "Epoch 65, loss: 2.302481\n",
            "Epoch 66, loss: 2.302116\n",
            "Epoch 67, loss: 2.302926\n",
            "Epoch 68, loss: 2.301507\n",
            "Epoch 69, loss: 2.302067\n",
            "Epoch 70, loss: 2.301669\n",
            "Epoch 71, loss: 2.301333\n",
            "Epoch 72, loss: 2.301668\n",
            "Epoch 73, loss: 2.302181\n",
            "Epoch 74, loss: 2.301868\n",
            "Epoch 75, loss: 2.301546\n",
            "Epoch 76, loss: 2.303113\n",
            "Epoch 77, loss: 2.302291\n",
            "Epoch 78, loss: 2.302359\n",
            "Epoch 79, loss: 2.301753\n",
            "Epoch 80, loss: 2.301907\n",
            "Epoch 81, loss: 2.301900\n",
            "Epoch 82, loss: 2.301806\n",
            "Epoch 83, loss: 2.301767\n",
            "Epoch 84, loss: 2.301600\n",
            "Epoch 85, loss: 2.302703\n",
            "Epoch 86, loss: 2.300865\n",
            "Epoch 87, loss: 2.301764\n",
            "Epoch 88, loss: 2.303195\n",
            "Epoch 89, loss: 2.302515\n",
            "Epoch 90, loss: 2.301876\n",
            "Epoch 91, loss: 2.301891\n",
            "Epoch 92, loss: 2.301891\n",
            "Epoch 93, loss: 2.302104\n",
            "Epoch 94, loss: 2.301561\n",
            "Epoch 95, loss: 2.301108\n",
            "Epoch 96, loss: 2.301325\n",
            "Epoch 97, loss: 2.301659\n",
            "Epoch 98, loss: 2.301875\n",
            "Epoch 99, loss: 2.301085\n",
            "Epoch 100, loss: 2.302221\n",
            "Epoch 101, loss: 2.301695\n",
            "Epoch 102, loss: 2.301764\n",
            "Epoch 103, loss: 2.301275\n",
            "Epoch 104, loss: 2.301555\n",
            "Epoch 105, loss: 2.302361\n",
            "Epoch 106, loss: 2.301621\n",
            "Epoch 107, loss: 2.301469\n",
            "Epoch 108, loss: 2.301963\n",
            "Epoch 109, loss: 2.301176\n",
            "Epoch 110, loss: 2.301654\n",
            "Epoch 111, loss: 2.301156\n",
            "Epoch 112, loss: 2.300940\n",
            "Epoch 113, loss: 2.302084\n",
            "Epoch 114, loss: 2.301574\n",
            "Epoch 115, loss: 2.300556\n",
            "Epoch 116, loss: 2.301790\n",
            "Epoch 117, loss: 2.301364\n",
            "Epoch 118, loss: 2.302063\n",
            "Epoch 119, loss: 2.301422\n",
            "Epoch 120, loss: 2.301738\n",
            "Epoch 121, loss: 2.301748\n",
            "Epoch 122, loss: 2.301640\n",
            "Epoch 123, loss: 2.301608\n",
            "Epoch 124, loss: 2.301835\n",
            "Epoch 125, loss: 2.301546\n",
            "Epoch 126, loss: 2.301601\n",
            "Epoch 127, loss: 2.302019\n",
            "Epoch 128, loss: 2.301016\n",
            "Epoch 129, loss: 2.301684\n",
            "Epoch 130, loss: 2.301631\n",
            "Epoch 131, loss: 2.301957\n",
            "Epoch 132, loss: 2.300107\n",
            "Epoch 133, loss: 2.301761\n",
            "Epoch 134, loss: 2.301749\n",
            "Epoch 135, loss: 2.301318\n",
            "Epoch 136, loss: 2.301039\n",
            "Epoch 137, loss: 2.302181\n",
            "Epoch 138, loss: 2.301575\n",
            "Epoch 139, loss: 2.300932\n",
            "Epoch 140, loss: 2.301990\n",
            "Epoch 141, loss: 2.300445\n",
            "Epoch 142, loss: 2.302015\n",
            "Epoch 143, loss: 2.301286\n",
            "Epoch 144, loss: 2.301512\n",
            "Epoch 145, loss: 2.301076\n",
            "Epoch 146, loss: 2.300369\n",
            "Epoch 147, loss: 2.301460\n",
            "Epoch 148, loss: 2.302324\n",
            "Epoch 149, loss: 2.301034\n",
            "Epoch 150, loss: 2.301399\n",
            "Epoch 151, loss: 2.300624\n",
            "Epoch 152, loss: 2.301429\n",
            "Epoch 153, loss: 2.301151\n",
            "Epoch 154, loss: 2.301164\n",
            "Epoch 155, loss: 2.300964\n",
            "Epoch 156, loss: 2.300998\n",
            "Epoch 157, loss: 2.301128\n",
            "Epoch 158, loss: 2.300975\n",
            "Epoch 159, loss: 2.301935\n",
            "Epoch 160, loss: 2.301642\n",
            "Epoch 161, loss: 2.299761\n",
            "Epoch 162, loss: 2.301130\n",
            "Epoch 163, loss: 2.301737\n",
            "Epoch 164, loss: 2.300813\n",
            "Epoch 165, loss: 2.301008\n",
            "Epoch 166, loss: 2.301189\n",
            "Epoch 167, loss: 2.300684\n",
            "Epoch 168, loss: 2.301696\n",
            "Epoch 169, loss: 2.301401\n",
            "Epoch 170, loss: 2.300190\n",
            "Epoch 171, loss: 2.300620\n",
            "Epoch 172, loss: 2.301452\n",
            "Epoch 173, loss: 2.300998\n",
            "Epoch 174, loss: 2.300778\n",
            "Epoch 175, loss: 2.300758\n",
            "Epoch 176, loss: 2.301625\n",
            "Epoch 177, loss: 2.300905\n",
            "Epoch 178, loss: 2.301172\n",
            "Epoch 179, loss: 2.300491\n",
            "Epoch 180, loss: 2.300650\n",
            "Epoch 181, loss: 2.300362\n",
            "Epoch 182, loss: 2.301160\n",
            "Epoch 183, loss: 2.300694\n",
            "Epoch 184, loss: 2.299725\n",
            "Epoch 185, loss: 2.301126\n",
            "Epoch 186, loss: 2.301058\n",
            "Epoch 187, loss: 2.300654\n",
            "Epoch 188, loss: 2.300318\n",
            "Epoch 189, loss: 2.300430\n",
            "Epoch 190, loss: 2.300256\n",
            "Epoch 191, loss: 2.300763\n",
            "Epoch 192, loss: 2.301595\n",
            "Epoch 193, loss: 2.301974\n",
            "Epoch 194, loss: 2.299829\n",
            "Epoch 195, loss: 2.300632\n",
            "Epoch 196, loss: 2.300535\n",
            "Epoch 197, loss: 2.300736\n",
            "Epoch 198, loss: 2.300937\n",
            "Epoch 199, loss: 2.300277\n",
            "Epoch 0, loss: 2.302585\n",
            "Epoch 1, loss: 2.302774\n",
            "Epoch 2, loss: 2.303438\n",
            "Epoch 3, loss: 2.303131\n",
            "Epoch 4, loss: 2.303294\n",
            "Epoch 5, loss: 2.303138\n",
            "Epoch 6, loss: 2.302723\n",
            "Epoch 7, loss: 2.302407\n",
            "Epoch 8, loss: 2.302418\n",
            "Epoch 9, loss: 2.302939\n",
            "Epoch 10, loss: 2.302793\n",
            "Epoch 11, loss: 2.302447\n",
            "Epoch 12, loss: 2.302554\n",
            "Epoch 13, loss: 2.302861\n",
            "Epoch 14, loss: 2.302345\n",
            "Epoch 15, loss: 2.302555\n",
            "Epoch 16, loss: 2.302884\n",
            "Epoch 17, loss: 2.302711\n",
            "Epoch 18, loss: 2.303112\n",
            "Epoch 19, loss: 2.302642\n",
            "Epoch 20, loss: 2.301917\n",
            "Epoch 21, loss: 2.302163\n",
            "Epoch 22, loss: 2.302685\n",
            "Epoch 23, loss: 2.302260\n",
            "Epoch 24, loss: 2.303422\n",
            "Epoch 25, loss: 2.302766\n",
            "Epoch 26, loss: 2.301659\n",
            "Epoch 27, loss: 2.302253\n",
            "Epoch 28, loss: 2.302372\n",
            "Epoch 29, loss: 2.302200\n",
            "Epoch 30, loss: 2.301999\n",
            "Epoch 31, loss: 2.302053\n",
            "Epoch 32, loss: 2.301720\n",
            "Epoch 33, loss: 2.302069\n",
            "Epoch 34, loss: 2.302957\n",
            "Epoch 35, loss: 2.302333\n",
            "Epoch 36, loss: 2.301158\n",
            "Epoch 37, loss: 2.303140\n",
            "Epoch 38, loss: 2.301401\n",
            "Epoch 39, loss: 2.301932\n",
            "Epoch 40, loss: 2.301574\n",
            "Epoch 41, loss: 2.302021\n",
            "Epoch 42, loss: 2.302485\n",
            "Epoch 43, loss: 2.302001\n",
            "Epoch 44, loss: 2.302130\n",
            "Epoch 45, loss: 2.302676\n",
            "Epoch 46, loss: 2.301444\n",
            "Epoch 47, loss: 2.301668\n",
            "Epoch 48, loss: 2.302154\n",
            "Epoch 49, loss: 2.302172\n",
            "Epoch 50, loss: 2.302289\n",
            "Epoch 51, loss: 2.301939\n",
            "Epoch 52, loss: 2.302332\n",
            "Epoch 53, loss: 2.302652\n",
            "Epoch 54, loss: 2.302818\n",
            "Epoch 55, loss: 2.302383\n",
            "Epoch 56, loss: 2.302846\n",
            "Epoch 57, loss: 2.302043\n",
            "Epoch 58, loss: 2.302194\n",
            "Epoch 59, loss: 2.302430\n",
            "Epoch 60, loss: 2.301738\n",
            "Epoch 61, loss: 2.301950\n",
            "Epoch 62, loss: 2.301460\n",
            "Epoch 63, loss: 2.302462\n",
            "Epoch 64, loss: 2.302358\n",
            "Epoch 65, loss: 2.301368\n",
            "Epoch 66, loss: 2.302326\n",
            "Epoch 67, loss: 2.302023\n",
            "Epoch 68, loss: 2.302038\n",
            "Epoch 69, loss: 2.302224\n",
            "Epoch 70, loss: 2.301714\n",
            "Epoch 71, loss: 2.301597\n",
            "Epoch 72, loss: 2.301182\n",
            "Epoch 73, loss: 2.301875\n",
            "Epoch 74, loss: 2.301689\n",
            "Epoch 75, loss: 2.301694\n",
            "Epoch 76, loss: 2.301198\n",
            "Epoch 77, loss: 2.301746\n",
            "Epoch 78, loss: 2.300531\n",
            "Epoch 79, loss: 2.302193\n",
            "Epoch 80, loss: 2.300785\n",
            "Epoch 81, loss: 2.301456\n",
            "Epoch 82, loss: 2.302067\n",
            "Epoch 83, loss: 2.301816\n",
            "Epoch 84, loss: 2.302095\n",
            "Epoch 85, loss: 2.301392\n",
            "Epoch 86, loss: 2.301540\n",
            "Epoch 87, loss: 2.301193\n",
            "Epoch 88, loss: 2.301521\n",
            "Epoch 89, loss: 2.301529\n",
            "Epoch 90, loss: 2.301329\n",
            "Epoch 91, loss: 2.302024\n",
            "Epoch 92, loss: 2.301667\n",
            "Epoch 93, loss: 2.300855\n",
            "Epoch 94, loss: 2.302591\n",
            "Epoch 95, loss: 2.302867\n",
            "Epoch 96, loss: 2.302428\n",
            "Epoch 97, loss: 2.301856\n",
            "Epoch 98, loss: 2.301348\n",
            "Epoch 99, loss: 2.301997\n",
            "Epoch 100, loss: 2.301729\n",
            "Epoch 101, loss: 2.301125\n",
            "Epoch 102, loss: 2.302044\n",
            "Epoch 103, loss: 2.301943\n",
            "Epoch 104, loss: 2.302084\n",
            "Epoch 105, loss: 2.301615\n",
            "Epoch 106, loss: 2.300881\n",
            "Epoch 107, loss: 2.301607\n",
            "Epoch 108, loss: 2.301825\n",
            "Epoch 109, loss: 2.301689\n",
            "Epoch 110, loss: 2.301006\n",
            "Epoch 111, loss: 2.301239\n",
            "Epoch 112, loss: 2.301787\n",
            "Epoch 113, loss: 2.302638\n",
            "Epoch 114, loss: 2.301576\n",
            "Epoch 115, loss: 2.300934\n",
            "Epoch 116, loss: 2.301411\n",
            "Epoch 117, loss: 2.299813\n",
            "Epoch 118, loss: 2.300977\n",
            "Epoch 119, loss: 2.300732\n",
            "Epoch 120, loss: 2.300584\n",
            "Epoch 121, loss: 2.302261\n",
            "Epoch 122, loss: 2.300556\n",
            "Epoch 123, loss: 2.301002\n",
            "Epoch 124, loss: 2.301551\n",
            "Epoch 125, loss: 2.301086\n",
            "Epoch 126, loss: 2.301098\n",
            "Epoch 127, loss: 2.300548\n",
            "Epoch 128, loss: 2.302112\n",
            "Epoch 129, loss: 2.300633\n",
            "Epoch 130, loss: 2.300793\n",
            "Epoch 131, loss: 2.301059\n",
            "Epoch 132, loss: 2.301319\n",
            "Epoch 133, loss: 2.301404\n",
            "Epoch 134, loss: 2.301390\n",
            "Epoch 135, loss: 2.301759\n",
            "Epoch 136, loss: 2.301523\n",
            "Epoch 137, loss: 2.300547\n",
            "Epoch 138, loss: 2.301606\n",
            "Epoch 139, loss: 2.301547\n",
            "Epoch 140, loss: 2.300852\n",
            "Epoch 141, loss: 2.301029\n",
            "Epoch 142, loss: 2.300283\n",
            "Epoch 143, loss: 2.300051\n",
            "Epoch 144, loss: 2.300530\n",
            "Epoch 145, loss: 2.300586\n",
            "Epoch 146, loss: 2.301259\n",
            "Epoch 147, loss: 2.300385\n",
            "Epoch 148, loss: 2.301168\n",
            "Epoch 149, loss: 2.301639\n",
            "Epoch 150, loss: 2.301529\n",
            "Epoch 151, loss: 2.302748\n",
            "Epoch 152, loss: 2.300364\n",
            "Epoch 153, loss: 2.301830\n",
            "Epoch 154, loss: 2.300730\n",
            "Epoch 155, loss: 2.299411\n",
            "Epoch 156, loss: 2.301367\n",
            "Epoch 157, loss: 2.300317\n",
            "Epoch 158, loss: 2.301144\n",
            "Epoch 159, loss: 2.300000\n",
            "Epoch 160, loss: 2.300401\n",
            "Epoch 161, loss: 2.300716\n",
            "Epoch 162, loss: 2.300723\n",
            "Epoch 163, loss: 2.301174\n",
            "Epoch 164, loss: 2.301626\n",
            "Epoch 165, loss: 2.300616\n",
            "Epoch 166, loss: 2.299672\n",
            "Epoch 167, loss: 2.299642\n",
            "Epoch 168, loss: 2.300315\n",
            "Epoch 169, loss: 2.300431\n",
            "Epoch 170, loss: 2.300911\n",
            "Epoch 171, loss: 2.300452\n",
            "Epoch 172, loss: 2.300765\n",
            "Epoch 173, loss: 2.300305\n",
            "Epoch 174, loss: 2.300845\n",
            "Epoch 175, loss: 2.300509\n",
            "Epoch 176, loss: 2.301718\n",
            "Epoch 177, loss: 2.302475\n",
            "Epoch 178, loss: 2.300311\n",
            "Epoch 179, loss: 2.300422\n",
            "Epoch 180, loss: 2.301245\n",
            "Epoch 181, loss: 2.300316\n",
            "Epoch 182, loss: 2.299922\n",
            "Epoch 183, loss: 2.300533\n",
            "Epoch 184, loss: 2.302763\n",
            "Epoch 185, loss: 2.299799\n",
            "Epoch 186, loss: 2.300779\n",
            "Epoch 187, loss: 2.298547\n",
            "Epoch 188, loss: 2.300475\n",
            "Epoch 189, loss: 2.299993\n",
            "Epoch 190, loss: 2.300542\n",
            "Epoch 191, loss: 2.301665\n",
            "Epoch 192, loss: 2.302514\n",
            "Epoch 193, loss: 2.301167\n",
            "Epoch 194, loss: 2.301363\n",
            "Epoch 195, loss: 2.299567\n",
            "Epoch 196, loss: 2.299515\n",
            "Epoch 197, loss: 2.299900\n",
            "Epoch 198, loss: 2.301602\n",
            "Epoch 199, loss: 2.300137\n",
            "Epoch 0, loss: 2.302751\n",
            "Epoch 1, loss: 2.302696\n",
            "Epoch 2, loss: 2.302775\n",
            "Epoch 3, loss: 2.301809\n",
            "Epoch 4, loss: 2.302340\n",
            "Epoch 5, loss: 2.302978\n",
            "Epoch 6, loss: 2.301757\n",
            "Epoch 7, loss: 2.303005\n",
            "Epoch 8, loss: 2.302466\n",
            "Epoch 9, loss: 2.302155\n",
            "Epoch 10, loss: 2.302508\n",
            "Epoch 11, loss: 2.302540\n",
            "Epoch 12, loss: 2.302227\n",
            "Epoch 13, loss: 2.302262\n",
            "Epoch 14, loss: 2.303271\n",
            "Epoch 15, loss: 2.302480\n",
            "Epoch 16, loss: 2.302068\n",
            "Epoch 17, loss: 2.302442\n",
            "Epoch 18, loss: 2.301712\n",
            "Epoch 19, loss: 2.302733\n",
            "Epoch 20, loss: 2.302828\n",
            "Epoch 21, loss: 2.302099\n",
            "Epoch 22, loss: 2.302224\n",
            "Epoch 23, loss: 2.302667\n",
            "Epoch 24, loss: 2.302601\n",
            "Epoch 25, loss: 2.301746\n",
            "Epoch 26, loss: 2.303252\n",
            "Epoch 27, loss: 2.300694\n",
            "Epoch 28, loss: 2.302230\n",
            "Epoch 29, loss: 2.301672\n",
            "Epoch 30, loss: 2.302316\n",
            "Epoch 31, loss: 2.301803\n",
            "Epoch 32, loss: 2.303107\n",
            "Epoch 33, loss: 2.302408\n",
            "Epoch 34, loss: 2.302523\n",
            "Epoch 35, loss: 2.302888\n",
            "Epoch 36, loss: 2.302804\n",
            "Epoch 37, loss: 2.302316\n",
            "Epoch 38, loss: 2.302329\n",
            "Epoch 39, loss: 2.301984\n",
            "Epoch 40, loss: 2.302314\n",
            "Epoch 41, loss: 2.302046\n",
            "Epoch 42, loss: 2.301799\n",
            "Epoch 43, loss: 2.302221\n",
            "Epoch 44, loss: 2.302212\n",
            "Epoch 45, loss: 2.302302\n",
            "Epoch 46, loss: 2.302171\n",
            "Epoch 47, loss: 2.301843\n",
            "Epoch 48, loss: 2.302052\n",
            "Epoch 49, loss: 2.302896\n",
            "Epoch 50, loss: 2.301816\n",
            "Epoch 51, loss: 2.301664\n",
            "Epoch 52, loss: 2.302131\n",
            "Epoch 53, loss: 2.302208\n",
            "Epoch 54, loss: 2.301129\n",
            "Epoch 55, loss: 2.302029\n",
            "Epoch 56, loss: 2.302467\n",
            "Epoch 57, loss: 2.302087\n",
            "Epoch 58, loss: 2.302983\n",
            "Epoch 59, loss: 2.302871\n",
            "Epoch 60, loss: 2.302446\n",
            "Epoch 61, loss: 2.302107\n",
            "Epoch 62, loss: 2.301229\n",
            "Epoch 63, loss: 2.301070\n",
            "Epoch 64, loss: 2.303201\n",
            "Epoch 65, loss: 2.302495\n",
            "Epoch 66, loss: 2.302486\n",
            "Epoch 67, loss: 2.302031\n",
            "Epoch 68, loss: 2.302148\n",
            "Epoch 69, loss: 2.302175\n",
            "Epoch 70, loss: 2.302207\n",
            "Epoch 71, loss: 2.301250\n",
            "Epoch 72, loss: 2.301510\n",
            "Epoch 73, loss: 2.302628\n",
            "Epoch 74, loss: 2.301915\n",
            "Epoch 75, loss: 2.302302\n",
            "Epoch 76, loss: 2.301249\n",
            "Epoch 77, loss: 2.302074\n",
            "Epoch 78, loss: 2.302139\n",
            "Epoch 79, loss: 2.301291\n",
            "Epoch 80, loss: 2.301769\n",
            "Epoch 81, loss: 2.302825\n",
            "Epoch 82, loss: 2.302762\n",
            "Epoch 83, loss: 2.302081\n",
            "Epoch 84, loss: 2.301637\n",
            "Epoch 85, loss: 2.301771\n",
            "Epoch 86, loss: 2.301804\n",
            "Epoch 87, loss: 2.301644\n",
            "Epoch 88, loss: 2.301645\n",
            "Epoch 89, loss: 2.302226\n",
            "Epoch 90, loss: 2.300979\n",
            "Epoch 91, loss: 2.299830\n",
            "Epoch 92, loss: 2.302049\n",
            "Epoch 93, loss: 2.301171\n",
            "Epoch 94, loss: 2.301549\n",
            "Epoch 95, loss: 2.301164\n",
            "Epoch 96, loss: 2.301775\n",
            "Epoch 97, loss: 2.301017\n",
            "Epoch 98, loss: 2.300614\n",
            "Epoch 99, loss: 2.301668\n",
            "Epoch 100, loss: 2.301293\n",
            "Epoch 101, loss: 2.302343\n",
            "Epoch 102, loss: 2.301354\n",
            "Epoch 103, loss: 2.301749\n",
            "Epoch 104, loss: 2.301782\n",
            "Epoch 105, loss: 2.301578\n",
            "Epoch 106, loss: 2.301922\n",
            "Epoch 107, loss: 2.302091\n",
            "Epoch 108, loss: 2.302168\n",
            "Epoch 109, loss: 2.301910\n",
            "Epoch 110, loss: 2.301511\n",
            "Epoch 111, loss: 2.301337\n",
            "Epoch 112, loss: 2.301138\n",
            "Epoch 113, loss: 2.301919\n",
            "Epoch 114, loss: 2.301471\n",
            "Epoch 115, loss: 2.301150\n",
            "Epoch 116, loss: 2.301846\n",
            "Epoch 117, loss: 2.301199\n",
            "Epoch 118, loss: 2.302178\n",
            "Epoch 119, loss: 2.301516\n",
            "Epoch 120, loss: 2.301664\n",
            "Epoch 121, loss: 2.301352\n",
            "Epoch 122, loss: 2.301951\n",
            "Epoch 123, loss: 2.300739\n",
            "Epoch 124, loss: 2.301061\n",
            "Epoch 125, loss: 2.301110\n",
            "Epoch 126, loss: 2.301904\n",
            "Epoch 127, loss: 2.301179\n",
            "Epoch 128, loss: 2.301852\n",
            "Epoch 129, loss: 2.301397\n",
            "Epoch 130, loss: 2.301009\n",
            "Epoch 131, loss: 2.301626\n",
            "Epoch 132, loss: 2.301138\n",
            "Epoch 133, loss: 2.301238\n",
            "Epoch 134, loss: 2.302469\n",
            "Epoch 135, loss: 2.302002\n",
            "Epoch 136, loss: 2.299891\n",
            "Epoch 137, loss: 2.302243\n",
            "Epoch 138, loss: 2.302555\n",
            "Epoch 139, loss: 2.301417\n",
            "Epoch 140, loss: 2.301482\n",
            "Epoch 141, loss: 2.301957\n",
            "Epoch 142, loss: 2.301000\n",
            "Epoch 143, loss: 2.301768\n",
            "Epoch 144, loss: 2.300602\n",
            "Epoch 145, loss: 2.301945\n",
            "Epoch 146, loss: 2.301100\n",
            "Epoch 147, loss: 2.300889\n",
            "Epoch 148, loss: 2.301264\n",
            "Epoch 149, loss: 2.301844\n",
            "Epoch 150, loss: 2.301908\n",
            "Epoch 151, loss: 2.299476\n",
            "Epoch 152, loss: 2.301756\n",
            "Epoch 153, loss: 2.300220\n",
            "Epoch 154, loss: 2.300909\n",
            "Epoch 155, loss: 2.301522\n",
            "Epoch 156, loss: 2.301566\n",
            "Epoch 157, loss: 2.300615\n",
            "Epoch 158, loss: 2.299769\n",
            "Epoch 159, loss: 2.300583\n",
            "Epoch 160, loss: 2.301122\n",
            "Epoch 161, loss: 2.301045\n",
            "Epoch 162, loss: 2.301546\n",
            "Epoch 163, loss: 2.299997\n",
            "Epoch 164, loss: 2.301304\n",
            "Epoch 165, loss: 2.300644\n",
            "Epoch 166, loss: 2.300383\n",
            "Epoch 167, loss: 2.300496\n",
            "Epoch 168, loss: 2.302184\n",
            "Epoch 169, loss: 2.300734\n",
            "Epoch 170, loss: 2.301015\n",
            "Epoch 171, loss: 2.300460\n",
            "Epoch 172, loss: 2.301181\n",
            "Epoch 173, loss: 2.300044\n",
            "Epoch 174, loss: 2.301528\n",
            "Epoch 175, loss: 2.301615\n",
            "Epoch 176, loss: 2.300469\n",
            "Epoch 177, loss: 2.299551\n",
            "Epoch 178, loss: 2.300489\n",
            "Epoch 179, loss: 2.300526\n",
            "Epoch 180, loss: 2.300391\n",
            "Epoch 181, loss: 2.300974\n",
            "Epoch 182, loss: 2.300962\n",
            "Epoch 183, loss: 2.301501\n",
            "Epoch 184, loss: 2.300497\n",
            "Epoch 185, loss: 2.299994\n",
            "Epoch 186, loss: 2.301299\n",
            "Epoch 187, loss: 2.300362\n",
            "Epoch 188, loss: 2.300938\n",
            "Epoch 189, loss: 2.299777\n",
            "Epoch 190, loss: 2.301477\n",
            "Epoch 191, loss: 2.301018\n",
            "Epoch 192, loss: 2.300673\n",
            "Epoch 193, loss: 2.300337\n",
            "Epoch 194, loss: 2.300813\n",
            "Epoch 195, loss: 2.300729\n",
            "Epoch 196, loss: 2.299794\n",
            "Epoch 197, loss: 2.300868\n",
            "Epoch 198, loss: 2.299733\n",
            "Epoch 199, loss: 2.300109\n",
            "Epoch 0, loss: 2.302914\n",
            "Epoch 1, loss: 2.302876\n",
            "Epoch 2, loss: 2.302719\n",
            "Epoch 3, loss: 2.302504\n",
            "Epoch 4, loss: 2.302926\n",
            "Epoch 5, loss: 2.302521\n",
            "Epoch 6, loss: 2.303463\n",
            "Epoch 7, loss: 2.304401\n",
            "Epoch 8, loss: 2.302682\n",
            "Epoch 9, loss: 2.303168\n",
            "Epoch 10, loss: 2.302856\n",
            "Epoch 11, loss: 2.302059\n",
            "Epoch 12, loss: 2.303497\n",
            "Epoch 13, loss: 2.302311\n",
            "Epoch 14, loss: 2.302913\n",
            "Epoch 15, loss: 2.302398\n",
            "Epoch 16, loss: 2.302309\n",
            "Epoch 17, loss: 2.303049\n",
            "Epoch 18, loss: 2.302349\n",
            "Epoch 19, loss: 2.303308\n",
            "Epoch 20, loss: 2.302949\n",
            "Epoch 21, loss: 2.302536\n",
            "Epoch 22, loss: 2.302489\n",
            "Epoch 23, loss: 2.301580\n",
            "Epoch 24, loss: 2.302506\n",
            "Epoch 25, loss: 2.301908\n",
            "Epoch 26, loss: 2.302837\n",
            "Epoch 27, loss: 2.302767\n",
            "Epoch 28, loss: 2.302625\n",
            "Epoch 29, loss: 2.302391\n",
            "Epoch 30, loss: 2.302271\n",
            "Epoch 31, loss: 2.302374\n",
            "Epoch 32, loss: 2.302572\n",
            "Epoch 33, loss: 2.303098\n",
            "Epoch 34, loss: 2.302819\n",
            "Epoch 35, loss: 2.302286\n",
            "Epoch 36, loss: 2.302460\n",
            "Epoch 37, loss: 2.303195\n",
            "Epoch 38, loss: 2.301783\n",
            "Epoch 39, loss: 2.302571\n",
            "Epoch 40, loss: 2.302600\n",
            "Epoch 41, loss: 2.302734\n",
            "Epoch 42, loss: 2.303429\n",
            "Epoch 43, loss: 2.302375\n",
            "Epoch 44, loss: 2.302437\n",
            "Epoch 45, loss: 2.302259\n",
            "Epoch 46, loss: 2.303128\n",
            "Epoch 47, loss: 2.302540\n",
            "Epoch 48, loss: 2.301928\n",
            "Epoch 49, loss: 2.303437\n",
            "Epoch 50, loss: 2.302153\n",
            "Epoch 51, loss: 2.301914\n",
            "Epoch 52, loss: 2.302528\n",
            "Epoch 53, loss: 2.302466\n",
            "Epoch 54, loss: 2.301196\n",
            "Epoch 55, loss: 2.301973\n",
            "Epoch 56, loss: 2.302353\n",
            "Epoch 57, loss: 2.302151\n",
            "Epoch 58, loss: 2.303461\n",
            "Epoch 59, loss: 2.302550\n",
            "Epoch 60, loss: 2.301113\n",
            "Epoch 61, loss: 2.301898\n",
            "Epoch 62, loss: 2.301732\n",
            "Epoch 63, loss: 2.302028\n",
            "Epoch 64, loss: 2.301986\n",
            "Epoch 65, loss: 2.301467\n",
            "Epoch 66, loss: 2.302074\n",
            "Epoch 67, loss: 2.302161\n",
            "Epoch 68, loss: 2.302556\n",
            "Epoch 69, loss: 2.302264\n",
            "Epoch 70, loss: 2.303014\n",
            "Epoch 71, loss: 2.302592\n",
            "Epoch 72, loss: 2.302040\n",
            "Epoch 73, loss: 2.301466\n",
            "Epoch 74, loss: 2.301708\n",
            "Epoch 75, loss: 2.302654\n",
            "Epoch 76, loss: 2.302464\n",
            "Epoch 77, loss: 2.301891\n",
            "Epoch 78, loss: 2.301443\n",
            "Epoch 79, loss: 2.301754\n",
            "Epoch 80, loss: 2.301850\n",
            "Epoch 81, loss: 2.301783\n",
            "Epoch 82, loss: 2.301970\n",
            "Epoch 83, loss: 2.302775\n",
            "Epoch 84, loss: 2.301829\n",
            "Epoch 85, loss: 2.302702\n",
            "Epoch 86, loss: 2.302167\n",
            "Epoch 87, loss: 2.302185\n",
            "Epoch 88, loss: 2.301938\n",
            "Epoch 89, loss: 2.301885\n",
            "Epoch 90, loss: 2.301610\n",
            "Epoch 91, loss: 2.302081\n",
            "Epoch 92, loss: 2.301877\n",
            "Epoch 93, loss: 2.301707\n",
            "Epoch 94, loss: 2.301103\n",
            "Epoch 95, loss: 2.301638\n",
            "Epoch 96, loss: 2.301786\n",
            "Epoch 97, loss: 2.302350\n",
            "Epoch 98, loss: 2.301501\n",
            "Epoch 99, loss: 2.302636\n",
            "Epoch 100, loss: 2.302798\n",
            "Epoch 101, loss: 2.302414\n",
            "Epoch 102, loss: 2.301796\n",
            "Epoch 103, loss: 2.301231\n",
            "Epoch 104, loss: 2.302195\n",
            "Epoch 105, loss: 2.302817\n",
            "Epoch 106, loss: 2.302644\n",
            "Epoch 107, loss: 2.301781\n",
            "Epoch 108, loss: 2.301231\n",
            "Epoch 109, loss: 2.302752\n",
            "Epoch 110, loss: 2.301985\n",
            "Epoch 111, loss: 2.301543\n",
            "Epoch 112, loss: 2.301623\n",
            "Epoch 113, loss: 2.301941\n",
            "Epoch 114, loss: 2.301867\n",
            "Epoch 115, loss: 2.302668\n",
            "Epoch 116, loss: 2.301720\n",
            "Epoch 117, loss: 2.300749\n",
            "Epoch 118, loss: 2.302857\n",
            "Epoch 119, loss: 2.301645\n",
            "Epoch 120, loss: 2.302026\n",
            "Epoch 121, loss: 2.301721\n",
            "Epoch 122, loss: 2.301489\n",
            "Epoch 123, loss: 2.300843\n",
            "Epoch 124, loss: 2.301970\n",
            "Epoch 125, loss: 2.302121\n",
            "Epoch 126, loss: 2.301558\n",
            "Epoch 127, loss: 2.301639\n",
            "Epoch 128, loss: 2.301131\n",
            "Epoch 129, loss: 2.301274\n",
            "Epoch 130, loss: 2.300929\n",
            "Epoch 131, loss: 2.301587\n",
            "Epoch 132, loss: 2.300510\n",
            "Epoch 133, loss: 2.301941\n",
            "Epoch 134, loss: 2.301288\n",
            "Epoch 135, loss: 2.301022\n",
            "Epoch 136, loss: 2.301756\n",
            "Epoch 137, loss: 2.301583\n",
            "Epoch 138, loss: 2.301344\n",
            "Epoch 139, loss: 2.301466\n",
            "Epoch 140, loss: 2.302317\n",
            "Epoch 141, loss: 2.301773\n",
            "Epoch 142, loss: 2.302357\n",
            "Epoch 143, loss: 2.303255\n",
            "Epoch 144, loss: 2.302138\n",
            "Epoch 145, loss: 2.302055\n",
            "Epoch 146, loss: 2.300347\n",
            "Epoch 147, loss: 2.300529\n",
            "Epoch 148, loss: 2.302724\n",
            "Epoch 149, loss: 2.301846\n",
            "Epoch 150, loss: 2.301480\n",
            "Epoch 151, loss: 2.301820\n",
            "Epoch 152, loss: 2.300724\n",
            "Epoch 153, loss: 2.301859\n",
            "Epoch 154, loss: 2.300862\n",
            "Epoch 155, loss: 2.301279\n",
            "Epoch 156, loss: 2.302664\n",
            "Epoch 157, loss: 2.301314\n",
            "Epoch 158, loss: 2.300588\n",
            "Epoch 159, loss: 2.301884\n",
            "Epoch 160, loss: 2.301206\n",
            "Epoch 161, loss: 2.301391\n",
            "Epoch 162, loss: 2.300542\n",
            "Epoch 163, loss: 2.300917\n",
            "Epoch 164, loss: 2.302511\n",
            "Epoch 165, loss: 2.301612\n",
            "Epoch 166, loss: 2.301081\n",
            "Epoch 167, loss: 2.301341\n",
            "Epoch 168, loss: 2.302524\n",
            "Epoch 169, loss: 2.300496\n",
            "Epoch 170, loss: 2.301595\n",
            "Epoch 171, loss: 2.302021\n",
            "Epoch 172, loss: 2.300849\n",
            "Epoch 173, loss: 2.300763\n",
            "Epoch 174, loss: 2.300431\n",
            "Epoch 175, loss: 2.299637\n",
            "Epoch 176, loss: 2.300142\n",
            "Epoch 177, loss: 2.301386\n",
            "Epoch 178, loss: 2.300090\n",
            "Epoch 179, loss: 2.299943\n",
            "Epoch 180, loss: 2.301513\n",
            "Epoch 181, loss: 2.300830\n",
            "Epoch 182, loss: 2.300964\n",
            "Epoch 183, loss: 2.300350\n",
            "Epoch 184, loss: 2.300795\n",
            "Epoch 185, loss: 2.301060\n",
            "Epoch 186, loss: 2.301283\n",
            "Epoch 187, loss: 2.300960\n",
            "Epoch 188, loss: 2.301168\n",
            "Epoch 189, loss: 2.300720\n",
            "Epoch 190, loss: 2.301540\n",
            "Epoch 191, loss: 2.301055\n",
            "Epoch 192, loss: 2.301188\n",
            "Epoch 193, loss: 2.299408\n",
            "Epoch 194, loss: 2.301789\n",
            "Epoch 195, loss: 2.301162\n",
            "Epoch 196, loss: 2.300707\n",
            "Epoch 197, loss: 2.300562\n",
            "Epoch 198, loss: 2.300179\n",
            "Epoch 199, loss: 2.298831\n",
            "Epoch 0, loss: 2.303067\n",
            "Epoch 1, loss: 2.301754\n",
            "Epoch 2, loss: 2.302400\n",
            "Epoch 3, loss: 2.302305\n",
            "Epoch 4, loss: 2.302218\n",
            "Epoch 5, loss: 2.302615\n",
            "Epoch 6, loss: 2.302632\n",
            "Epoch 7, loss: 2.302952\n",
            "Epoch 8, loss: 2.302957\n",
            "Epoch 9, loss: 2.302432\n",
            "Epoch 10, loss: 2.301601\n",
            "Epoch 11, loss: 2.302463\n",
            "Epoch 12, loss: 2.302505\n",
            "Epoch 13, loss: 2.302478\n",
            "Epoch 14, loss: 2.302871\n",
            "Epoch 15, loss: 2.302739\n",
            "Epoch 16, loss: 2.301901\n",
            "Epoch 17, loss: 2.303504\n",
            "Epoch 18, loss: 2.301668\n",
            "Epoch 19, loss: 2.301429\n",
            "Epoch 20, loss: 2.301505\n",
            "Epoch 21, loss: 2.302330\n",
            "Epoch 22, loss: 2.302287\n",
            "Epoch 23, loss: 2.301157\n",
            "Epoch 24, loss: 2.301748\n",
            "Epoch 25, loss: 2.303626\n",
            "Epoch 26, loss: 2.302149\n",
            "Epoch 27, loss: 2.302195\n",
            "Epoch 28, loss: 2.302639\n",
            "Epoch 29, loss: 2.302144\n",
            "Epoch 30, loss: 2.302641\n",
            "Epoch 31, loss: 2.303015\n",
            "Epoch 32, loss: 2.302044\n",
            "Epoch 33, loss: 2.302437\n",
            "Epoch 34, loss: 2.301882\n",
            "Epoch 35, loss: 2.302809\n",
            "Epoch 36, loss: 2.301541\n",
            "Epoch 37, loss: 2.301236\n",
            "Epoch 38, loss: 2.302968\n",
            "Epoch 39, loss: 2.302089\n",
            "Epoch 40, loss: 2.303048\n",
            "Epoch 41, loss: 2.302055\n",
            "Epoch 42, loss: 2.302178\n",
            "Epoch 43, loss: 2.302360\n",
            "Epoch 44, loss: 2.302347\n",
            "Epoch 45, loss: 2.301528\n",
            "Epoch 46, loss: 2.302595\n",
            "Epoch 47, loss: 2.302119\n",
            "Epoch 48, loss: 2.302222\n",
            "Epoch 49, loss: 2.302272\n",
            "Epoch 50, loss: 2.303397\n",
            "Epoch 51, loss: 2.301397\n",
            "Epoch 52, loss: 2.303578\n",
            "Epoch 53, loss: 2.301792\n",
            "Epoch 54, loss: 2.302851\n",
            "Epoch 55, loss: 2.302777\n",
            "Epoch 56, loss: 2.302036\n",
            "Epoch 57, loss: 2.302458\n",
            "Epoch 58, loss: 2.303511\n",
            "Epoch 59, loss: 2.303097\n",
            "Epoch 60, loss: 2.302854\n",
            "Epoch 61, loss: 2.302948\n",
            "Epoch 62, loss: 2.302427\n",
            "Epoch 63, loss: 2.302027\n",
            "Epoch 64, loss: 2.303060\n",
            "Epoch 65, loss: 2.301713\n",
            "Epoch 66, loss: 2.301415\n",
            "Epoch 67, loss: 2.302576\n",
            "Epoch 68, loss: 2.301685\n",
            "Epoch 69, loss: 2.302298\n",
            "Epoch 70, loss: 2.302600\n",
            "Epoch 71, loss: 2.302136\n",
            "Epoch 72, loss: 2.302491\n",
            "Epoch 73, loss: 2.302378\n",
            "Epoch 74, loss: 2.302531\n",
            "Epoch 75, loss: 2.302564\n",
            "Epoch 76, loss: 2.302087\n",
            "Epoch 77, loss: 2.302853\n",
            "Epoch 78, loss: 2.301911\n",
            "Epoch 79, loss: 2.302000\n",
            "Epoch 80, loss: 2.302544\n",
            "Epoch 81, loss: 2.303528\n",
            "Epoch 82, loss: 2.302111\n",
            "Epoch 83, loss: 2.301842\n",
            "Epoch 84, loss: 2.302945\n",
            "Epoch 85, loss: 2.302973\n",
            "Epoch 86, loss: 2.301833\n",
            "Epoch 87, loss: 2.302739\n",
            "Epoch 88, loss: 2.302961\n",
            "Epoch 89, loss: 2.301612\n",
            "Epoch 90, loss: 2.302189\n",
            "Epoch 91, loss: 2.302426\n",
            "Epoch 92, loss: 2.301768\n",
            "Epoch 93, loss: 2.302349\n",
            "Epoch 94, loss: 2.302841\n",
            "Epoch 95, loss: 2.301790\n",
            "Epoch 96, loss: 2.302769\n",
            "Epoch 97, loss: 2.302420\n",
            "Epoch 98, loss: 2.302839\n",
            "Epoch 99, loss: 2.301873\n",
            "Epoch 100, loss: 2.302328\n",
            "Epoch 101, loss: 2.302313\n",
            "Epoch 102, loss: 2.302226\n",
            "Epoch 103, loss: 2.301969\n",
            "Epoch 104, loss: 2.302842\n",
            "Epoch 105, loss: 2.301902\n",
            "Epoch 106, loss: 2.301895\n",
            "Epoch 107, loss: 2.302680\n",
            "Epoch 108, loss: 2.302511\n",
            "Epoch 109, loss: 2.302409\n",
            "Epoch 110, loss: 2.301335\n",
            "Epoch 111, loss: 2.301876\n",
            "Epoch 112, loss: 2.302108\n",
            "Epoch 113, loss: 2.301102\n",
            "Epoch 114, loss: 2.302634\n",
            "Epoch 115, loss: 2.301723\n",
            "Epoch 116, loss: 2.302822\n",
            "Epoch 117, loss: 2.302220\n",
            "Epoch 118, loss: 2.302521\n",
            "Epoch 119, loss: 2.302269\n",
            "Epoch 120, loss: 2.301808\n",
            "Epoch 121, loss: 2.302229\n",
            "Epoch 122, loss: 2.302821\n",
            "Epoch 123, loss: 2.301889\n",
            "Epoch 124, loss: 2.301534\n",
            "Epoch 125, loss: 2.302451\n",
            "Epoch 126, loss: 2.301455\n",
            "Epoch 127, loss: 2.303185\n",
            "Epoch 128, loss: 2.302047\n",
            "Epoch 129, loss: 2.302951\n",
            "Epoch 130, loss: 2.301808\n",
            "Epoch 131, loss: 2.301607\n",
            "Epoch 132, loss: 2.302171\n",
            "Epoch 133, loss: 2.301018\n",
            "Epoch 134, loss: 2.302312\n",
            "Epoch 135, loss: 2.302318\n",
            "Epoch 136, loss: 2.301977\n",
            "Epoch 137, loss: 2.301993\n",
            "Epoch 138, loss: 2.301505\n",
            "Epoch 139, loss: 2.302419\n",
            "Epoch 140, loss: 2.302271\n",
            "Epoch 141, loss: 2.301474\n",
            "Epoch 142, loss: 2.301899\n",
            "Epoch 143, loss: 2.302872\n",
            "Epoch 144, loss: 2.301785\n",
            "Epoch 145, loss: 2.302919\n",
            "Epoch 146, loss: 2.302795\n",
            "Epoch 147, loss: 2.301947\n",
            "Epoch 148, loss: 2.301264\n",
            "Epoch 149, loss: 2.301212\n",
            "Epoch 150, loss: 2.301772\n",
            "Epoch 151, loss: 2.301656\n",
            "Epoch 152, loss: 2.301931\n",
            "Epoch 153, loss: 2.301472\n",
            "Epoch 154, loss: 2.303305\n",
            "Epoch 155, loss: 2.301848\n",
            "Epoch 156, loss: 2.302728\n",
            "Epoch 157, loss: 2.301711\n",
            "Epoch 158, loss: 2.301648\n",
            "Epoch 159, loss: 2.302101\n",
            "Epoch 160, loss: 2.302560\n",
            "Epoch 161, loss: 2.301206\n",
            "Epoch 162, loss: 2.302143\n",
            "Epoch 163, loss: 2.302422\n",
            "Epoch 164, loss: 2.301899\n",
            "Epoch 165, loss: 2.301053\n",
            "Epoch 166, loss: 2.301791\n",
            "Epoch 167, loss: 2.301452\n",
            "Epoch 168, loss: 2.301882\n",
            "Epoch 169, loss: 2.302190\n",
            "Epoch 170, loss: 2.302896\n",
            "Epoch 171, loss: 2.302748\n",
            "Epoch 172, loss: 2.302046\n",
            "Epoch 173, loss: 2.302390\n",
            "Epoch 174, loss: 2.301887\n",
            "Epoch 175, loss: 2.301918\n",
            "Epoch 176, loss: 2.302453\n",
            "Epoch 177, loss: 2.302371\n",
            "Epoch 178, loss: 2.302010\n",
            "Epoch 179, loss: 2.301890\n",
            "Epoch 180, loss: 2.301850\n",
            "Epoch 181, loss: 2.302610\n",
            "Epoch 182, loss: 2.302825\n",
            "Epoch 183, loss: 2.303057\n",
            "Epoch 184, loss: 2.301667\n",
            "Epoch 185, loss: 2.301899\n",
            "Epoch 186, loss: 2.302320\n",
            "Epoch 187, loss: 2.303410\n",
            "Epoch 188, loss: 2.302025\n",
            "Epoch 189, loss: 2.301845\n",
            "Epoch 190, loss: 2.301226\n",
            "Epoch 191, loss: 2.302085\n",
            "Epoch 192, loss: 2.301901\n",
            "Epoch 193, loss: 2.301598\n",
            "Epoch 194, loss: 2.302417\n",
            "Epoch 195, loss: 2.302553\n",
            "Epoch 196, loss: 2.301873\n",
            "Epoch 197, loss: 2.302353\n",
            "Epoch 198, loss: 2.302016\n",
            "Epoch 199, loss: 2.301982\n",
            "Epoch 0, loss: 2.302430\n",
            "Epoch 1, loss: 2.302112\n",
            "Epoch 2, loss: 2.302146\n",
            "Epoch 3, loss: 2.302579\n",
            "Epoch 4, loss: 2.302551\n",
            "Epoch 5, loss: 2.301605\n",
            "Epoch 6, loss: 2.301972\n",
            "Epoch 7, loss: 2.302303\n",
            "Epoch 8, loss: 2.303677\n",
            "Epoch 9, loss: 2.302749\n",
            "Epoch 10, loss: 2.302890\n",
            "Epoch 11, loss: 2.301894\n",
            "Epoch 12, loss: 2.302777\n",
            "Epoch 13, loss: 2.303060\n",
            "Epoch 14, loss: 2.302662\n",
            "Epoch 15, loss: 2.302325\n",
            "Epoch 16, loss: 2.302391\n",
            "Epoch 17, loss: 2.302709\n",
            "Epoch 18, loss: 2.302657\n",
            "Epoch 19, loss: 2.302307\n",
            "Epoch 20, loss: 2.302119\n",
            "Epoch 21, loss: 2.302953\n",
            "Epoch 22, loss: 2.301970\n",
            "Epoch 23, loss: 2.302616\n",
            "Epoch 24, loss: 2.302238\n",
            "Epoch 25, loss: 2.303269\n",
            "Epoch 26, loss: 2.302635\n",
            "Epoch 27, loss: 2.301943\n",
            "Epoch 28, loss: 2.301820\n",
            "Epoch 29, loss: 2.301608\n",
            "Epoch 30, loss: 2.302901\n",
            "Epoch 31, loss: 2.302357\n",
            "Epoch 32, loss: 2.302896\n",
            "Epoch 33, loss: 2.302494\n",
            "Epoch 34, loss: 2.301950\n",
            "Epoch 35, loss: 2.302583\n",
            "Epoch 36, loss: 2.302370\n",
            "Epoch 37, loss: 2.303812\n",
            "Epoch 38, loss: 2.303288\n",
            "Epoch 39, loss: 2.302142\n",
            "Epoch 40, loss: 2.301746\n",
            "Epoch 41, loss: 2.302809\n",
            "Epoch 42, loss: 2.303569\n",
            "Epoch 43, loss: 2.302010\n",
            "Epoch 44, loss: 2.302532\n",
            "Epoch 45, loss: 2.302182\n",
            "Epoch 46, loss: 2.302809\n",
            "Epoch 47, loss: 2.302412\n",
            "Epoch 48, loss: 2.303569\n",
            "Epoch 49, loss: 2.302409\n",
            "Epoch 50, loss: 2.303581\n",
            "Epoch 51, loss: 2.301764\n",
            "Epoch 52, loss: 2.302338\n",
            "Epoch 53, loss: 2.302517\n",
            "Epoch 54, loss: 2.302934\n",
            "Epoch 55, loss: 2.302543\n",
            "Epoch 56, loss: 2.302929\n",
            "Epoch 57, loss: 2.303256\n",
            "Epoch 58, loss: 2.302142\n",
            "Epoch 59, loss: 2.302378\n",
            "Epoch 60, loss: 2.302580\n",
            "Epoch 61, loss: 2.301637\n",
            "Epoch 62, loss: 2.303863\n",
            "Epoch 63, loss: 2.302464\n",
            "Epoch 64, loss: 2.302478\n",
            "Epoch 65, loss: 2.302474\n",
            "Epoch 66, loss: 2.302060\n",
            "Epoch 67, loss: 2.302724\n",
            "Epoch 68, loss: 2.302369\n",
            "Epoch 69, loss: 2.302476\n",
            "Epoch 70, loss: 2.303035\n",
            "Epoch 71, loss: 2.302777\n",
            "Epoch 72, loss: 2.303266\n",
            "Epoch 73, loss: 2.301386\n",
            "Epoch 74, loss: 2.302272\n",
            "Epoch 75, loss: 2.302398\n",
            "Epoch 76, loss: 2.302243\n",
            "Epoch 77, loss: 2.302323\n",
            "Epoch 78, loss: 2.302017\n",
            "Epoch 79, loss: 2.302810\n",
            "Epoch 80, loss: 2.302529\n",
            "Epoch 81, loss: 2.302188\n",
            "Epoch 82, loss: 2.302608\n",
            "Epoch 83, loss: 2.301401\n",
            "Epoch 84, loss: 2.302552\n",
            "Epoch 85, loss: 2.302842\n",
            "Epoch 86, loss: 2.302591\n",
            "Epoch 87, loss: 2.303205\n",
            "Epoch 88, loss: 2.303417\n",
            "Epoch 89, loss: 2.302243\n",
            "Epoch 90, loss: 2.302678\n",
            "Epoch 91, loss: 2.303233\n",
            "Epoch 92, loss: 2.303006\n",
            "Epoch 93, loss: 2.302518\n",
            "Epoch 94, loss: 2.302451\n",
            "Epoch 95, loss: 2.302848\n",
            "Epoch 96, loss: 2.302092\n",
            "Epoch 97, loss: 2.302140\n",
            "Epoch 98, loss: 2.302364\n",
            "Epoch 99, loss: 2.302787\n",
            "Epoch 100, loss: 2.301897\n",
            "Epoch 101, loss: 2.302133\n",
            "Epoch 102, loss: 2.302053\n",
            "Epoch 103, loss: 2.302991\n",
            "Epoch 104, loss: 2.303030\n",
            "Epoch 105, loss: 2.303408\n",
            "Epoch 106, loss: 2.302080\n",
            "Epoch 107, loss: 2.302380\n",
            "Epoch 108, loss: 2.302630\n",
            "Epoch 109, loss: 2.303077\n",
            "Epoch 110, loss: 2.302911\n",
            "Epoch 111, loss: 2.302695\n",
            "Epoch 112, loss: 2.303337\n",
            "Epoch 113, loss: 2.303195\n",
            "Epoch 114, loss: 2.302992\n",
            "Epoch 115, loss: 2.302326\n",
            "Epoch 116, loss: 2.302777\n",
            "Epoch 117, loss: 2.302967\n",
            "Epoch 118, loss: 2.302156\n",
            "Epoch 119, loss: 2.302914\n",
            "Epoch 120, loss: 2.302236\n",
            "Epoch 121, loss: 2.302770\n",
            "Epoch 122, loss: 2.302748\n",
            "Epoch 123, loss: 2.302398\n",
            "Epoch 124, loss: 2.302869\n",
            "Epoch 125, loss: 2.301951\n",
            "Epoch 126, loss: 2.303032\n",
            "Epoch 127, loss: 2.302830\n",
            "Epoch 128, loss: 2.303304\n",
            "Epoch 129, loss: 2.302778\n",
            "Epoch 130, loss: 2.302121\n",
            "Epoch 131, loss: 2.301896\n",
            "Epoch 132, loss: 2.301939\n",
            "Epoch 133, loss: 2.302413\n",
            "Epoch 134, loss: 2.301837\n",
            "Epoch 135, loss: 2.303000\n",
            "Epoch 136, loss: 2.303121\n",
            "Epoch 137, loss: 2.302700\n",
            "Epoch 138, loss: 2.301556\n",
            "Epoch 139, loss: 2.301968\n",
            "Epoch 140, loss: 2.302638\n",
            "Epoch 141, loss: 2.302278\n",
            "Epoch 142, loss: 2.302630\n",
            "Epoch 143, loss: 2.301889\n",
            "Epoch 144, loss: 2.302522\n",
            "Epoch 145, loss: 2.302963\n",
            "Epoch 146, loss: 2.302129\n",
            "Epoch 147, loss: 2.302237\n",
            "Epoch 148, loss: 2.302199\n",
            "Epoch 149, loss: 2.302155\n",
            "Epoch 150, loss: 2.302138\n",
            "Epoch 151, loss: 2.302086\n",
            "Epoch 152, loss: 2.302180\n",
            "Epoch 153, loss: 2.302226\n",
            "Epoch 154, loss: 2.302550\n",
            "Epoch 155, loss: 2.302401\n",
            "Epoch 156, loss: 2.302951\n",
            "Epoch 157, loss: 2.303209\n",
            "Epoch 158, loss: 2.302775\n",
            "Epoch 159, loss: 2.302888\n",
            "Epoch 160, loss: 2.302370\n",
            "Epoch 161, loss: 2.302249\n",
            "Epoch 162, loss: 2.302717\n",
            "Epoch 163, loss: 2.303003\n",
            "Epoch 164, loss: 2.302920\n",
            "Epoch 165, loss: 2.302835\n",
            "Epoch 166, loss: 2.302644\n",
            "Epoch 167, loss: 2.302274\n",
            "Epoch 168, loss: 2.301818\n",
            "Epoch 169, loss: 2.302389\n",
            "Epoch 170, loss: 2.301465\n",
            "Epoch 171, loss: 2.302838\n",
            "Epoch 172, loss: 2.301948\n",
            "Epoch 173, loss: 2.302870\n",
            "Epoch 174, loss: 2.302431\n",
            "Epoch 175, loss: 2.301510\n",
            "Epoch 176, loss: 2.302570\n",
            "Epoch 177, loss: 2.302661\n",
            "Epoch 178, loss: 2.302666\n",
            "Epoch 179, loss: 2.302396\n",
            "Epoch 180, loss: 2.302283\n",
            "Epoch 181, loss: 2.302219\n",
            "Epoch 182, loss: 2.302639\n",
            "Epoch 183, loss: 2.302300\n",
            "Epoch 184, loss: 2.302618\n",
            "Epoch 185, loss: 2.302620\n",
            "Epoch 186, loss: 2.301974\n",
            "Epoch 187, loss: 2.301695\n",
            "Epoch 188, loss: 2.302542\n",
            "Epoch 189, loss: 2.301607\n",
            "Epoch 190, loss: 2.302969\n",
            "Epoch 191, loss: 2.302079\n",
            "Epoch 192, loss: 2.302692\n",
            "Epoch 193, loss: 2.302001\n",
            "Epoch 194, loss: 2.302590\n",
            "Epoch 195, loss: 2.301602\n",
            "Epoch 196, loss: 2.301674\n",
            "Epoch 197, loss: 2.302013\n",
            "Epoch 198, loss: 2.302041\n",
            "Epoch 199, loss: 2.302101\n",
            "Epoch 0, loss: 2.302832\n",
            "Epoch 1, loss: 2.302769\n",
            "Epoch 2, loss: 2.302969\n",
            "Epoch 3, loss: 2.302568\n",
            "Epoch 4, loss: 2.302265\n",
            "Epoch 5, loss: 2.302460\n",
            "Epoch 6, loss: 2.302036\n",
            "Epoch 7, loss: 2.301923\n",
            "Epoch 8, loss: 2.302284\n",
            "Epoch 9, loss: 2.302629\n",
            "Epoch 10, loss: 2.303448\n",
            "Epoch 11, loss: 2.302790\n",
            "Epoch 12, loss: 2.302653\n",
            "Epoch 13, loss: 2.302225\n",
            "Epoch 14, loss: 2.302348\n",
            "Epoch 15, loss: 2.302693\n",
            "Epoch 16, loss: 2.302980\n",
            "Epoch 17, loss: 2.302854\n",
            "Epoch 18, loss: 2.302201\n",
            "Epoch 19, loss: 2.301542\n",
            "Epoch 20, loss: 2.301379\n",
            "Epoch 21, loss: 2.302813\n",
            "Epoch 22, loss: 2.302600\n",
            "Epoch 23, loss: 2.302674\n",
            "Epoch 24, loss: 2.303001\n",
            "Epoch 25, loss: 2.301952\n",
            "Epoch 26, loss: 2.302032\n",
            "Epoch 27, loss: 2.302267\n",
            "Epoch 28, loss: 2.302948\n",
            "Epoch 29, loss: 2.302672\n",
            "Epoch 30, loss: 2.302508\n",
            "Epoch 31, loss: 2.303466\n",
            "Epoch 32, loss: 2.302793\n",
            "Epoch 33, loss: 2.302859\n",
            "Epoch 34, loss: 2.302499\n",
            "Epoch 35, loss: 2.302118\n",
            "Epoch 36, loss: 2.302385\n",
            "Epoch 37, loss: 2.303292\n",
            "Epoch 38, loss: 2.302249\n",
            "Epoch 39, loss: 2.302852\n",
            "Epoch 40, loss: 2.302142\n",
            "Epoch 41, loss: 2.302452\n",
            "Epoch 42, loss: 2.302448\n",
            "Epoch 43, loss: 2.301750\n",
            "Epoch 44, loss: 2.302527\n",
            "Epoch 45, loss: 2.303410\n",
            "Epoch 46, loss: 2.303430\n",
            "Epoch 47, loss: 2.302155\n",
            "Epoch 48, loss: 2.302110\n",
            "Epoch 49, loss: 2.303061\n",
            "Epoch 50, loss: 2.303107\n",
            "Epoch 51, loss: 2.302633\n",
            "Epoch 52, loss: 2.302624\n",
            "Epoch 53, loss: 2.302292\n",
            "Epoch 54, loss: 2.302176\n",
            "Epoch 55, loss: 2.301721\n",
            "Epoch 56, loss: 2.303496\n",
            "Epoch 57, loss: 2.302501\n",
            "Epoch 58, loss: 2.302290\n",
            "Epoch 59, loss: 2.302702\n",
            "Epoch 60, loss: 2.302486\n",
            "Epoch 61, loss: 2.302148\n",
            "Epoch 62, loss: 2.302016\n",
            "Epoch 63, loss: 2.302979\n",
            "Epoch 64, loss: 2.302339\n",
            "Epoch 65, loss: 2.302218\n",
            "Epoch 66, loss: 2.303065\n",
            "Epoch 67, loss: 2.302724\n",
            "Epoch 68, loss: 2.302866\n",
            "Epoch 69, loss: 2.302137\n",
            "Epoch 70, loss: 2.303632\n",
            "Epoch 71, loss: 2.302721\n",
            "Epoch 72, loss: 2.302864\n",
            "Epoch 73, loss: 2.303368\n",
            "Epoch 74, loss: 2.301787\n",
            "Epoch 75, loss: 2.302428\n",
            "Epoch 76, loss: 2.302236\n",
            "Epoch 77, loss: 2.302851\n",
            "Epoch 78, loss: 2.302300\n",
            "Epoch 79, loss: 2.301822\n",
            "Epoch 80, loss: 2.302870\n",
            "Epoch 81, loss: 2.302128\n",
            "Epoch 82, loss: 2.302518\n",
            "Epoch 83, loss: 2.301991\n",
            "Epoch 84, loss: 2.302743\n",
            "Epoch 85, loss: 2.302851\n",
            "Epoch 86, loss: 2.302936\n",
            "Epoch 87, loss: 2.303380\n",
            "Epoch 88, loss: 2.302241\n",
            "Epoch 89, loss: 2.302900\n",
            "Epoch 90, loss: 2.303208\n",
            "Epoch 91, loss: 2.302510\n",
            "Epoch 92, loss: 2.302639\n",
            "Epoch 93, loss: 2.302088\n",
            "Epoch 94, loss: 2.302570\n",
            "Epoch 95, loss: 2.303944\n",
            "Epoch 96, loss: 2.302429\n",
            "Epoch 97, loss: 2.302595\n",
            "Epoch 98, loss: 2.303610\n",
            "Epoch 99, loss: 2.301961\n",
            "Epoch 100, loss: 2.302439\n",
            "Epoch 101, loss: 2.301524\n",
            "Epoch 102, loss: 2.303581\n",
            "Epoch 103, loss: 2.302091\n",
            "Epoch 104, loss: 2.301834\n",
            "Epoch 105, loss: 2.302981\n",
            "Epoch 106, loss: 2.301639\n",
            "Epoch 107, loss: 2.302958\n",
            "Epoch 108, loss: 2.302331\n",
            "Epoch 109, loss: 2.302913\n",
            "Epoch 110, loss: 2.303139\n",
            "Epoch 111, loss: 2.302340\n",
            "Epoch 112, loss: 2.303128\n",
            "Epoch 113, loss: 2.302464\n",
            "Epoch 114, loss: 2.302421\n",
            "Epoch 115, loss: 2.301886\n",
            "Epoch 116, loss: 2.302347\n",
            "Epoch 117, loss: 2.301507\n",
            "Epoch 118, loss: 2.302871\n",
            "Epoch 119, loss: 2.302640\n",
            "Epoch 120, loss: 2.302762\n",
            "Epoch 121, loss: 2.302246\n",
            "Epoch 122, loss: 2.302057\n",
            "Epoch 123, loss: 2.301977\n",
            "Epoch 124, loss: 2.302514\n",
            "Epoch 125, loss: 2.302233\n",
            "Epoch 126, loss: 2.302788\n",
            "Epoch 127, loss: 2.303027\n",
            "Epoch 128, loss: 2.301978\n",
            "Epoch 129, loss: 2.302610\n",
            "Epoch 130, loss: 2.302586\n",
            "Epoch 131, loss: 2.302504\n",
            "Epoch 132, loss: 2.303099\n",
            "Epoch 133, loss: 2.301586\n",
            "Epoch 134, loss: 2.302997\n",
            "Epoch 135, loss: 2.303208\n",
            "Epoch 136, loss: 2.302582\n",
            "Epoch 137, loss: 2.302830\n",
            "Epoch 138, loss: 2.303164\n",
            "Epoch 139, loss: 2.301980\n",
            "Epoch 140, loss: 2.302711\n",
            "Epoch 141, loss: 2.302866\n",
            "Epoch 142, loss: 2.303337\n",
            "Epoch 143, loss: 2.301800\n",
            "Epoch 144, loss: 2.302561\n",
            "Epoch 145, loss: 2.302195\n",
            "Epoch 146, loss: 2.302029\n",
            "Epoch 147, loss: 2.302381\n",
            "Epoch 148, loss: 2.302551\n",
            "Epoch 149, loss: 2.302626\n",
            "Epoch 150, loss: 2.302567\n",
            "Epoch 151, loss: 2.302616\n",
            "Epoch 152, loss: 2.303227\n",
            "Epoch 153, loss: 2.301959\n",
            "Epoch 154, loss: 2.302658\n",
            "Epoch 155, loss: 2.302314\n",
            "Epoch 156, loss: 2.302814\n",
            "Epoch 157, loss: 2.302566\n",
            "Epoch 158, loss: 2.301735\n",
            "Epoch 159, loss: 2.303855\n",
            "Epoch 160, loss: 2.303027\n",
            "Epoch 161, loss: 2.302850\n",
            "Epoch 162, loss: 2.302288\n",
            "Epoch 163, loss: 2.302577\n",
            "Epoch 164, loss: 2.301975\n",
            "Epoch 165, loss: 2.302523\n",
            "Epoch 166, loss: 2.302007\n",
            "Epoch 167, loss: 2.303132\n",
            "Epoch 168, loss: 2.303299\n",
            "Epoch 169, loss: 2.302190\n",
            "Epoch 170, loss: 2.301676\n",
            "Epoch 171, loss: 2.303107\n",
            "Epoch 172, loss: 2.302523\n",
            "Epoch 173, loss: 2.303274\n",
            "Epoch 174, loss: 2.302032\n",
            "Epoch 175, loss: 2.302257\n",
            "Epoch 176, loss: 2.302717\n",
            "Epoch 177, loss: 2.301040\n",
            "Epoch 178, loss: 2.301737\n",
            "Epoch 179, loss: 2.303388\n",
            "Epoch 180, loss: 2.302332\n",
            "Epoch 181, loss: 2.302457\n",
            "Epoch 182, loss: 2.301628\n",
            "Epoch 183, loss: 2.302855\n",
            "Epoch 184, loss: 2.302835\n",
            "Epoch 185, loss: 2.303115\n",
            "Epoch 186, loss: 2.302469\n",
            "Epoch 187, loss: 2.302996\n",
            "Epoch 188, loss: 2.302537\n",
            "Epoch 189, loss: 2.302105\n",
            "Epoch 190, loss: 2.303124\n",
            "Epoch 191, loss: 2.302235\n",
            "Epoch 192, loss: 2.302588\n",
            "Epoch 193, loss: 2.302023\n",
            "Epoch 194, loss: 2.302498\n",
            "Epoch 195, loss: 2.303450\n",
            "Epoch 196, loss: 2.302001\n",
            "Epoch 197, loss: 2.301927\n",
            "Epoch 198, loss: 2.302769\n",
            "Epoch 199, loss: 2.301351\n",
            "Epoch 0, loss: 2.301892\n",
            "Epoch 1, loss: 2.302901\n",
            "Epoch 2, loss: 2.302519\n",
            "Epoch 3, loss: 2.302613\n",
            "Epoch 4, loss: 2.302086\n",
            "Epoch 5, loss: 2.302350\n",
            "Epoch 6, loss: 2.302243\n",
            "Epoch 7, loss: 2.302399\n",
            "Epoch 8, loss: 2.302638\n",
            "Epoch 9, loss: 2.302567\n",
            "Epoch 10, loss: 2.302721\n",
            "Epoch 11, loss: 2.301744\n",
            "Epoch 12, loss: 2.302579\n",
            "Epoch 13, loss: 2.303100\n",
            "Epoch 14, loss: 2.302407\n",
            "Epoch 15, loss: 2.301478\n",
            "Epoch 16, loss: 2.302847\n",
            "Epoch 17, loss: 2.302511\n",
            "Epoch 18, loss: 2.303161\n",
            "Epoch 19, loss: 2.302292\n",
            "Epoch 20, loss: 2.303028\n",
            "Epoch 21, loss: 2.302831\n",
            "Epoch 22, loss: 2.301828\n",
            "Epoch 23, loss: 2.302573\n",
            "Epoch 24, loss: 2.302703\n",
            "Epoch 25, loss: 2.302743\n",
            "Epoch 26, loss: 2.303416\n",
            "Epoch 27, loss: 2.302859\n",
            "Epoch 28, loss: 2.302095\n",
            "Epoch 29, loss: 2.302001\n",
            "Epoch 30, loss: 2.301718\n",
            "Epoch 31, loss: 2.302079\n",
            "Epoch 32, loss: 2.301887\n",
            "Epoch 33, loss: 2.302165\n",
            "Epoch 34, loss: 2.301501\n",
            "Epoch 35, loss: 2.303041\n",
            "Epoch 36, loss: 2.302333\n",
            "Epoch 37, loss: 2.302951\n",
            "Epoch 38, loss: 2.302386\n",
            "Epoch 39, loss: 2.302674\n",
            "Epoch 40, loss: 2.301581\n",
            "Epoch 41, loss: 2.301842\n",
            "Epoch 42, loss: 2.302198\n",
            "Epoch 43, loss: 2.302898\n",
            "Epoch 44, loss: 2.301863\n",
            "Epoch 45, loss: 2.302397\n",
            "Epoch 46, loss: 2.302520\n",
            "Epoch 47, loss: 2.303064\n",
            "Epoch 48, loss: 2.302524\n",
            "Epoch 49, loss: 2.302143\n",
            "Epoch 50, loss: 2.302811\n",
            "Epoch 51, loss: 2.302152\n",
            "Epoch 52, loss: 2.301783\n",
            "Epoch 53, loss: 2.302597\n",
            "Epoch 54, loss: 2.302526\n",
            "Epoch 55, loss: 2.302181\n",
            "Epoch 56, loss: 2.302355\n",
            "Epoch 57, loss: 2.301702\n",
            "Epoch 58, loss: 2.302437\n",
            "Epoch 59, loss: 2.303184\n",
            "Epoch 60, loss: 2.302547\n",
            "Epoch 61, loss: 2.302885\n",
            "Epoch 62, loss: 2.302608\n",
            "Epoch 63, loss: 2.302658\n",
            "Epoch 64, loss: 2.302931\n",
            "Epoch 65, loss: 2.302288\n",
            "Epoch 66, loss: 2.303230\n",
            "Epoch 67, loss: 2.302256\n",
            "Epoch 68, loss: 2.302762\n",
            "Epoch 69, loss: 2.303005\n",
            "Epoch 70, loss: 2.301986\n",
            "Epoch 71, loss: 2.302001\n",
            "Epoch 72, loss: 2.302458\n",
            "Epoch 73, loss: 2.303285\n",
            "Epoch 74, loss: 2.302905\n",
            "Epoch 75, loss: 2.302736\n",
            "Epoch 76, loss: 2.302763\n",
            "Epoch 77, loss: 2.302324\n",
            "Epoch 78, loss: 2.303059\n",
            "Epoch 79, loss: 2.302654\n",
            "Epoch 80, loss: 2.303117\n",
            "Epoch 81, loss: 2.302605\n",
            "Epoch 82, loss: 2.301863\n",
            "Epoch 83, loss: 2.303104\n",
            "Epoch 84, loss: 2.302148\n",
            "Epoch 85, loss: 2.302091\n",
            "Epoch 86, loss: 2.302479\n",
            "Epoch 87, loss: 2.302184\n",
            "Epoch 88, loss: 2.302101\n",
            "Epoch 89, loss: 2.302456\n",
            "Epoch 90, loss: 2.301939\n",
            "Epoch 91, loss: 2.302331\n",
            "Epoch 92, loss: 2.302880\n",
            "Epoch 93, loss: 2.302484\n",
            "Epoch 94, loss: 2.302316\n",
            "Epoch 95, loss: 2.302799\n",
            "Epoch 96, loss: 2.302384\n",
            "Epoch 97, loss: 2.302576\n",
            "Epoch 98, loss: 2.302702\n",
            "Epoch 99, loss: 2.301539\n",
            "Epoch 100, loss: 2.302751\n",
            "Epoch 101, loss: 2.303104\n",
            "Epoch 102, loss: 2.302083\n",
            "Epoch 103, loss: 2.303116\n",
            "Epoch 104, loss: 2.301991\n",
            "Epoch 105, loss: 2.302685\n",
            "Epoch 106, loss: 2.301933\n",
            "Epoch 107, loss: 2.302370\n",
            "Epoch 108, loss: 2.302274\n",
            "Epoch 109, loss: 2.302403\n",
            "Epoch 110, loss: 2.302221\n",
            "Epoch 111, loss: 2.302459\n",
            "Epoch 112, loss: 2.302461\n",
            "Epoch 113, loss: 2.302818\n",
            "Epoch 114, loss: 2.302302\n",
            "Epoch 115, loss: 2.302336\n",
            "Epoch 116, loss: 2.301736\n",
            "Epoch 117, loss: 2.302304\n",
            "Epoch 118, loss: 2.302785\n",
            "Epoch 119, loss: 2.302104\n",
            "Epoch 120, loss: 2.302690\n",
            "Epoch 121, loss: 2.302226\n",
            "Epoch 122, loss: 2.302484\n",
            "Epoch 123, loss: 2.302692\n",
            "Epoch 124, loss: 2.302405\n",
            "Epoch 125, loss: 2.302586\n",
            "Epoch 126, loss: 2.302034\n",
            "Epoch 127, loss: 2.302659\n",
            "Epoch 128, loss: 2.302246\n",
            "Epoch 129, loss: 2.301594\n",
            "Epoch 130, loss: 2.303051\n",
            "Epoch 131, loss: 2.303678\n",
            "Epoch 132, loss: 2.302124\n",
            "Epoch 133, loss: 2.301523\n",
            "Epoch 134, loss: 2.302049\n",
            "Epoch 135, loss: 2.302177\n",
            "Epoch 136, loss: 2.302175\n",
            "Epoch 137, loss: 2.301946\n",
            "Epoch 138, loss: 2.302758\n",
            "Epoch 139, loss: 2.302493\n",
            "Epoch 140, loss: 2.302555\n",
            "Epoch 141, loss: 2.302048\n",
            "Epoch 142, loss: 2.302852\n",
            "Epoch 143, loss: 2.302324\n",
            "Epoch 144, loss: 2.302120\n",
            "Epoch 145, loss: 2.302001\n",
            "Epoch 146, loss: 2.303012\n",
            "Epoch 147, loss: 2.302129\n",
            "Epoch 148, loss: 2.302070\n",
            "Epoch 149, loss: 2.302846\n",
            "Epoch 150, loss: 2.302783\n",
            "Epoch 151, loss: 2.302501\n",
            "Epoch 152, loss: 2.301748\n",
            "Epoch 153, loss: 2.302030\n",
            "Epoch 154, loss: 2.302898\n",
            "Epoch 155, loss: 2.301984\n",
            "Epoch 156, loss: 2.302016\n",
            "Epoch 157, loss: 2.302597\n",
            "Epoch 158, loss: 2.302366\n",
            "Epoch 159, loss: 2.302297\n",
            "Epoch 160, loss: 2.301995\n",
            "Epoch 161, loss: 2.302370\n",
            "Epoch 162, loss: 2.302671\n",
            "Epoch 163, loss: 2.303027\n",
            "Epoch 164, loss: 2.302323\n",
            "Epoch 165, loss: 2.302763\n",
            "Epoch 166, loss: 2.302662\n",
            "Epoch 167, loss: 2.302234\n",
            "Epoch 168, loss: 2.302555\n",
            "Epoch 169, loss: 2.302902\n",
            "Epoch 170, loss: 2.301519\n",
            "Epoch 171, loss: 2.302187\n",
            "Epoch 172, loss: 2.302039\n",
            "Epoch 173, loss: 2.302395\n",
            "Epoch 174, loss: 2.302253\n",
            "Epoch 175, loss: 2.302049\n",
            "Epoch 176, loss: 2.302022\n",
            "Epoch 177, loss: 2.301589\n",
            "Epoch 178, loss: 2.302181\n",
            "Epoch 179, loss: 2.302697\n",
            "Epoch 180, loss: 2.302945\n",
            "Epoch 181, loss: 2.302082\n",
            "Epoch 182, loss: 2.302127\n",
            "Epoch 183, loss: 2.302698\n",
            "Epoch 184, loss: 2.301865\n",
            "Epoch 185, loss: 2.303352\n",
            "Epoch 186, loss: 2.302502\n",
            "Epoch 187, loss: 2.302540\n",
            "Epoch 188, loss: 2.302404\n",
            "Epoch 189, loss: 2.302041\n",
            "Epoch 190, loss: 2.301828\n",
            "Epoch 191, loss: 2.302427\n",
            "Epoch 192, loss: 2.302215\n",
            "Epoch 193, loss: 2.301550\n",
            "Epoch 194, loss: 2.302393\n",
            "Epoch 195, loss: 2.302440\n",
            "Epoch 196, loss: 2.302241\n",
            "Epoch 197, loss: 2.302007\n",
            "Epoch 198, loss: 2.302541\n",
            "Epoch 199, loss: 2.302734\n",
            "Epoch 0, loss: 2.302367\n",
            "Epoch 1, loss: 2.302614\n",
            "Epoch 2, loss: 2.302917\n",
            "Epoch 3, loss: 2.302001\n",
            "Epoch 4, loss: 2.302731\n",
            "Epoch 5, loss: 2.301898\n",
            "Epoch 6, loss: 2.301959\n",
            "Epoch 7, loss: 2.303049\n",
            "Epoch 8, loss: 2.302610\n",
            "Epoch 9, loss: 2.302669\n",
            "Epoch 10, loss: 2.303376\n",
            "Epoch 11, loss: 2.302570\n",
            "Epoch 12, loss: 2.300700\n",
            "Epoch 13, loss: 2.303387\n",
            "Epoch 14, loss: 2.303053\n",
            "Epoch 15, loss: 2.301808\n",
            "Epoch 16, loss: 2.301855\n",
            "Epoch 17, loss: 2.300739\n",
            "Epoch 18, loss: 2.302191\n",
            "Epoch 19, loss: 2.302661\n",
            "Epoch 20, loss: 2.302069\n",
            "Epoch 21, loss: 2.301923\n",
            "Epoch 22, loss: 2.302462\n",
            "Epoch 23, loss: 2.302474\n",
            "Epoch 24, loss: 2.303024\n",
            "Epoch 25, loss: 2.301837\n",
            "Epoch 26, loss: 2.302898\n",
            "Epoch 27, loss: 2.302887\n",
            "Epoch 28, loss: 2.301717\n",
            "Epoch 29, loss: 2.302585\n",
            "Epoch 30, loss: 2.302149\n",
            "Epoch 31, loss: 2.301225\n",
            "Epoch 32, loss: 2.303501\n",
            "Epoch 33, loss: 2.301614\n",
            "Epoch 34, loss: 2.302923\n",
            "Epoch 35, loss: 2.302109\n",
            "Epoch 36, loss: 2.301605\n",
            "Epoch 37, loss: 2.302144\n",
            "Epoch 38, loss: 2.301731\n",
            "Epoch 39, loss: 2.303157\n",
            "Epoch 40, loss: 2.301954\n",
            "Epoch 41, loss: 2.303143\n",
            "Epoch 42, loss: 2.301551\n",
            "Epoch 43, loss: 2.302336\n",
            "Epoch 44, loss: 2.303141\n",
            "Epoch 45, loss: 2.302682\n",
            "Epoch 46, loss: 2.302289\n",
            "Epoch 47, loss: 2.302455\n",
            "Epoch 48, loss: 2.302348\n",
            "Epoch 49, loss: 2.301561\n",
            "Epoch 50, loss: 2.303287\n",
            "Epoch 51, loss: 2.301292\n",
            "Epoch 52, loss: 2.301426\n",
            "Epoch 53, loss: 2.302392\n",
            "Epoch 54, loss: 2.301704\n",
            "Epoch 55, loss: 2.301839\n",
            "Epoch 56, loss: 2.302676\n",
            "Epoch 57, loss: 2.300977\n",
            "Epoch 58, loss: 2.300706\n",
            "Epoch 59, loss: 2.301953\n",
            "Epoch 60, loss: 2.302591\n",
            "Epoch 61, loss: 2.302230\n",
            "Epoch 62, loss: 2.302216\n",
            "Epoch 63, loss: 2.302910\n",
            "Epoch 64, loss: 2.303236\n",
            "Epoch 65, loss: 2.302653\n",
            "Epoch 66, loss: 2.301924\n",
            "Epoch 67, loss: 2.301718\n",
            "Epoch 68, loss: 2.302092\n",
            "Epoch 69, loss: 2.301582\n",
            "Epoch 70, loss: 2.302365\n",
            "Epoch 71, loss: 2.301676\n",
            "Epoch 72, loss: 2.301769\n",
            "Epoch 73, loss: 2.301738\n",
            "Epoch 74, loss: 2.302474\n",
            "Epoch 75, loss: 2.303784\n",
            "Epoch 76, loss: 2.302986\n",
            "Epoch 77, loss: 2.303442\n",
            "Epoch 78, loss: 2.302161\n",
            "Epoch 79, loss: 2.300953\n",
            "Epoch 80, loss: 2.302173\n",
            "Epoch 81, loss: 2.302111\n",
            "Epoch 82, loss: 2.302715\n",
            "Epoch 83, loss: 2.302011\n",
            "Epoch 84, loss: 2.303364\n",
            "Epoch 85, loss: 2.302893\n",
            "Epoch 86, loss: 2.301191\n",
            "Epoch 87, loss: 2.302198\n",
            "Epoch 88, loss: 2.301774\n",
            "Epoch 89, loss: 2.302338\n",
            "Epoch 90, loss: 2.302306\n",
            "Epoch 91, loss: 2.302254\n",
            "Epoch 92, loss: 2.303232\n",
            "Epoch 93, loss: 2.301656\n",
            "Epoch 94, loss: 2.301723\n",
            "Epoch 95, loss: 2.302896\n",
            "Epoch 96, loss: 2.302688\n",
            "Epoch 97, loss: 2.301499\n",
            "Epoch 98, loss: 2.302352\n",
            "Epoch 99, loss: 2.301523\n",
            "Epoch 100, loss: 2.302155\n",
            "Epoch 101, loss: 2.302265\n",
            "Epoch 102, loss: 2.302439\n",
            "Epoch 103, loss: 2.302442\n",
            "Epoch 104, loss: 2.301211\n",
            "Epoch 105, loss: 2.303320\n",
            "Epoch 106, loss: 2.302120\n",
            "Epoch 107, loss: 2.302005\n",
            "Epoch 108, loss: 2.302336\n",
            "Epoch 109, loss: 2.300750\n",
            "Epoch 110, loss: 2.302571\n",
            "Epoch 111, loss: 2.301898\n",
            "Epoch 112, loss: 2.302482\n",
            "Epoch 113, loss: 2.302249\n",
            "Epoch 114, loss: 2.302717\n",
            "Epoch 115, loss: 2.302370\n",
            "Epoch 116, loss: 2.303259\n",
            "Epoch 117, loss: 2.303469\n",
            "Epoch 118, loss: 2.301884\n",
            "Epoch 119, loss: 2.302528\n",
            "Epoch 120, loss: 2.300905\n",
            "Epoch 121, loss: 2.302493\n",
            "Epoch 122, loss: 2.302123\n",
            "Epoch 123, loss: 2.301861\n",
            "Epoch 124, loss: 2.302525\n",
            "Epoch 125, loss: 2.302763\n",
            "Epoch 126, loss: 2.301696\n",
            "Epoch 127, loss: 2.301198\n",
            "Epoch 128, loss: 2.303767\n",
            "Epoch 129, loss: 2.302218\n",
            "Epoch 130, loss: 2.302385\n",
            "Epoch 131, loss: 2.301668\n",
            "Epoch 132, loss: 2.300725\n",
            "Epoch 133, loss: 2.301895\n",
            "Epoch 134, loss: 2.300864\n",
            "Epoch 135, loss: 2.303195\n",
            "Epoch 136, loss: 2.301634\n",
            "Epoch 137, loss: 2.302825\n",
            "Epoch 138, loss: 2.301990\n",
            "Epoch 139, loss: 2.302120\n",
            "Epoch 140, loss: 2.302863\n",
            "Epoch 141, loss: 2.302335\n",
            "Epoch 142, loss: 2.301971\n",
            "Epoch 143, loss: 2.301692\n",
            "Epoch 144, loss: 2.301371\n",
            "Epoch 145, loss: 2.302486\n",
            "Epoch 146, loss: 2.300993\n",
            "Epoch 147, loss: 2.302121\n",
            "Epoch 148, loss: 2.302307\n",
            "Epoch 149, loss: 2.301951\n",
            "Epoch 150, loss: 2.301899\n",
            "Epoch 151, loss: 2.301368\n",
            "Epoch 152, loss: 2.302343\n",
            "Epoch 153, loss: 2.302002\n",
            "Epoch 154, loss: 2.302999\n",
            "Epoch 155, loss: 2.303360\n",
            "Epoch 156, loss: 2.303556\n",
            "Epoch 157, loss: 2.302003\n",
            "Epoch 158, loss: 2.301711\n",
            "Epoch 159, loss: 2.302180\n",
            "Epoch 160, loss: 2.301419\n",
            "Epoch 161, loss: 2.301966\n",
            "Epoch 162, loss: 2.302640\n",
            "Epoch 163, loss: 2.302626\n",
            "Epoch 164, loss: 2.302777\n",
            "Epoch 165, loss: 2.301510\n",
            "Epoch 166, loss: 2.301455\n",
            "Epoch 167, loss: 2.303287\n",
            "Epoch 168, loss: 2.302371\n",
            "Epoch 169, loss: 2.301876\n",
            "Epoch 170, loss: 2.302344\n",
            "Epoch 171, loss: 2.301899\n",
            "Epoch 172, loss: 2.302634\n",
            "Epoch 173, loss: 2.302759\n",
            "Epoch 174, loss: 2.302419\n",
            "Epoch 175, loss: 2.301891\n",
            "Epoch 176, loss: 2.301261\n",
            "Epoch 177, loss: 2.302315\n",
            "Epoch 178, loss: 2.302295\n",
            "Epoch 179, loss: 2.302202\n",
            "Epoch 180, loss: 2.302497\n",
            "Epoch 181, loss: 2.302268\n",
            "Epoch 182, loss: 2.302873\n",
            "Epoch 183, loss: 2.303572\n",
            "Epoch 184, loss: 2.302639\n",
            "Epoch 185, loss: 2.302903\n",
            "Epoch 186, loss: 2.303400\n",
            "Epoch 187, loss: 2.301445\n",
            "Epoch 188, loss: 2.303439\n",
            "Epoch 189, loss: 2.301342\n",
            "Epoch 190, loss: 2.302334\n",
            "Epoch 191, loss: 2.302024\n",
            "Epoch 192, loss: 2.301546\n",
            "Epoch 193, loss: 2.300928\n",
            "Epoch 194, loss: 2.302255\n",
            "Epoch 195, loss: 2.302188\n",
            "Epoch 196, loss: 2.301019\n",
            "Epoch 197, loss: 2.301962\n",
            "Epoch 198, loss: 2.300917\n",
            "Epoch 199, loss: 2.301194\n",
            "best validation accuracy achieved: 0.243000\n",
            "best learning_rate = 0.010000\n",
            "best reg_strength = 0.000010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PyNH2-rNlWc",
        "colab_type": "text"
      },
      "source": [
        "# Какой же точности мы добились на тестовых данных?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5sV1bdENlWc",
        "colab_type": "code",
        "outputId": "1b4a1d55-1b4c-4dca-e390-9061816e154e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_pred = best_classifier.predict(test_X)\n",
        "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
        "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear softmax classifier test set accuracy: 0.202000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
